{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate evaluate bitsandbytes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/trl\n",
    "!pip install git+https://github.com/huggingface/peft"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "_gK1RhOjmJKH"
   },
   "source": [
    "If you are using a GPU with Ampere architecture (e.g. NVIDIA A10G or RTX 4090/3090) or newer you can use Flash attention. Flash Attention is a an method that reorders the attention computation and leverages classical techniques (tiling, recomputation) to significantly speed it up and reduce memory usage from quadratic to linear in sequence length. The TL;DR; accelerates training up to 3x. Learn more at [FlashAttention](https://github.com/Dao-AILab/flash-attention/tree/main).\n",
    "\n",
    "_Note: If your machine has less than 96GB of RAM and lots of CPU cores, reduce the number of `MAX_JOBS`. On the `g5.2xlarge` we used `4`._\n",
    "_Installing flash attention can take quite a bit of time (10-45 minutes)._\n",
    " import torch; assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'\n",
    " install flash-attn\n",
    " !pip install ninja packaging\n",
    " !MAX_JOBS=4 pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntaxbPXmmJKI",
    "outputId": "1b796a49-2970-4314-ac9c-6df65f4af044"
   },
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "\n",
    "import os\n",
    "HUGGINGFACE_TOKEN = userdata.get('HUGGINGFACE_TOKEN')\n",
    "\n",
    "login(\n",
    "  token=HUGGINGFACE_TOKEN, # ADD YOUR TOKEN HERE\n",
    "  add_to_git_credential=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:35:18.938729Z",
     "iopub.status.busy": "2024-05-16T08:35:18.938293Z",
     "iopub.status.idle": "2024-05-16T08:35:18.946629Z",
     "shell.execute_reply": "2024-05-16T08:35:18.946028Z",
     "shell.execute_reply.started": "2024-05-16T08:35:18.938699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "isWin=False\n",
    "shard=10\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "maxInput=2000\n",
    "IGNORE_INDEX = -100"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "dataset=load_dataset(\"json\", data_files={#\"train\":\"I:/kaggle/wizard_train_dataset.json\", \n",
    "                                         \"test\":\"I:/kaggle/math.stackexchange.com.shard_0.jsonl\"}, \n",
    "                     cache_dir=\"I:/kaggle/cache\") # 原始数据集, 不是token\n",
    "dataset "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "source": [
    "!ls -la /mnt/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:37:15.339374Z",
     "iopub.status.busy": "2024-05-16T08:37:15.339087Z",
     "iopub.status.idle": "2024-05-16T08:37:23.574519Z",
     "shell.execute_reply": "2024-05-16T08:37:23.574035Z",
     "shell.execute_reply.started": "2024-05-16T08:37:15.339357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 788416 examples [00:05, 134959.98 examples/s]\n",
      "Generating test split: 1580 examples [00:00, 19298.03 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 788416\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 1580\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "if isWin:\n",
    "    dataset=load_dataset(\"json\", \n",
    "        data_files={\"train\":\"I:/kaggle/tokened_deepseek_math.stackexchange.com_shard\" + str(shard) + \"_train_dataset.json\", \n",
    "                    \"test\":\"I:/kaggle/tokened_deepseek_math.stackexchange.com_shard\" + str(shard) + \"_test_dataset.json\"}, \n",
    "                     cache_dir=\"I:/kaggle/cache\") # 是token,可以直接训练,不需要在token化\n",
    "else:\n",
    "    # dataset=load_dataset(\"json\", \n",
    "        # data_files={\"train\":\"/mnt/data/data/tokened_deepseek_math.stackexchange.com_shard\" + str(shard) + \"_train_dataset.json\", \n",
    "        #             \"test\":\"/mnt/data/data/tokened_deepseek_math.stackexchange.com_shard\" + str(shard) + \"_test_dataset.json\"}, \n",
    "        #              cache_dir=\"I:/kaggle/cache\") # 是token,可以直接训练,不需要在token化\n",
    "    dataset=load_dataset(\"json\", \n",
    "        data_files={\"train\":\"/mnt/data/data/tokened_deepseek_math.OpenMathIns_train_dataset.json\", \n",
    "                    \"test\":\"/mnt/data/data/tokened_deepseek_math.OpenMathIns_test_dataset.json\"}, \n",
    "                     cache_dir=\"I:/kaggle/cache\") # 是token,可以直接训练,不需要在token化\n",
    "dataset "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset=dataset.remove_columns(\"meta\") # 第一次处理,不需要再运行了\n",
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset=dataset[\"test\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset=dataset.shuffle() # 第一次处理,不需要再运行了\n",
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 原始数据分片用,不需要再运行了\n",
    "dataset=dataset.shuffle()\n",
    "\n",
    "for i in range(40):\n",
    "    dataset.shard(num_shards=40, index=i).to_json(\"I:/kaggle/math.stackexchange.com.shard_\" + str(i) + \".jsonl\", orient=\"records\")\n",
    "    print(i,\"finished\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "dataset=load_dataset(\"json\", data_files={\"train\":\"I:/kaggle/tokened_test_train_dataset.json\", \"test\":\"I:/kaggle/tokened_test_test_dataset.json\"}, \n",
    "                     cache_dir=\"I:/kaggle/cache\") # wizard 的 tokened 数据集, 装载直接可以训练\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:37:32.832307Z",
     "iopub.status.busy": "2024-05-16T08:37:32.831759Z",
     "iopub.status.idle": "2024-05-16T08:37:35.967033Z",
     "shell.execute_reply": "2024-05-16T08:37:35.966551Z",
     "shell.execute_reply.started": "2024-05-16T08:37:32.832287Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, BitsAndBytesConfig, PreTrainedModel, pipeline\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:37:39.725329Z",
     "iopub.status.busy": "2024-05-16T08:37:39.724746Z",
     "iopub.status.idle": "2024-05-16T08:38:17.878759Z",
     "shell.execute_reply": "2024-05-16T08:38:17.878287Z",
     "shell.execute_reply.started": "2024-05-16T08:37:39.725308Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:35<00:00, 11.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LlamaForCausalLM(\n",
       "   (model): LlamaModel(\n",
       "     (embed_tokens): Embedding(102400, 4096)\n",
       "     (layers): ModuleList(\n",
       "       (0-29): 30 x LlamaDecoderLayer(\n",
       "         (self_attn): LlamaFlashAttention2(\n",
       "           (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "           (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "           (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "           (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "           (rotary_emb): LlamaRotaryEmbedding()\n",
       "         )\n",
       "         (mlp): LlamaMLP(\n",
       "           (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "           (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "           (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "           (act_fn): SiLU()\n",
       "         )\n",
       "         (input_layernorm): LlamaRMSNorm()\n",
       "         (post_attention_layernorm): LlamaRMSNorm()\n",
       "       )\n",
       "     )\n",
       "     (norm): LlamaRMSNorm()\n",
       "   )\n",
       "   (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
       " ),\n",
       " LlamaTokenizerFast(name_or_path='/mnt/data/deepseek-math-7b-it', vocab_size=100000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       " \t100000: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t100001: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " })"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isWin:\n",
    "    model_name = \"I:/kaggle/deepseek-math-7b-it\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"I:/kaggle/deepseek-math-7b-it\")\n",
    "    attn_implementation=None\n",
    "    bnb_config=None\n",
    "else:\n",
    "    model_name = \"/mnt/data/deepseek-math-7b-it\"\n",
    "    # model_name = \"/mnt/data/deepseek-math-7b-it-Train\" + str(shard) + \"Merged\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"/mnt/data/deepseek-math-7b-it\")\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             attn_implementation = attn_implementation,\n",
    "                                             quantization_config=bnb_config)\n",
    "\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "model, tokenizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "import os # PROTOCOL version problem, solved\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\"\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:17.879931Z",
     "iopub.status.busy": "2024-05-16T08:38:17.879703Z",
     "iopub.status.idle": "2024-05-16T08:38:17.882975Z",
     "shell.execute_reply": "2024-05-16T08:38:17.882583Z",
     "shell.execute_reply.started": "2024-05-16T08:38:17.879909Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 788416\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 1580\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-15T19:09:19.667988Z",
     "iopub.status.busy": "2024-05-15T19:09:19.667677Z",
     "iopub.status.idle": "2024-05-15T19:09:19.675145Z",
     "shell.execute_reply": "2024-05-15T19:09:19.674769Z",
     "shell.execute_reply.started": "2024-05-15T19:09:19.667972Z"
    },
    "tags": []
   },
   "source": [
    "dataset = dataset.filter(lambda x: len(x[\"input_ids\"]) < maxInput and len(x[\"labels\"]) > 10)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:17.883661Z",
     "iopub.status.busy": "2024-05-16T08:38:17.883516Z",
     "iopub.status.idle": "2024-05-16T08:38:17.888344Z",
     "shell.execute_reply": "2024-05-16T08:38:17.887947Z",
     "shell.execute_reply.started": "2024-05-16T08:38:17.883648Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].select([0]) # dataset分片成dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset = dataset.map( # 训练集已经是token,不用运行token化\n",
    "        train_tokenize_function,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=6,\n",
    "        remove_columns=dataset.column_names,\n",
    "        load_from_cache_file=True, # not args.overwrite_cache\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "        fn_kwargs={\"tokenizer\": tokenizer}, \n",
    "    )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:17.889540Z",
     "iopub.status.busy": "2024-05-16T08:38:17.889323Z",
     "iopub.status.idle": "2024-05-16T08:38:17.986224Z",
     "shell.execute_reply": "2024-05-16T08:38:17.985812Z",
     "shell.execute_reply.started": "2024-05-16T08:38:17.889520Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "cc579f76e7be4092b3942987154e3b44",
      "6bc000b7fcdc4c84b1707af92d1ba12a",
      "fd98f0d9d2254d90857765c5455039fa",
      "2c75a816067041619e25612e46720b1e",
      "175960d3168c412cabb59bfe78b03ecc",
      "63ea853c844f487bb09f65f2feeff984",
      "f8210c6f006447058895e3fa818daf2a",
      "42927861ab844eec9b279a221f574ecf",
      "007cfd8a537142229c2d235b15400c8e",
      "b0c8764dcdae4187b4a4131ea1e8c88d",
      "156fdb05e0174c01b8b8654b53678f67",
      "4fe593d166024384a2dc0ec21d00b176",
      "13e3e63b9b15449ab4ef12d616d8cf8b",
      "c542d12ff49e4906a929c20dcae6211c",
      "4701f15db2f547e89fae6b90b13ff846",
      "50e4e01a0d544b11b0dcf230719b7f16",
      "7c53421f3e144a5c8f177776cdb27f4d",
      "ada74a8c85d048f0a21d2aa87805ea57",
      "30f67e4575954a2caf8bed2265a583d8",
      "cf0257bf1eba428d8c475ff263f51f47",
      "c4a1a352853f4b2c9c77240b1ca49b9b",
      "5e7fad834ce64f04bce884f79696003a",
      "d446af78e6ce4d10b204da001c228043",
      "9e4f9354cc944c4f99386a48acde165f",
      "6bd021532b76412cb055c3e39d3c641e",
      "d198b894872f40ffaeb3febcbd3e6f14",
      "9f12c904bdc844a696519b3e6986b996",
      "5cf9d8de00cd46c3a1c2c7ffe55ed393",
      "2a697b9a7d254aa28224d575b0c115b5",
      "7ec24ce536db4942bfb917a706f8ad45",
      "12bff94024954bc8821ea4a44a840e32",
      "591e62b79c8149619c0cb603bb7072e0",
      "9b94dcef291f42ecbe60f581797e59b4",
      "43c08dffca244f849456ede07572064a",
      "5651bb0eaff04486831b58b2b57b89ce",
      "cb4441030c074583b5484f47e8098914",
      "859510d2bfb24b72855c7efbb7c19803",
      "a8b4cada8cf8458da963b8491f379fcf",
      "12d445af02ea423c9aad5787fa77c458",
      "d82646bbbd064b44802c0eee8b3a3655",
      "67edbbe26a124b0dabdd35a85654aa28",
      "e1cfc4a4074d40e9bf587f8f2cb6a047",
      "ba7ea628ec594bf99931fd0b50bfe7ec",
      "31c5d5388a2b4c668ad12587e188cfb7",
      "31686c96e7af40d092dd93b5ee483978",
      "032f0226c35449a2896e7ed91fcd386e",
      "862b7ba3b11f44439c307ead7344d2cb",
      "3f1434935da240c386618b8022a5fbf9",
      "a85d45deaa2d4257a5603d6ccd9a7bb9",
      "8b9f33eba5924aeda288228e798bca13",
      "69d50e01293b4bdca4660ab260e3c6a2",
      "39dad16cb7cf402fa11643da3dfea7c5",
      "6b338dd6322c4abda77e6dc005029080",
      "e4384ae8aed14fb2b6bfd95d3a948d30",
      "55b0f3cf946e4bba8576ff9c35d3c4dd"
     ]
    },
    "id": "x5dvjw3JmJKJ",
    "outputId": "2c707c39-7dc9-4a43-c27a-c158d101a92c"
   },
   "source": [
    "# Load dataset from the hub 官方例子\n",
    "dataset_dict = load_dataset(\"Hello-SimpleAI/HC3-Chinese\", name=\"baike\")\n",
    "dataset = dataset_dict['train']\n",
    "print(create_conversation(dataset[0]))\n",
    "\n",
    "# # Convert dataset to OAI messages\n",
    "dataset = dataset.map(create_conversation, remove_columns=[\"id\", \"chatgpt_answers\"], batched=False)\n",
    "# # split dataset into 10,000 training samples and 2,500 test samples\n",
    "# dataset = dataset.train_test_split(test_size=4500/4616)  # baike split\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKlEnozbmJKJ"
   },
   "source": [
    "## 4. Fine-tune LLM using `trl` and the `SFTTrainer`\n",
    "\n",
    "use [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer) from `trl` to fine-tune our model. The `SFTTrainer` makes it straightfoward to supervise fine-tune open LLMs. The `SFTTrainer` is a subclass of the `Trainer` from the `transformers` library and supports all the same features, including logging, evaluation, and checkpointing, but adds additiional quality of life features, including:\n",
    "* Dataset formatting, including conversational and instruction format\n",
    "* Training on completions only, ignoring prompts\n",
    "* Packing datasets for more efficient training\n",
    "* PEFT (parameter-efficient fine-tuning) support including Q-LoRA\n",
    "* Preparing the model and tokenizer for conversational fine-tuning (e.g. adding special tokens)\n",
    "\n",
    "We will use the dataset formatting, packing and PEFT features in our example. As peft method we will use [QLoRA](https://arxiv.org/abs/2305.14314) a technique to reduce the memory footprint of large language models during finetuning, without sacrificing performance by using quantization. If you want to learn more about QLoRA and how it works, check out [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes) blog post.\n",
    "\n",
    "Next, we will load our LLM. For our use case we are going to use CodeLlama 7B. CodeLlama is a Llama model trained for general code synthesis and understanding.\n",
    "But we can easily swap out the model for another model, e.g. [Mistral](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) or [Mixtral](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) models, TII [Falcon](https://huggingface.co/tiiuae/falcon-40b), or any other LLMs by changing our `model_id` variable. We will use bitsandbytes to quantize our model to 4-bit.\n",
    "\n",
    "_Note: Be aware the bigger the model the more memory it will require. In our example we will use the 7B version, which can be tuned on 24GB GPUs. If you have a smaller GPU._\n",
    "\n",
    "Correctly, preparing the LLM and Tokenizer for training chat/conversational models is crucial. We need to add new special tokens to the tokenizer and model and teach to understand the different roles in a conversation. In `trl` we have a convinient method called [setup_chat_format](https://huggingface.co/docs/trl/main/en/sft_trainer#add-special-tokens-for-chat-format), which:\n",
    "* Adds special tokens to the tokenizer, e.g. `<|im_start|>` and `<|im_end|>`, to indicate the start and end of a conversation.\n",
    "* Resizes the model’s embedding layer to accommodate the new tokens.\n",
    "* Sets the `chat_template` of the tokenizer, which is used to format the input data into a chat-like format. The default is `chatml` from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:17.987074Z",
     "iopub.status.busy": "2024-05-16T08:38:17.986911Z",
     "iopub.status.idle": "2024-05-16T08:38:18.075131Z",
     "shell.execute_reply": "2024-05-16T08:38:18.074603Z",
     "shell.execute_reply.started": "2024-05-16T08:38:17.987060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 可以直接从 peft 的检查点装载模型.  所有的模型都可以直接从检查点加载 . 可以测试下从这个检查点装载的模型,参数是否是可训练的\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "检查点_path,\n",
    "torch_dtype=torch.bfloat16, device_map=\"auto\",\n",
    "load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 不要装载 peft 模型, 装载之后梯度传播不了\n",
    "# 把 peft 模型合并到基础模型装载, 之后加 peft 进行训练\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    \"I:/kaggle/your model path\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    is_trainable = True,\n",
    "    adapter_name = \"peft_adapter1\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"I:/kaggle/deepseek-math-7b-it\",use_fast=True)\n",
    "tokenizer.padding_side = 'right' # to prevent warnings\n",
    "model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.075967Z",
     "iopub.status.busy": "2024-05-16T08:38:18.075752Z",
     "iopub.status.idle": "2024-05-16T08:38:18.080388Z",
     "shell.execute_reply": "2024-05-16T08:38:18.080007Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.075951Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[100000,  56846,     87,   1689,  39422]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Latex LaTex\",\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=4096,\n",
    "                truncation=True,\n",
    "            )#.input_ids.ne(tokenizer.pad_token_id).sum().item()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "da = dataset.train_test_split(test_size=0.005) # 装载的已经是train和test的dict dataset了\n",
    "da"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "test_dataset=load_dataset(\"json\", data_files={\"train\":\"I:/kaggle/tokened_test_train_dataset.json\", \"test\":\"I:/kaggle/tokened_test_test_dataset.json\"}, \n",
    "                     cache_dir=\"I:/kaggle/cache\") # wizard 的 tokened 数据集, 装载直接可以训练\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 把带有 input , output 和 instruction 的数据转化成 token , wizard 可以直接训练的 token\n",
    "test_dataset = da[\"test\"].map(\n",
    "        train_tokenize_function,\n",
    "        batched=True, # 必须为True,因为 1个问答分解的不是个问题,而是一系列问题,答案是一个列表的列表.要求长度一样\n",
    "        batch_size=1000,\n",
    "        num_proc=6,\n",
    "        remove_columns=da[\"test\"].column_names,\n",
    "        load_from_cache_file=True, # not args.overwrite_cache\n",
    "        desc=\"Running tokenizer on test dataset\",\n",
    "        fn_kwargs={\"tokenizer\": tokenizer}\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_dataset = train_dataset.train_test_split(test_size=0.003)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "da[\"train\"].to_json(\"I:/kaggle/tokened_shard0_train_dataset.json\", orient=\"records\") # 这个数据读出来可以直接训练\n",
    "da[\"test\"].to_json(\"I:/kaggle/tokened_shard0_test_dataset.json\", orient=\"records\") # shard0已保存,装载就行.以免train数据shuffle到验证数据,结果过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.081063Z",
     "iopub.status.busy": "2024-05-16T08:38:18.080915Z",
     "iopub.status.idle": "2024-05-16T08:38:18.086894Z",
     "shell.execute_reply": "2024-05-16T08:38:18.086505Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.081050Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForSupervisedDataset(tokenizer=LlamaTokenizerFast(name_or_path='/mnt/data/deepseek-math-7b-it', vocab_size=100000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t100000: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t100001: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from typing import Optional, Dict, Sequence\n",
    "from dataclasses import dataclass, field\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = [torch.tensor(x) for x in input_ids]\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=False, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = [torch.tensor(x) for x in labels]\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=False, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.087587Z",
     "iopub.status.busy": "2024-05-16T08:38:18.087427Z",
     "iopub.status.idle": "2024-05-16T08:38:18.205001Z",
     "shell.execute_reply": "2024-05-16T08:38:18.204522Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.087574Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"]=dataset[\"train\"].shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.206056Z",
     "iopub.status.busy": "2024-05-16T08:38:18.205723Z",
     "iopub.status.idle": "2024-05-16T08:38:18.209027Z",
     "shell.execute_reply": "2024-05-16T08:38:18.208648Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.206038Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.210608Z",
     "iopub.status.busy": "2024-05-16T08:38:18.210323Z",
     "iopub.status.idle": "2024-05-16T08:38:18.213789Z",
     "shell.execute_reply": "2024-05-16T08:38:18.213320Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.210592Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset': Dataset({\n",
       "     features: ['input_ids', 'labels'],\n",
       "     num_rows: 788416\n",
       " }),\n",
       " 'eval_dataset': Dataset({\n",
       "     features: ['input_ids', 'labels'],\n",
       "     num_rows: 1580\n",
       " }),\n",
       " 'data_collator': DataCollatorForSupervisedDataset(tokenizer=LlamaTokenizerFast(name_or_path='/mnt/data/deepseek-math-7b-it', vocab_size=100000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       " \t100000: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " \t100001: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " })}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = dict(train_dataset=dataset[\"train\"], eval_dataset=dataset[\"test\"], data_collator=data_collator)\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.214592Z",
     "iopub.status.busy": "2024-05-16T08:38:18.214330Z",
     "iopub.status.idle": "2024-05-16T08:38:18.219000Z",
     "shell.execute_reply": "2024-05-16T08:38:18.218630Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.214578Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([100000,\n",
       "  5726,\n",
       "  25,\n",
       "  1724,\n",
       "  1313,\n",
       "  4864,\n",
       "  8095,\n",
       "  1217,\n",
       "  207,\n",
       "  18,\n",
       "  15,\n",
       "  463,\n",
       "  30,\n",
       "  185,\n",
       "  7900,\n",
       "  2806,\n",
       "  3458,\n",
       "  457,\n",
       "  3458,\n",
       "  11,\n",
       "  285,\n",
       "  565,\n",
       "  463,\n",
       "  2328,\n",
       "  3510,\n",
       "  1957,\n",
       "  254,\n",
       "  2328,\n",
       "  3510,\n",
       "  2383,\n",
       "  357,\n",
       "  63962,\n",
       "  40639,\n",
       "  410,\n",
       "  1957,\n",
       "  254,\n",
       "  3510,\n",
       "  1166,\n",
       "  655,\n",
       "  549,\n",
       "  3510,\n",
       "  317,\n",
       "  22734,\n",
       "  207,\n",
       "  185,\n",
       "  185,\n",
       "  77398,\n",
       "  25],\n",
       " [100000,\n",
       "  549,\n",
       "  9966,\n",
       "  45867,\n",
       "  280,\n",
       "  207,\n",
       "  18,\n",
       "  15,\n",
       "  317,\n",
       "  363,\n",
       "  17,\n",
       "  357,\n",
       "  3560,\n",
       "  207,\n",
       "  18,\n",
       "  357,\n",
       "  3560,\n",
       "  207,\n",
       "  20,\n",
       "  1332,\n",
       "  185,\n",
       "  6902,\n",
       "  6088,\n",
       "  280,\n",
       "  207,\n",
       "  18,\n",
       "  15,\n",
       "  1534,\n",
       "  330,\n",
       "  280,\n",
       "  254,\n",
       "  1020,\n",
       "  363,\n",
       "  17,\n",
       "  61,\n",
       "  64,\n",
       "  357,\n",
       "  3560,\n",
       "  207,\n",
       "  18,\n",
       "  61,\n",
       "  65,\n",
       "  357,\n",
       "  3560,\n",
       "  207,\n",
       "  20,\n",
       "  61,\n",
       "  66,\n",
       "  3,\n",
       "  1066,\n",
       "  363,\n",
       "  15,\n",
       "  357,\n",
       "  2848,\n",
       "  245,\n",
       "  357,\n",
       "  2848,\n",
       "  207,\n",
       "  16,\n",
       "  1348,\n",
       "  363,\n",
       "  15,\n",
       "  357,\n",
       "  2848,\n",
       "  270,\n",
       "  357,\n",
       "  2848,\n",
       "  207,\n",
       "  16,\n",
       "  1348,\n",
       "  285,\n",
       "  363,\n",
       "  15,\n",
       "  357,\n",
       "  2848,\n",
       "  258,\n",
       "  357,\n",
       "  2848,\n",
       "  207,\n",
       "  16,\n",
       "  1332,\n",
       "  185,\n",
       "  11775,\n",
       "  11,\n",
       "  745,\n",
       "  418,\n",
       "  3309,\n",
       "  16,\n",
       "  10,\n",
       "  16,\n",
       "  4951,\n",
       "  16,\n",
       "  10,\n",
       "  16,\n",
       "  4951,\n",
       "  16,\n",
       "  10,\n",
       "  16,\n",
       "  8,\n",
       "  403,\n",
       "  357,\n",
       "  63962,\n",
       "  90,\n",
       "  23,\n",
       "  759,\n",
       "  4864,\n",
       "  8095,\n",
       "  280,\n",
       "  207,\n",
       "  18,\n",
       "  15,\n",
       "  13,\n",
       "  185,\n",
       "  549,\n",
       "  3510,\n",
       "  317,\n",
       "  25,\n",
       "  207,\n",
       "  23])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]['input_ids'], dataset[\"test\"][0]['labels'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.219661Z",
     "iopub.status.busy": "2024-05-16T08:38:18.219494Z",
     "iopub.status.idle": "2024-05-16T08:38:18.223377Z",
     "shell.execute_reply": "2024-05-16T08:38:18.223006Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.219647Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prime factorization of 30 is $2 \\\\cdot 3 \\\\cdot 5$.\\nAny factor of 30 must be of the form $2^a \\\\cdot 3^b \\\\cdot 5^c$ where $0 \\\\leq a \\\\leq 1$, $0 \\\\leq b \\\\leq 1$, and $0 \\\\leq c \\\\leq 1$.\\nThus, there are $(1+1)(1+1)(1+1) = \\\\boxed{8}$ positive factors of 30.\\nThe answer is: 8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset[\"test\"][0]['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:18.224057Z",
     "iopub.status.busy": "2024-05-16T08:38:18.223905Z",
     "iopub.status.idle": "2024-05-16T08:38:18.228037Z",
     "shell.execute_reply": "2024-05-16T08:38:18.227668Z",
     "shell.execute_reply.started": "2024-05-16T08:38:18.224044Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(102400, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-29): 30 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:25.709367Z",
     "iopub.status.busy": "2024-05-16T08:38:25.709034Z",
     "iopub.status.idle": "2024-05-16T08:38:26.061754Z",
     "shell.execute_reply": "2024-05-16T08:38:26.061286Z",
     "shell.execute_reply.started": "2024-05-16T08:38:25.709347Z"
    },
    "id": "MCyxa3p2mJKK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import TrainingArguments\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=128,\n",
    "        lora_dropout=0.05,\n",
    "        r=128,\n",
    "        bias=\"none\",\n",
    "        # target_modules=r\"model\\.layers\\.(0|1|2)\\..*\\..*_proj\", # all-linear \"model.layers.30.mlp.down_proj\" 2 5 8 11 14 17 20 23 26 29 \n",
    "        # target_modules=r\".*\\..*\\..*_proj\", # 好的能用 (0|1|2|3|4|5|6|7|8|9) |1|2|3|4|5|6|7|8|9|10|11|12|13|14\n",
    "        # target_modules=r\"model.embed_tokens\",\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        # modules_to_save=[\"model.embed_tokens\"], 不能加,加了内存爆了\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:30.652185Z",
     "iopub.status.busy": "2024-05-16T08:38:30.651843Z",
     "iopub.status.idle": "2024-05-16T08:38:33.058613Z",
     "shell.execute_reply": "2024-05-16T08:38:33.058151Z",
     "shell.execute_reply.started": "2024-05-16T08:38:30.652167Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(102400, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-29): 30 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (peft_adapter1): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=4096, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=128, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (peft_adapter1): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=4096, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=128, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (peft_adapter1): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=4096, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=128, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (peft_adapter1): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=4096, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=128, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (peft_adapter1): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=4096, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=128, out_features=11008, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (peft_adapter1): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=4096, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=128, out_features=11008, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (peft_adapter1): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=11008, out_features=128, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (peft_adapter1): Linear(in_features=128, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_adapter(peft_config, \"peft_adapter1\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:37.954012Z",
     "iopub.status.busy": "2024-05-16T08:38:37.953687Z",
     "iopub.status.idle": "2024-05-16T08:38:37.961871Z",
     "shell.execute_reply": "2024-05-16T08:38:37.961355Z",
     "shell.execute_reply.started": "2024-05-16T08:38:37.953994Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 299827200 || all params: 4174565376 || trainable%: 7.18\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "     trainable_params = 0\n",
    "     all_param = 0\n",
    "     for _, param in model.named_parameters():\n",
    "         all_param += param.numel()\n",
    "         if param.requires_grad:\n",
    "             trainable_params += param.numel()\n",
    "     print(\n",
    "         f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "     )\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:38:38.615651Z",
     "iopub.status.busy": "2024-05-16T08:38:38.615369Z",
     "iopub.status.idle": "2024-05-16T08:38:38.626947Z",
     "shell.execute_reply": "2024-05-16T08:38:38.626449Z",
     "shell.execute_reply.started": "2024-05-16T08:38:38.615635Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 4174565376\n",
      "Trainable parameters: 299827200\n",
      "Non-trainable parameters: 3874738176\n"
     ]
    }
   ],
   "source": [
    "# 打印总参数数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters: {total_params}')\n",
    "\n",
    "# 打印可训练参数数量\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Trainable parameters: {trainable_params}')\n",
    "\n",
    "# 打印不可训练参数数量\n",
    "non_trainable_params = total_params - trainable_params\n",
    "print(f'Non-trainable parameters: {non_trainable_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:39:36.849047Z",
     "iopub.status.busy": "2024-05-16T08:39:36.848716Z",
     "iopub.status.idle": "2024-05-16T08:39:36.919880Z",
     "shell.execute_reply": "2024-05-16T08:39:36.919445Z",
     "shell.execute_reply.started": "2024-05-16T08:39:36.849027Z"
    },
    "id": "jZCA9nljmJKK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import os\n",
    "#32batch,1e-5,norm 0.03 不收敛\n",
    "#32batch,1e-5,norm 0.1 不收敛\n",
    "#32batch,1e-5,norm 1.0 不收敛\n",
    "#32batch,1e-5,norm 5.0 \n",
    "\n",
    "if isWin:\n",
    "    output_dir = \"I:/kaggle/deepseek-math-7b-it-Train\" + str(shard)\n",
    "    learning_rate=2e-5\n",
    "    g_acc_steps=16\n",
    "    warmup_ratio=0.01\n",
    "    report_to=\"tensorboard\"\n",
    "else:\n",
    "    output_dir = \"/mnt/data/deepseek-math-7b-it-Train\" + str(shard)\n",
    "    learning_rate=1e-6 # when grad is small from 1e-7 to 2e-7 to 5e-7 to 1e-6 to 3e-6 to 1e-5 3e-5 5e-5\n",
    "    g_acc_steps=128 # when grad is smal,from 32 to 128\n",
    "    warmup_ratio=0.05\n",
    "    report_to=\"none\"\n",
    "    \n",
    "train_args = TrainingArguments(\n",
    "    output_dir=output_dir, # directory to save and repository id\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    num_train_epochs=2,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "gradient_accumulation_steps=g_acc_steps,      # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,             # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",                # use fused adamw optimizer\n",
    "    logging_steps=1,                          # log every 10 steps\n",
    "    save_strategy=\"steps\",                    # save checkpoint every   epoch,steps,no\n",
    "    save_steps = 50,\n",
    "    learning_rate=learning_rate,              # learning rate, based on QLoRA paper 1e-4收敛慢,用3e-4\n",
    "    bf16=False,                              # use bfloat16 precision if you have supported GPU\n",
    "    tf32=False,                              # use tf32 precision if you have supported GPU\n",
    "    max_grad_norm=1,                       # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=warmup_ratio,                # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"constant_with_warmup\", # use constant learning rate scheduler\n",
    "    push_to_hub=False,                       # push model to hub\n",
    "    report_to=report_to,                      # report metrics to tensorboard\n",
    "    fp16 = False,                            # 必须不能使用混合精度训练,用了就nan\n",
    "    evaluation_strategy = \"steps\",            # steps / no / epoch\n",
    "eval_steps=len(dataset[\"train\"])//g_acc_steps//7,\n",
    "    per_device_eval_batch_size=1,\n",
    ")\n",
    "\n",
    "if not os.path.exists(train_args.output_dir):\n",
    "    os.makedirs(train_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:39:38.124652Z",
     "iopub.status.busy": "2024-05-16T08:39:38.124363Z",
     "iopub.status.idle": "2024-05-16T08:39:38.246365Z",
     "shell.execute_reply": "2024-05-16T08:39:38.245745Z",
     "shell.execute_reply.started": "2024-05-16T08:39:38.124634Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect(),torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:39:39.238788Z",
     "iopub.status.busy": "2024-05-16T08:39:39.238463Z",
     "iopub.status.idle": "2024-05-16T08:39:39.763329Z",
     "shell.execute_reply": "2024-05-16T08:39:39.762864Z",
     "shell.execute_reply.started": "2024-05-16T08:39:39.238770Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: model.embed_tokens.weight Shape: torch.Size([102400, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -0.00049591064453125, 'max': 4.5, 'min': -4.65625, 'median': -0.00029754638671875, 'variance': 0.03173828125}\n",
      "Name: model.layers.0.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.0.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 8.001355126907583e-06, 'max': 0.015624992549419403, 'min': -0.015624985098838806, 'median': 3.546103835105896e-05, 'variance': 8.150124631356448e-05}\n",
      "Name: model.layers.0.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.0.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.0.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0182457117480226e-06, 'max': 0.015624955296516418, 'min': -0.01562499813735485, 'median': 5.841255187988281e-06, 'variance': 8.161352889146656e-05}\n",
      "Name: model.layers.0.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.0.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.0.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 7.116650976968231e-06, 'max': 0.015624918043613434, 'min': -0.01562497392296791, 'median': 9.113922715187073e-06, 'variance': 8.13682418083772e-05}\n",
      "Name: model.layers.0.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.0.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.0.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.2879201676696539e-05, 'max': 0.015624972060322762, 'min': -0.015624921768903732, 'median': -1.3677403330802917e-05, 'variance': 8.132231596391648e-05}\n",
      "Name: model.layers.0.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.0.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.0.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.3981468732235953e-06, 'max': 0.015624944120645523, 'min': -0.015624957159161568, 'median': 3.734603524208069e-06, 'variance': 8.14705781522207e-05}\n",
      "Name: model.layers.0.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.0.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.0.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.7988109902944416e-05, 'max': 0.015624972060322762, 'min': -0.015624964609742165, 'median': -1.5776604413986206e-05, 'variance': 8.142019942170009e-05}\n",
      "Name: model.layers.0.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.0.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.0.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -5.129150395077886e-06, 'max': 0.00953115988522768, 'min': -0.009531156159937382, 'median': -1.801336111384444e-05, 'variance': 3.0309549401863478e-05}\n",
      "Name: model.layers.0.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.0.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0225830078125, 'max': 0.8203125, 'min': -0.0029754638671875, 'median': 0.0179443359375, 'variance': 0.00124359130859375}\n",
      "Name: model.layers.0.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.05078125, 'max': 0.400390625, 'min': -0.000942230224609375, 'median': 0.046630859375, 'variance': 0.000579833984375}\n",
      "Name: model.layers.1.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.1.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 6.535557076858822e-06, 'max': 0.015624845400452614, 'min': -0.015624772757291794, 'median': -2.0097941160202026e-06, 'variance': 8.142078877426684e-05}\n",
      "Name: model.layers.1.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.1.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.1.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.0676091733330395e-05, 'max': 0.015624990686774254, 'min': -0.015624992549419403, 'median': -2.1260231733322144e-05, 'variance': 8.13354054116644e-05}\n",
      "Name: model.layers.1.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.1.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.1.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 5.668292033078615e-06, 'max': 0.015624798834323883, 'min': -0.015624986961483955, 'median': 1.718662679195404e-05, 'variance': 8.145916217472404e-05}\n",
      "Name: model.layers.1.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.1.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.1.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.9103682663844666e-06, 'max': 0.015624847263097763, 'min': -0.015624981373548508, 'median': -1.8980354070663452e-06, 'variance': 8.132852235576138e-05}\n",
      "Name: model.layers.1.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.1.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.1.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.5024716049083509e-05, 'max': 0.015624964609742165, 'min': -0.015624940395355225, 'median': 1.2218952178955078e-05, 'variance': 8.131279173539951e-05}\n",
      "Name: model.layers.1.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.1.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.1.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.69737369712675e-06, 'max': 0.015624899417161942, 'min': -0.015624986961483955, 'median': 1.3647601008415222e-05, 'variance': 8.141371654346585e-05}\n",
      "Name: model.layers.1.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.1.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.1.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.4994827185764734e-07, 'max': 0.009531158953905106, 'min': -0.009531133808195591, 'median': 1.4657017288755014e-07, 'variance': 3.022616874659434e-05}\n",
      "Name: model.layers.1.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.1.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.04736328125, 'max': 0.375, 'min': -0.000461578369140625, 'median': 0.04248046875, 'variance': 0.000545501708984375}\n",
      "Name: model.layers.1.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.08056640625, 'max': 0.5625, 'min': -0.00130462646484375, 'median': 0.08203125, 'variance': 0.000331878662109375}\n",
      "Name: model.layers.2.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.2.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.2314169907767791e-05, 'max': 0.015624966472387314, 'min': -0.015624981373548508, 'median': 9.952113032341003e-06, 'variance': 8.13872684375383e-05}\n",
      "Name: model.layers.2.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.2.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.2.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.0926051800197456e-05, 'max': 0.015624796971678734, 'min': -0.015624932944774628, 'median': -1.4182180166244507e-05, 'variance': 8.109371265163645e-05}\n",
      "Name: model.layers.2.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.2.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.2.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0272472536598798e-05, 'max': 0.015624988824129105, 'min': -0.015624774619936943, 'median': 3.7979334592819214e-06, 'variance': 8.15599414636381e-05}\n",
      "Name: model.layers.2.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.2.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.2.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.4375510545505676e-05, 'max': 0.015624986961483955, 'min': -0.015624906867742538, 'median': -2.530403435230255e-05, 'variance': 8.13770602690056e-05}\n",
      "Name: model.layers.2.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.2.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.2.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.617652616114356e-06, 'max': 0.015624986961483955, 'min': -0.01562497764825821, 'median': -3.332272171974182e-06, 'variance': 8.148737833835185e-05}\n",
      "Name: model.layers.2.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.2.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.2.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.8001330317929387e-05, 'max': 0.015624918043613434, 'min': -0.015624981373548508, 'median': 2.732500433921814e-05, 'variance': 8.135344251058996e-05}\n",
      "Name: model.layers.2.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.2.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.2.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.1210608995024813e-06, 'max': 0.009531142190098763, 'min': -0.009531145915389061, 'median': 3.1813681289349915e-07, 'variance': 3.0279803468147293e-05}\n",
      "Name: model.layers.2.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.2.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1728515625, 'max': 0.40625, 'min': -0.00848388671875, 'median': 0.171875, 'variance': 0.0002841949462890625}\n",
      "Name: model.layers.2.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0966796875, 'max': 0.1533203125, 'min': -0.0005035400390625, 'median': 0.09912109375, 'variance': 0.00019168853759765625}\n",
      "Name: model.layers.3.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.3.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 5.848033652000595e-06, 'max': 0.015624960884451866, 'min': -0.015624850988388062, 'median': -3.546476364135742e-06, 'variance': 8.13977385405451e-05}\n",
      "Name: model.layers.3.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.3.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.3.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.4082308553042822e-05, 'max': 0.015624996274709702, 'min': -0.01562497578561306, 'median': -4.4889748096466064e-06, 'variance': 8.136707037920132e-05}\n",
      "Name: model.layers.3.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.3.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.3.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -7.418528184643947e-06, 'max': 0.015624906867742538, 'min': -0.01562497764825821, 'median': -7.1302056312561035e-06, 'variance': 8.13407968962565e-05}\n",
      "Name: model.layers.3.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.3.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.3.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.8575217836769298e-05, 'max': 0.015624988824129105, 'min': -0.01562495157122612, 'median': -3.467686474323273e-05, 'variance': 8.112091745715588e-05}\n",
      "Name: model.layers.3.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.3.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.3.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.056338967639022e-06, 'max': 0.015624990686774254, 'min': -0.015624921768903732, 'median': 1.3925135135650635e-05, 'variance': 8.129753405228257e-05}\n",
      "Name: model.layers.3.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.3.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.3.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.513236747996416e-05, 'max': 0.015624986961483955, 'min': -0.015624957159161568, 'median': -2.7492642402648926e-05, 'variance': 8.138545672409236e-05}\n",
      "Name: model.layers.3.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.3.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.3.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -5.8245159380021505e-06, 'max': 0.00953114964067936, 'min': -0.009531122632324696, 'median': -8.403356332564726e-06, 'variance': 3.029107756447047e-05}\n",
      "Name: model.layers.3.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.3.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.16796875, 'max': 0.4296875, 'min': -0.000232696533203125, 'median': 0.166015625, 'variance': 0.000293731689453125}\n",
      "Name: model.layers.3.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.10595703125, 'max': 0.140625, 'min': -0.000629425048828125, 'median': 0.1083984375, 'variance': 0.000156402587890625}\n",
      "Name: model.layers.4.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.4.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.949863184971036e-06, 'max': 0.015624705702066422, 'min': -0.015624990686774254, 'median': -1.0989606380462646e-05, 'variance': 8.146370237227529e-05}\n",
      "Name: model.layers.4.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.4.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.4.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.725655460584676e-06, 'max': 0.01562482863664627, 'min': -0.015624940395355225, 'median': -1.825392246246338e-05, 'variance': 8.141621947288513e-05}\n",
      "Name: model.layers.4.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.4.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.4.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.6759158825152554e-06, 'max': 0.015624968335032463, 'min': -0.01562483049929142, 'median': -2.2295862436294556e-05, 'variance': 8.133820665534586e-05}\n",
      "Name: model.layers.4.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.4.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.4.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.911601313826395e-06, 'max': 0.015624990686774254, 'min': -0.015624936670064926, 'median': 2.4411827325820923e-05, 'variance': 8.148928463924676e-05}\n",
      "Name: model.layers.4.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.4.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.4.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.729836407728726e-06, 'max': 0.015624888241291046, 'min': -0.01562495157122612, 'median': -2.12155282497406e-06, 'variance': 8.140304998960346e-05}\n",
      "Name: model.layers.4.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.4.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.4.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.0270344975870103e-05, 'max': 0.015624947845935822, 'min': -0.015624918043613434, 'median': 3.682635724544525e-05, 'variance': 8.137746044667438e-05}\n",
      "Name: model.layers.4.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.4.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.4.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.252870447387977e-06, 'max': 0.009531154297292233, 'min': -0.009531160816550255, 'median': 5.0276980800845195e-06, 'variance': 3.0290490030893125e-05}\n",
      "Name: model.layers.4.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.4.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.205078125, 'max': 0.4375, 'min': 6.246566772460938e-05, 'median': 0.203125, 'variance': 0.0003490447998046875}\n",
      "Name: model.layers.4.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.11376953125, 'max': 0.1435546875, 'min': -0.000545501708984375, 'median': 0.1162109375, 'variance': 0.00016307830810546875}\n",
      "Name: model.layers.5.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.5.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.338629539939575e-05, 'max': 0.01562490127980709, 'min': -0.015624972060322762, 'median': 5.1157549023628235e-05, 'variance': 8.148424240062013e-05}\n",
      "Name: model.layers.5.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.5.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.5.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.6785732441348955e-05, 'max': 0.015624986961483955, 'min': -0.015624778345227242, 'median': -2.304650843143463e-05, 'variance': 8.133681694744155e-05}\n",
      "Name: model.layers.5.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.5.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.5.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.8286926206201315e-05, 'max': 0.015624931082129478, 'min': -0.015624748542904854, 'median': -2.724863588809967e-05, 'variance': 8.159055141732097e-05}\n",
      "Name: model.layers.5.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.5.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.5.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.955977495526895e-06, 'max': 0.015624931082129478, 'min': -0.015624996274709702, 'median': 2.3096799850463867e-07, 'variance': 8.143073500832543e-05}\n",
      "Name: model.layers.5.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.5.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.5.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.9147197387355845e-06, 'max': 0.015624910593032837, 'min': -0.01562492921948433, 'median': 4.069879651069641e-06, 'variance': 8.131571667036042e-05}\n",
      "Name: model.layers.5.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.5.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.5.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 8.17418458609609e-06, 'max': 0.015624960884451866, 'min': -0.01562497578561306, 'median': 2.3096799850463867e-05, 'variance': 8.147879998432472e-05}\n",
      "Name: model.layers.5.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.5.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.5.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.556457613740349e-06, 'max': 0.009531155228614807, 'min': -0.009531151503324509, 'median': 1.5736410432509729e-06, 'variance': 3.0291606890386902e-05}\n",
      "Name: model.layers.5.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.5.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.197265625, 'max': 0.421875, 'min': 0.00020885467529296875, 'median': 0.1953125, 'variance': 0.0003299713134765625}\n",
      "Name: model.layers.5.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.12255859375, 'max': 0.1650390625, 'min': -0.0011444091796875, 'median': 0.12451171875, 'variance': 0.00011730194091796875}\n",
      "Name: model.layers.6.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.6.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.3719694834435359e-05, 'max': 0.01562495343387127, 'min': -0.015624968335032463, 'median': 2.4760141968727112e-05, 'variance': 8.12537400634028e-05}\n",
      "Name: model.layers.6.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.6.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.6.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.1727419405360706e-05, 'max': 0.015624754130840302, 'min': -0.01562490314245224, 'median': 1.8402934074401855e-05, 'variance': 8.148416964104399e-05}\n",
      "Name: model.layers.6.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.6.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.6.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.1588181223487481e-05, 'max': 0.015624970197677612, 'min': -0.015624957159161568, 'median': -8.035451173782349e-06, 'variance': 8.140837599057704e-05}\n",
      "Name: model.layers.6.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.6.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.6.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.8462188765843166e-06, 'max': 0.015624994412064552, 'min': -0.01562494970858097, 'median': 9.583309292793274e-06, 'variance': 8.143632294377312e-05}\n",
      "Name: model.layers.6.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.6.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.6.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 5.921190222579753e-06, 'max': 0.015624942258000374, 'min': -0.015624983236193657, 'median': 9.059906005859375e-06, 'variance': 8.154461102094501e-05}\n",
      "Name: model.layers.6.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.6.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.6.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 8.223063559853472e-06, 'max': 0.015624959021806717, 'min': -0.015624996274709702, 'median': 2.853013575077057e-05, 'variance': 8.139731653500348e-05}\n",
      "Name: model.layers.6.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.6.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.6.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -7.956163017297513e-07, 'max': 0.009531155228614807, 'min': -0.009531148709356785, 'median': 2.77915228252823e-06, 'variance': 3.0246696042013355e-05}\n",
      "Name: model.layers.6.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.6.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1904296875, 'max': 0.39453125, 'min': -3.0040740966796875e-05, 'median': 0.1884765625, 'variance': 0.0003185272216796875}\n",
      "Name: model.layers.6.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1318359375, 'max': 0.1484375, 'min': -0.0003757476806640625, 'median': 0.134765625, 'variance': 0.00016498565673828125}\n",
      "Name: model.layers.7.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.7.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.47168371870066e-06, 'max': 0.015624996274709702, 'min': -0.015624986961483955, 'median': -7.625669240951538e-06, 'variance': 8.151750080287457e-05}\n",
      "Name: model.layers.7.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.7.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.7.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0511889740882907e-05, 'max': 0.015624864026904106, 'min': -0.015624994412064552, 'median': 1.4575198292732239e-05, 'variance': 8.154629176715389e-05}\n",
      "Name: model.layers.7.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.7.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.7.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -8.611672456027009e-06, 'max': 0.015624932944774628, 'min': -0.015624964609742165, 'median': -1.601874828338623e-06, 'variance': 8.133395022014156e-05}\n",
      "Name: model.layers.7.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.7.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.7.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.390667527331971e-06, 'max': 0.015624931082129478, 'min': -0.015624959021806717, 'median': -1.031532883644104e-05, 'variance': 8.124803571263328e-05}\n",
      "Name: model.layers.7.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.7.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.7.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.7121671994100325e-06, 'max': 0.015624888241291046, 'min': -0.015624996274709702, 'median': 1.4528632164001465e-07, 'variance': 8.14183076727204e-05}\n",
      "Name: model.layers.7.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.7.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.7.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -8.817959496809635e-06, 'max': 0.01562492735683918, 'min': -0.015624990686774254, 'median': -1.002475619316101e-05, 'variance': 8.138360135490075e-05}\n",
      "Name: model.layers.7.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.7.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.7.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.184208547362232e-08, 'max': 0.00953115988522768, 'min': -0.009531158953905106, 'median': -4.27098666477832e-06, 'variance': 3.0302508093882352e-05}\n",
      "Name: model.layers.7.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.7.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.208984375, 'max': 0.4140625, 'min': 0.0001392364501953125, 'median': 0.2060546875, 'variance': 0.000400543212890625}\n",
      "Name: model.layers.7.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.142578125, 'max': 0.1630859375, 'min': 4.112720489501953e-06, 'median': 0.146484375, 'variance': 0.00019359588623046875}\n",
      "Name: model.layers.8.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.8.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.2338701455737464e-05, 'max': 0.015624988824129105, 'min': -0.015624936670064926, 'median': 3.772228956222534e-05, 'variance': 8.127372711896896e-05}\n",
      "Name: model.layers.8.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.8.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.8.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.999089727178216e-05, 'max': 0.01562497764825821, 'min': -0.01562499813735485, 'median': -3.6403536796569824e-05, 'variance': 8.140586578520015e-05}\n",
      "Name: model.layers.8.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.8.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.8.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -5.103614057588857e-06, 'max': 0.015624934807419777, 'min': -0.015624914318323135, 'median': -4.7031790018081665e-06, 'variance': 8.151596557581797e-05}\n",
      "Name: model.layers.8.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.8.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.8.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.271297934290487e-07, 'max': 0.015624921768903732, 'min': -0.015624916180968285, 'median': -4.656612873077393e-06, 'variance': 8.118748519336805e-05}\n",
      "Name: model.layers.8.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.8.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.8.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.7075064533855766e-05, 'max': 0.015624983236193657, 'min': -0.015624966472387314, 'median': 4.0726736187934875e-05, 'variance': 8.146537584252656e-05}\n",
      "Name: model.layers.8.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.8.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.8.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.051971387118101e-05, 'max': 0.015624912455677986, 'min': -0.015624979510903358, 'median': 4.526786506175995e-05, 'variance': 8.151664223987609e-05}\n",
      "Name: model.layers.8.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.8.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.8.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.30550847138511e-06, 'max': 0.009531152434647083, 'min': -0.009531134739518166, 'median': -2.379208808633848e-06, 'variance': 3.0283606974990107e-05}\n",
      "Name: model.layers.8.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.8.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1923828125, 'max': 0.490234375, 'min': -0.000308990478515625, 'median': 0.19140625, 'variance': 0.000392913818359375}\n",
      "Name: model.layers.8.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1484375, 'max': 0.1728515625, 'min': 0.0005340576171875, 'median': 0.1513671875, 'variance': 0.00018405914306640625}\n",
      "Name: model.layers.9.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.9.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.514028710720595e-05, 'max': 0.015624940395355225, 'min': -0.015624944120645523, 'median': -4.5280903577804565e-05, 'variance': 8.151467773132026e-05}\n",
      "Name: model.layers.9.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.9.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.9.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 5.6149774536606856e-06, 'max': 0.015624916180968285, 'min': -0.015624873340129852, 'median': 1.9282102584838867e-05, 'variance': 8.137377153616399e-05}\n",
      "Name: model.layers.9.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.9.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.9.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -8.160623110597953e-06, 'max': 0.015624891966581345, 'min': -0.015624964609742165, 'median': -8.19377601146698e-06, 'variance': 8.122171857394278e-05}\n",
      "Name: model.layers.9.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.9.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.9.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.158755887649022e-05, 'max': 0.015624938532710075, 'min': -0.015624986961483955, 'median': -1.5428289771080017e-05, 'variance': 8.110754424706101e-05}\n",
      "Name: model.layers.9.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.9.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.9.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.823091553087579e-06, 'max': 0.015624754130840302, 'min': -0.01562485657632351, 'median': -2.2165477275848389e-07, 'variance': 8.143365994328633e-05}\n",
      "Name: model.layers.9.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.9.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.9.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -7.694527084822766e-06, 'max': 0.015624798834323883, 'min': -0.015625, 'median': -2.129003405570984e-06, 'variance': 8.156290277838707e-05}\n",
      "Name: model.layers.9.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.9.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.9.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.0632701307476964e-06, 'max': 0.00953114964067936, 'min': -0.009531158953905106, 'median': 7.260336474246287e-07, 'variance': 3.0312765375128947e-05}\n",
      "Name: model.layers.9.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.9.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.2255859375, 'max': 0.50390625, 'min': 0.028564453125, 'median': 0.224609375, 'variance': 0.000507354736328125}\n",
      "Name: model.layers.9.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.15625, 'max': 0.18359375, 'min': 0.000530242919921875, 'median': 0.1591796875, 'variance': 0.00023937225341796875}\n",
      "Name: model.layers.10.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.10.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -9.827863323152997e-06, 'max': 0.015624800696969032, 'min': -0.015624972060322762, 'median': -1.2002885341644287e-05, 'variance': 8.140264981193468e-05}\n",
      "Name: model.layers.10.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.10.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.10.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.6907744540949352e-05, 'max': 0.015624869614839554, 'min': -0.015624936670064926, 'median': 2.4586915969848633e-05, 'variance': 8.145253377733752e-05}\n",
      "Name: model.layers.10.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.10.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.10.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.677754077420104e-06, 'max': 0.015624966472387314, 'min': -0.015624938532710075, 'median': 5.077570676803589e-06, 'variance': 8.140053978422657e-05}\n",
      "Name: model.layers.10.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.10.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.10.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -5.535627678909805e-06, 'max': 0.015624994412064552, 'min': -0.015625, 'median': 1.6409903764724731e-06, 'variance': 8.136538963299245e-05}\n",
      "Name: model.layers.10.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.10.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.10.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.390230388817145e-07, 'max': 0.01562485657632351, 'min': -0.01562497764825821, 'median': -2.450123429298401e-05, 'variance': 8.12568177934736e-05}\n",
      "Name: model.layers.10.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.10.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.10.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.84438884188421e-06, 'max': 0.015624966472387314, 'min': -0.01562478207051754, 'median': 8.143484592437744e-06, 'variance': 8.152661030180752e-05}\n",
      "Name: model.layers.10.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.10.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.10.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 7.802163963788189e-06, 'max': 0.009531156159937382, 'min': -0.009531141258776188, 'median': 1.5363735656137578e-05, 'variance': 3.028932769666426e-05}\n",
      "Name: model.layers.10.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.10.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.2314453125, 'max': 0.5546875, 'min': 0.03857421875, 'median': 0.2314453125, 'variance': 0.000598907470703125}\n",
      "Name: model.layers.10.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.16015625, 'max': 0.189453125, 'min': 0.00811767578125, 'median': 0.1630859375, 'variance': 0.00019550323486328125}\n",
      "Name: model.layers.11.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.11.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.6776113625383005e-05, 'max': 0.015624985098838806, 'min': -0.015624962747097015, 'median': -1.0624527931213379e-05, 'variance': 8.138107659760863e-05}\n",
      "Name: model.layers.11.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.11.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.11.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.3422356864321046e-06, 'max': 0.015624845400452614, 'min': -0.01562497578561306, 'median': -8.491799235343933e-06, 'variance': 8.12232174212113e-05}\n",
      "Name: model.layers.11.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.11.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.11.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 6.822444447607268e-06, 'max': 0.015624882653355598, 'min': -0.015624871477484703, 'median': 3.946945071220398e-06, 'variance': 8.128750050673261e-05}\n",
      "Name: model.layers.11.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.11.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.11.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -8.991299864646862e-07, 'max': 0.01562497578561306, 'min': -0.015624986961483955, 'median': 2.592802047729492e-06, 'variance': 8.13532606116496e-05}\n",
      "Name: model.layers.11.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.11.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.11.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.5535431884927675e-05, 'max': 0.01562482863664627, 'min': -0.015624899417161942, 'median': -2.09026038646698e-05, 'variance': 8.13460283097811e-05}\n",
      "Name: model.layers.11.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.11.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.11.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.6242189303738996e-05, 'max': 0.015624914318323135, 'min': -0.0156248789280653, 'median': 3.579072654247284e-05, 'variance': 8.13379738247022e-05}\n",
      "Name: model.layers.11.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.11.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.11.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -5.775530553364661e-06, 'max': 0.009531152434647083, 'min': -0.009531158953905106, 'median': -8.003413313417695e-06, 'variance': 3.0255150704761036e-05}\n",
      "Name: model.layers.11.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.11.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.2490234375, 'max': 0.52734375, 'min': 0.041015625, 'median': 0.248046875, 'variance': 0.00057220458984375}\n",
      "Name: model.layers.11.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.169921875, 'max': 0.2041015625, 'min': 0.00830078125, 'median': 0.1728515625, 'variance': 0.00030517578125}\n",
      "Name: model.layers.12.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.12.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.5187441022135317e-05, 'max': 0.015624955296516418, 'min': -0.015624964609742165, 'median': 9.004026651382446e-06, 'variance': 8.142739534378052e-05}\n",
      "Name: model.layers.12.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.12.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.12.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.676545358961448e-06, 'max': 0.015624955296516418, 'min': -0.01562490500509739, 'median': -1.599639654159546e-05, 'variance': 8.14280501799658e-05}\n",
      "Name: model.layers.12.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.12.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.12.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -9.186624083667994e-07, 'max': 0.015624947845935822, 'min': -0.015624919906258583, 'median': 1.9710510969161987e-05, 'variance': 8.143371815094724e-05}\n",
      "Name: model.layers.12.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.12.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.12.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.1795449356432073e-06, 'max': 0.01562497392296791, 'min': -0.015624986961483955, 'median': 4.766508936882019e-06, 'variance': 8.134291419992223e-05}\n",
      "Name: model.layers.12.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.12.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.12.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.759551302413456e-06, 'max': 0.01562492921948433, 'min': -0.015624972060322762, 'median': 2.4091452360153198e-05, 'variance': 8.130517380777746e-05}\n",
      "Name: model.layers.12.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.12.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.12.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.554019925417379e-06, 'max': 0.01562480814754963, 'min': -0.01562495157122612, 'median': -7.079914212226868e-06, 'variance': 8.1381578638684e-05}\n",
      "Name: model.layers.12.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.12.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.12.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.193663815181935e-06, 'max': 0.009531155228614807, 'min': -0.009531108662486076, 'median': 8.085219633358065e-06, 'variance': 3.0323055398184806e-05}\n",
      "Name: model.layers.12.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.12.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.2470703125, 'max': 0.55078125, 'min': 0.03271484375, 'median': 0.248046875, 'variance': 0.00080108642578125}\n",
      "Name: model.layers.12.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1748046875, 'max': 0.208984375, 'min': 0.00738525390625, 'median': 0.177734375, 'variance': 0.000293731689453125}\n",
      "Name: model.layers.13.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.13.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0669668881746475e-06, 'max': 0.015624985098838806, 'min': -0.015624994412064552, 'median': -6.556510925292969e-07, 'variance': 8.142016304191202e-05}\n",
      "Name: model.layers.13.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.13.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.13.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.1616224583121948e-05, 'max': 0.015624955296516418, 'min': -0.015624845400452614, 'median': 3.020837903022766e-05, 'variance': 8.135439566103742e-05}\n",
      "Name: model.layers.13.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.13.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.13.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.422955721063772e-06, 'max': 0.01562497578561306, 'min': -0.01562483049929142, 'median': -1.2461096048355103e-05, 'variance': 8.161873847711831e-05}\n",
      "Name: model.layers.13.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.13.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.13.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.9967887055827305e-05, 'max': 0.015624966472387314, 'min': -0.015624981373548508, 'median': 2.971850335597992e-05, 'variance': 8.131874346872792e-05}\n",
      "Name: model.layers.13.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.13.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.13.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.696764113352401e-06, 'max': 0.015624959021806717, 'min': -0.015624979510903358, 'median': 1.2030825018882751e-05, 'variance': 8.140417048707604e-05}\n",
      "Name: model.layers.13.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.13.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.13.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.3882014172850177e-05, 'max': 0.01562492549419403, 'min': -0.015624985098838806, 'median': 2.096220850944519e-05, 'variance': 8.129874913720414e-05}\n",
      "Name: model.layers.13.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.13.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.13.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.937724497722229e-06, 'max': 0.009531158953905106, 'min': -0.009531155228614807, 'median': 6.18435251453775e-06, 'variance': 3.0278477424872108e-05}\n",
      "Name: model.layers.13.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.13.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.26953125, 'max': 0.5703125, 'min': 0.03369140625, 'median': 0.26953125, 'variance': 0.00067138671875}\n",
      "Name: model.layers.13.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1787109375, 'max': 0.2138671875, 'min': 0.01324462890625, 'median': 0.1806640625, 'variance': 0.000263214111328125}\n",
      "Name: model.layers.14.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.14.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.6822431209438946e-07, 'max': 0.015624966472387314, 'min': -0.015624741092324257, 'median': -1.8347054719924927e-06, 'variance': 8.140409045154229e-05}\n",
      "Name: model.layers.14.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.14.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.14.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.1043086892168503e-06, 'max': 0.015624942258000374, 'min': -0.015624996274709702, 'median': 7.78399407863617e-06, 'variance': 8.124813030008227e-05}\n",
      "Name: model.layers.14.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.14.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.14.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.7476901120971888e-05, 'max': 0.01562499813735485, 'min': -0.01562494970858097, 'median': 2.4182721972465515e-05, 'variance': 8.132403308991343e-05}\n",
      "Name: model.layers.14.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.14.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.14.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.3828766896040179e-05, 'max': 0.015624988824129105, 'min': -0.015624992549419403, 'median': 2.734735608100891e-05, 'variance': 8.14153827377595e-05}\n",
      "Name: model.layers.14.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.14.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.14.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.8773876945488155e-05, 'max': 0.015624942258000374, 'min': -0.015624821186065674, 'median': -2.3027881979942322e-05, 'variance': 8.143972809193656e-05}\n",
      "Name: model.layers.14.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.14.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.14.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.3456666238198522e-05, 'max': 0.015624886378645897, 'min': -0.015624959021806717, 'median': 1.0129064321517944e-05, 'variance': 8.129019988700747e-05}\n",
      "Name: model.layers.14.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.14.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.14.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.5900627658993471e-06, 'max': 0.009531157091259956, 'min': -0.009531156159937382, 'median': 1.832695261327899e-06, 'variance': 3.0275716198957525e-05}\n",
      "Name: model.layers.14.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.14.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.2490234375, 'max': 0.58203125, 'min': 0.052001953125, 'median': 0.2490234375, 'variance': 0.000701904296875}\n",
      "Name: model.layers.14.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1845703125, 'max': 0.21875, 'min': 0.0203857421875, 'median': 0.1875, 'variance': 0.0002288818359375}\n",
      "Name: model.layers.15.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.15.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.535650077741593e-06, 'max': 0.015624983236193657, 'min': -0.01562492735683918, 'median': -9.881332516670227e-06, 'variance': 8.136361429933459e-05}\n",
      "Name: model.layers.15.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.15.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.15.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.196647751086857e-06, 'max': 0.015624895691871643, 'min': -0.015624795109033585, 'median': 4.900619387626648e-06, 'variance': 8.146636537276208e-05}\n",
      "Name: model.layers.15.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.15.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.15.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.675234650785569e-06, 'max': 0.01562495343387127, 'min': -0.01562492735683918, 'median': 1.3675540685653687e-05, 'variance': 8.134752715704963e-05}\n",
      "Name: model.layers.15.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.15.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.15.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.828028527801507e-06, 'max': 0.015624979510903358, 'min': -0.015624981373548508, 'median': 1.730024814605713e-05, 'variance': 8.134308882290497e-05}\n",
      "Name: model.layers.15.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.15.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.15.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.1459289453341626e-05, 'max': 0.015624960884451866, 'min': -0.01562499813735485, 'median': 8.27014446258545e-06, 'variance': 8.127155888359994e-05}\n",
      "Name: model.layers.15.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.15.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.15.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.4165550459874794e-06, 'max': 0.01562499813735485, 'min': -0.01562482863664627, 'median': 1.1567026376724243e-06, 'variance': 8.129764319164678e-05}\n",
      "Name: model.layers.15.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.15.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.15.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -7.099236881913384e-06, 'max': 0.009531138464808464, 'min': -0.009531129151582718, 'median': -9.350949767394923e-06, 'variance': 3.0304527172120288e-05}\n",
      "Name: model.layers.15.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.15.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.291015625, 'max': 0.5546875, 'min': 0.04345703125, 'median': 0.29296875, 'variance': 0.000667572021484375}\n",
      "Name: model.layers.15.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.1943359375, 'max': 0.2275390625, 'min': 0.0244140625, 'median': 0.197265625, 'variance': 0.00020694732666015625}\n",
      "Name: model.layers.16.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.16.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.786520442692563e-08, 'max': 0.015624955296516418, 'min': -0.01562490500509739, 'median': -4.798173904418945e-06, 'variance': 8.119668927974999e-05}\n",
      "Name: model.layers.16.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.16.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.16.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.528119461610913e-06, 'max': 0.01562492921948433, 'min': -0.01562495343387127, 'median': 1.3634562492370605e-06, 'variance': 8.1361569755245e-05}\n",
      "Name: model.layers.16.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.16.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.16.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -7.765571353957057e-06, 'max': 0.01562495157122612, 'min': -0.01562482863664627, 'median': 3.0603259801864624e-06, 'variance': 8.14861778053455e-05}\n",
      "Name: model.layers.16.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.16.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.16.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.614386969275074e-06, 'max': 0.01562499813735485, 'min': -0.015624908730387688, 'median': -1.3444572687149048e-05, 'variance': 8.134103700285777e-05}\n",
      "Name: model.layers.16.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.16.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.16.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.5692210581619292e-05, 'max': 0.015624979510903358, 'min': -0.01562490127980709, 'median': -2.771802246570587e-05, 'variance': 8.150591020239517e-05}\n",
      "Name: model.layers.16.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.16.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.16.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.078952643903904e-06, 'max': 0.015624992549419403, 'min': -0.015624886378645897, 'median': 2.6930123567581177e-05, 'variance': 8.121155406115577e-05}\n",
      "Name: model.layers.16.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.16.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.16.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.0772266705316724e-06, 'max': 0.009531151503324509, 'min': -0.00953115988522768, 'median': -9.657725286160712e-07, 'variance': 3.0312117814901285e-05}\n",
      "Name: model.layers.16.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.16.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.302734375, 'max': 0.6015625, 'min': 0.041259765625, 'median': 0.3046875, 'variance': 0.0006103515625}\n",
      "Name: model.layers.16.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.208984375, 'max': 0.2392578125, 'min': 0.03076171875, 'median': 0.2109375, 'variance': 0.00022792816162109375}\n",
      "Name: model.layers.17.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.17.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.6529531421838328e-05, 'max': 0.01562495157122612, 'min': -0.015624862164258957, 'median': -2.2670254111289978e-05, 'variance': 8.152816735673696e-05}\n",
      "Name: model.layers.17.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.17.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.17.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.137649996962864e-05, 'max': 0.015624970197677612, 'min': -0.015624983236193657, 'median': -1.3550743460655212e-05, 'variance': 8.143018931150436e-05}\n",
      "Name: model.layers.17.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.17.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.17.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 5.86762234888738e-06, 'max': 0.01562497392296791, 'min': -0.015624970197677612, 'median': 6.016343832015991e-07, 'variance': 8.135446842061356e-05}\n",
      "Name: model.layers.17.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.17.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.17.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.159002623462584e-06, 'max': 0.015624955296516418, 'min': -0.015624914318323135, 'median': -1.0635703802108765e-06, 'variance': 8.114930096780881e-05}\n",
      "Name: model.layers.17.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.17.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.17.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.280494522390654e-06, 'max': 0.015624944120645523, 'min': -0.015624968335032463, 'median': 5.630776286125183e-06, 'variance': 8.134513336699456e-05}\n",
      "Name: model.layers.17.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.17.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.17.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.9521892681950703e-05, 'max': 0.015624981373548508, 'min': -0.015624986961483955, 'median': 2.100318670272827e-05, 'variance': 8.12946746009402e-05}\n",
      "Name: model.layers.17.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.17.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.17.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.812310867739143e-06, 'max': 0.009531151503324509, 'min': -0.00953114964067936, 'median': 6.921748081367696e-06, 'variance': 3.0259445338742808e-05}\n",
      "Name: model.layers.17.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.17.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.29296875, 'max': 0.60546875, 'min': 0.05126953125, 'median': 0.29296875, 'variance': 0.0004405975341796875}\n",
      "Name: model.layers.17.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.220703125, 'max': 0.251953125, 'min': 0.0235595703125, 'median': 0.2236328125, 'variance': 0.0002231597900390625}\n",
      "Name: model.layers.18.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.18.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.1945930964429863e-05, 'max': 0.015624966472387314, 'min': -0.015624992549419403, 'median': -1.792237162590027e-05, 'variance': 8.150129724526778e-05}\n",
      "Name: model.layers.18.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.18.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.18.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.462884812208358e-06, 'max': 0.015624716877937317, 'min': -0.015624966472387314, 'median': -5.425885319709778e-06, 'variance': 8.142424485413358e-05}\n",
      "Name: model.layers.18.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.18.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.18.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.8300304620643146e-05, 'max': 0.015624957159161568, 'min': -0.015625, 'median': 2.2491440176963806e-05, 'variance': 8.131627691909671e-05}\n",
      "Name: model.layers.18.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.18.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.18.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.536524905532133e-05, 'max': 0.015624875202775002, 'min': -0.01562497764825821, 'median': -1.6847625374794006e-05, 'variance': 8.137274562614039e-05}\n",
      "Name: model.layers.18.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.18.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.18.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -7.689925951126497e-06, 'max': 0.01562488079071045, 'min': -0.015624990686774254, 'median': -6.932765245437622e-06, 'variance': 8.142388105625287e-05}\n",
      "Name: model.layers.18.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.18.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.18.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.3557858437707182e-05, 'max': 0.015624972060322762, 'min': -0.015624994412064552, 'median': 1.167692244052887e-05, 'variance': 8.124221494654194e-05}\n",
      "Name: model.layers.18.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.18.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.18.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.3097259145288263e-06, 'max': 0.009531155228614807, 'min': -0.00953115988522768, 'median': -8.814662578515708e-06, 'variance': 3.0322700695251115e-05}\n",
      "Name: model.layers.18.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.18.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.3046875, 'max': 0.65234375, 'min': 0.050048828125, 'median': 0.3046875, 'variance': 0.0004634857177734375}\n",
      "Name: model.layers.18.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.232421875, 'max': 0.267578125, 'min': 0.0150146484375, 'median': 0.234375, 'variance': 0.000209808349609375}\n",
      "Name: model.layers.19.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.19.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.547865268657915e-06, 'max': 0.015624862164258957, 'min': -0.015624986961483955, 'median': -1.1129304766654968e-05, 'variance': 8.147018525050953e-05}\n",
      "Name: model.layers.19.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.19.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.19.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.3486987629439682e-05, 'max': 0.015624990686774254, 'min': -0.01562494970858097, 'median': -4.404783248901367e-05, 'variance': 8.125878230202943e-05}\n",
      "Name: model.layers.19.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.19.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.19.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -8.627532224636525e-06, 'max': 0.015624873340129852, 'min': -0.015624970197677612, 'median': -6.027519702911377e-06, 'variance': 8.139838610077277e-05}\n",
      "Name: model.layers.19.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.19.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.19.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.7419986761524342e-05, 'max': 0.015624992549419403, 'min': -0.01562492921948433, 'median': -4.036910831928253e-05, 'variance': 8.123312727548182e-05}\n",
      "Name: model.layers.19.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.19.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.19.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.3476965250447392e-05, 'max': 0.015624970197677612, 'min': -0.015624836087226868, 'median': 1.8483027815818787e-05, 'variance': 8.134518429869786e-05}\n",
      "Name: model.layers.19.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.19.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.19.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.409370088367723e-05, 'max': 0.015624871477484703, 'min': -0.015625, 'median': 2.0908191800117493e-05, 'variance': 8.117451216094196e-05}\n",
      "Name: model.layers.19.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.19.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.19.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.261378315575712e-06, 'max': 0.009531136602163315, 'min': -0.009531148709356785, 'median': 3.833548817055998e-06, 'variance': 3.027041384484619e-05}\n",
      "Name: model.layers.19.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.19.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.31640625, 'max': 0.65234375, 'min': 0.04736328125, 'median': 0.314453125, 'variance': 0.0004367828369140625}\n",
      "Name: model.layers.19.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.248046875, 'max': 0.283203125, 'min': 0.0194091796875, 'median': 0.25, 'variance': 0.000225067138671875}\n",
      "Name: model.layers.20.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.20.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 8.778069968684576e-06, 'max': 0.01562495157122612, 'min': -0.015624966472387314, 'median': 1.0866671800613403e-05, 'variance': 8.160835568560287e-05}\n",
      "Name: model.layers.20.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.20.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.20.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0401468898635358e-05, 'max': 0.015624981373548508, 'min': -0.015624959021806717, 'median': 1.9408762454986572e-05, 'variance': 8.133374649332836e-05}\n",
      "Name: model.layers.20.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.20.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.20.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.5645349523983896e-05, 'max': 0.015624962747097015, 'min': -0.015624972060322762, 'median': -4.157610237598419e-05, 'variance': 8.129594789352268e-05}\n",
      "Name: model.layers.20.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.20.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.20.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.601114258344751e-06, 'max': 0.015624962747097015, 'min': -0.01562497392296791, 'median': -4.343688488006592e-06, 'variance': 8.147814514813945e-05}\n",
      "Name: model.layers.20.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.20.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.20.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 5.043220880907029e-06, 'max': 0.015624992549419403, 'min': -0.01562490500509739, 'median': 6.372109055519104e-06, 'variance': 8.123831503326073e-05}\n",
      "Name: model.layers.20.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.20.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.20.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -8.053698365984019e-06, 'max': 0.01562497578561306, 'min': -0.015624968335032463, 'median': -1.1924654245376587e-05, 'variance': 8.140985300997272e-05}\n",
      "Name: model.layers.20.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.20.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.20.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.451634362747427e-06, 'max': 0.009531158953905106, 'min': -0.009531130082905293, 'median': -9.869058885669801e-06, 'variance': 3.0234446967369877e-05}\n",
      "Name: model.layers.20.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.20.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.33203125, 'max': 0.63671875, 'min': 0.046142578125, 'median': 0.33203125, 'variance': 0.000415802001953125}\n",
      "Name: model.layers.20.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.259765625, 'max': 0.296875, 'min': 0.016845703125, 'median': 0.26171875, 'variance': 0.0002803802490234375}\n",
      "Name: model.layers.21.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.21.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.4097909115662333e-05, 'max': 0.015624988824129105, 'min': -0.015624985098838806, 'median': -3.919005393981934e-06, 'variance': 8.129244088195264e-05}\n",
      "Name: model.layers.21.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.21.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.21.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.39350663125515e-07, 'max': 0.015624921768903732, 'min': -0.015625, 'median': -2.1792948246002197e-06, 'variance': 8.131280628731474e-05}\n",
      "Name: model.layers.21.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.21.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.21.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -8.77488582773367e-06, 'max': 0.015624970197677612, 'min': -0.015624959021806717, 'median': -2.7725473046302795e-05, 'variance': 8.152201917255297e-05}\n",
      "Name: model.layers.21.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.21.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.21.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.0066450310405344e-05, 'max': 0.015624914318323135, 'min': -0.015624996274709702, 'median': -6.998702883720398e-05, 'variance': 8.145711763063446e-05}\n",
      "Name: model.layers.21.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.21.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.21.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 8.081929991021752e-06, 'max': 0.015624940395355225, 'min': -0.015624970197677612, 'median': 1.481175422668457e-05, 'variance': 8.153356611728668e-05}\n",
      "Name: model.layers.21.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.21.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.21.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -9.076110472960863e-06, 'max': 0.015624970197677612, 'min': -0.015624981373548508, 'median': -3.4283846616744995e-05, 'variance': 8.139079000102356e-05}\n",
      "Name: model.layers.21.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.21.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.21.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.1924579414189793e-06, 'max': 0.009531154297292233, 'min': -0.009531144052743912, 'median': 2.207642182838754e-06, 'variance': 3.02931457554223e-05}\n",
      "Name: model.layers.21.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.21.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.345703125, 'max': 0.671875, 'min': 0.03857421875, 'median': 0.345703125, 'variance': 0.0004215240478515625}\n",
      "Name: model.layers.21.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.26953125, 'max': 0.29296875, 'min': 0.0203857421875, 'median': 0.2734375, 'variance': 0.000301361083984375}\n",
      "Name: model.layers.22.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.22.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.322013410273939e-06, 'max': 0.01562480628490448, 'min': -0.01562499813735485, 'median': -5.515292286872864e-06, 'variance': 8.151816291501746e-05}\n",
      "Name: model.layers.22.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.22.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.22.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 7.096011358953547e-06, 'max': 0.015624983236193657, 'min': -0.015624994412064552, 'median': -7.495284080505371e-06, 'variance': 8.138436533045024e-05}\n",
      "Name: model.layers.22.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.22.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.22.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.08809285343159e-06, 'max': 0.015624996274709702, 'min': -0.015624957159161568, 'median': 1.3716518878936768e-05, 'variance': 8.114452793961391e-05}\n",
      "Name: model.layers.22.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.22.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.22.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -9.677469279267825e-07, 'max': 0.01562485471367836, 'min': -0.015624959021806717, 'median': 6.081536412239075e-06, 'variance': 8.142049773596227e-05}\n",
      "Name: model.layers.22.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.22.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.22.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.2905284165753983e-05, 'max': 0.01562495157122612, 'min': -0.01562497764825821, 'median': 1.064687967300415e-05, 'variance': 8.154278475558385e-05}\n",
      "Name: model.layers.22.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.22.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.22.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.3060564419429284e-06, 'max': 0.015624968335032463, 'min': -0.015624765306711197, 'median': 2.384185791015625e-07, 'variance': 8.13381266198121e-05}\n",
      "Name: model.layers.22.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.22.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.22.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.6762969557457836e-06, 'max': 0.009531150572001934, 'min': -0.009531154297292233, 'median': -3.170006038999418e-06, 'variance': 3.026514605153352e-05}\n",
      "Name: model.layers.22.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.22.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.349609375, 'max': 0.69140625, 'min': 0.032958984375, 'median': 0.34765625, 'variance': 0.000518798828125}\n",
      "Name: model.layers.22.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.28515625, 'max': 0.3203125, 'min': 0.01519775390625, 'median': 0.287109375, 'variance': 0.000385284423828125}\n",
      "Name: model.layers.23.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.23.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.918433205602923e-06, 'max': 0.01562497392296791, 'min': -0.015624789521098137, 'median': -2.948567271232605e-06, 'variance': 8.148604683810845e-05}\n",
      "Name: model.layers.23.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.23.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.23.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -5.009691449231468e-06, 'max': 0.015624824911355972, 'min': -0.01562495157122612, 'median': -1.0579824447631836e-05, 'variance': 8.153844100888819e-05}\n",
      "Name: model.layers.23.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.23.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.23.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.3106088772474322e-05, 'max': 0.015624890103936195, 'min': -0.015624970197677612, 'median': -2.5644898414611816e-05, 'variance': 8.147203334374353e-05}\n",
      "Name: model.layers.23.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.23.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.23.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -9.279740879719611e-06, 'max': 0.015624988824129105, 'min': -0.015624981373548508, 'median': -2.2748485207557678e-05, 'variance': 8.126949978759512e-05}\n",
      "Name: model.layers.23.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.23.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.23.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.1098592040070798e-05, 'max': 0.01562490127980709, 'min': -0.015624990686774254, 'median': -2.8330832719802856e-06, 'variance': 8.129607158480212e-05}\n",
      "Name: model.layers.23.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.23.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.23.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.117608568776632e-06, 'max': 0.015624957159161568, 'min': -0.015624985098838806, 'median': 1.080147922039032e-05, 'variance': 8.146572508849204e-05}\n",
      "Name: model.layers.23.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.23.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.23.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.5377036106656305e-06, 'max': 0.009531126357614994, 'min': -0.009531157091259956, 'median': -1.9008674598808284e-06, 'variance': 3.026074409717694e-05}\n",
      "Name: model.layers.23.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.23.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.359375, 'max': 0.7265625, 'min': 0.033203125, 'median': 0.35546875, 'variance': 0.0009765625}\n",
      "Name: model.layers.23.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.296875, 'max': 0.32421875, 'min': 0.00095367431640625, 'median': 0.30078125, 'variance': 0.000415802001953125}\n",
      "Name: model.layers.24.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.24.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -5.956024779152358e-06, 'max': 0.015624972060322762, 'min': -0.015624882653355598, 'median': -5.174428224563599e-06, 'variance': 8.125636668410152e-05}\n",
      "Name: model.layers.24.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.24.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.24.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.576144419843331e-06, 'max': 0.015624629333615303, 'min': -0.015624886378645897, 'median': -7.547438144683838e-06, 'variance': 8.128256013151258e-05}\n",
      "Name: model.layers.24.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.24.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.24.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.802572337008314e-06, 'max': 0.015624871477484703, 'min': -0.015624972060322762, 'median': -2.043880522251129e-05, 'variance': 8.148913912009448e-05}\n",
      "Name: model.layers.24.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.24.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.24.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.3317857337824535e-05, 'max': 0.01562497392296791, 'min': -0.01562497578561306, 'median': 2.18171626329422e-05, 'variance': 8.131366485031322e-05}\n",
      "Name: model.layers.24.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.24.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.24.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.2503700165543705e-06, 'max': 0.015624886378645897, 'min': -0.015624994412064552, 'median': -6.12996518611908e-06, 'variance': 8.14692975836806e-05}\n",
      "Name: model.layers.24.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.24.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.24.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.4198983485111967e-06, 'max': 0.015624942258000374, 'min': -0.015624986961483955, 'median': 1.7955899238586426e-06, 'variance': 8.128856279654428e-05}\n",
      "Name: model.layers.24.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.24.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.24.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 3.4558838706288952e-06, 'max': 0.009531154297292233, 'min': -0.009531156159937382, 'median': 3.966484200645937e-06, 'variance': 3.02803200611379e-05}\n",
      "Name: model.layers.24.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.24.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.3671875, 'max': 0.77734375, 'min': 0.0419921875, 'median': 0.365234375, 'variance': 0.00104522705078125}\n",
      "Name: model.layers.24.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.310546875, 'max': 0.3359375, 'min': 0.00439453125, 'median': 0.3125, 'variance': 0.00046539306640625}\n",
      "Name: model.layers.25.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.25.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.075248266919516e-05, 'max': 0.015624921768903732, 'min': -0.015624918043613434, 'median': 2.191774547100067e-05, 'variance': 8.131638605846092e-05}\n",
      "Name: model.layers.25.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.25.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.25.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -6.529094207508024e-07, 'max': 0.015624960884451866, 'min': -0.015624893829226494, 'median': 8.881092071533203e-06, 'variance': 8.136769611155614e-05}\n",
      "Name: model.layers.25.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.25.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.25.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.6925957879720954e-06, 'max': 0.015624921768903732, 'min': -0.01562490127980709, 'median': -9.492039680480957e-06, 'variance': 8.12825164757669e-05}\n",
      "Name: model.layers.25.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.25.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.25.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.0038434993475676e-05, 'max': 0.01562490500509739, 'min': -0.015624886378645897, 'median': -1.8989667296409607e-05, 'variance': 8.133463416015729e-05}\n",
      "Name: model.layers.25.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.25.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.25.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.5532614068361e-06, 'max': 0.01562499813735485, 'min': -0.015624986961483955, 'median': 3.4481287002563477e-05, 'variance': 8.150435314746574e-05}\n",
      "Name: model.layers.25.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.25.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.25.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.5323580505064456e-06, 'max': 0.015624992549419403, 'min': -0.01562492735683918, 'median': -1.9688159227371216e-06, 'variance': 8.137273107422516e-05}\n",
      "Name: model.layers.25.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.25.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.25.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -7.89600562711712e-06, 'max': 0.009531139396131039, 'min': -0.009531160816550255, 'median': -1.1692663974827155e-05, 'variance': 3.0280485589173622e-05}\n",
      "Name: model.layers.25.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.25.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.390625, 'max': 0.765625, 'min': 0.0277099609375, 'median': 0.388671875, 'variance': 0.00103759765625}\n",
      "Name: model.layers.25.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.322265625, 'max': 0.349609375, 'min': 0.000904083251953125, 'median': 0.32421875, 'variance': 0.000484466552734375}\n",
      "Name: model.layers.26.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.26.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -4.679404810303822e-06, 'max': 0.015624988824129105, 'min': -0.015624923631548882, 'median': -2.014264464378357e-05, 'variance': 8.124933810904622e-05}\n",
      "Name: model.layers.26.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.26.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.26.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.832138984056655e-06, 'max': 0.01562497578561306, 'min': -0.01562499813735485, 'median': 2.6028603315353394e-05, 'variance': 8.137482655001804e-05}\n",
      "Name: model.layers.26.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.26.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.26.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0726695109042339e-05, 'max': 0.01562497392296791, 'min': -0.015624968335032463, 'median': 2.0897015929222107e-05, 'variance': 8.123298903228715e-05}\n",
      "Name: model.layers.26.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.26.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.26.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.610950782080181e-06, 'max': 0.01562499813735485, 'min': -0.015624910593032837, 'median': 1.2647360563278198e-05, 'variance': 8.159531716955826e-05}\n",
      "Name: model.layers.26.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.26.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.26.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.9596121748909354e-06, 'max': 0.015624893829226494, 'min': -0.01562490500509739, 'median': 1.1583790183067322e-05, 'variance': 8.141254511428997e-05}\n",
      "Name: model.layers.26.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.26.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.26.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.2955983947904315e-05, 'max': 0.015624985098838806, 'min': -0.015624968335032463, 'median': 3.287196159362793e-05, 'variance': 8.14091763459146e-05}\n",
      "Name: model.layers.26.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.26.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.26.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 2.173575694541796e-06, 'max': 0.009531129151582718, 'min': -0.009531157091259956, 'median': 4.736829851026414e-06, 'variance': 3.02908883895725e-05}\n",
      "Name: model.layers.26.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.26.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.38671875, 'max': 0.8125, 'min': 0.03369140625, 'median': 0.3828125, 'variance': 0.00127410888671875}\n",
      "Name: model.layers.26.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.3359375, 'max': 0.3671875, 'min': 0.000713348388671875, 'median': 0.33984375, 'variance': 0.0004787445068359375}\n",
      "Name: model.layers.27.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.27.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.0429777830722742e-05, 'max': 0.015624990686774254, 'min': -0.01562492735683918, 'median': -1.500733196735382e-05, 'variance': 8.14665763755329e-05}\n",
      "Name: model.layers.27.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.27.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.27.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.2320551832090132e-05, 'max': 0.015624871477484703, 'min': -0.015624817460775375, 'median': 1.749582588672638e-05, 'variance': 8.118045661831275e-05}\n",
      "Name: model.layers.27.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.27.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.27.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.5441914001712576e-05, 'max': 0.015624942258000374, 'min': -0.015624992549419403, 'median': -1.4005228877067566e-05, 'variance': 8.145051106112078e-05}\n",
      "Name: model.layers.27.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.27.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.27.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.8881066353060305e-05, 'max': 0.015624996274709702, 'min': -0.015624964609742165, 'median': -1.8503516912460327e-05, 'variance': 8.12826183391735e-05}\n",
      "Name: model.layers.27.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.27.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.27.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.1744674338842742e-05, 'max': 0.015624940395355225, 'min': -0.01562499813735485, 'median': 9.601935744285583e-06, 'variance': 8.131900540320203e-05}\n",
      "Name: model.layers.27.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.27.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.27.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0202621524513233e-05, 'max': 0.015624908730387688, 'min': -0.015624983236193657, 'median': 8.732080459594727e-06, 'variance': 8.130483911372721e-05}\n",
      "Name: model.layers.27.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.27.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.27.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.969226104847621e-06, 'max': 0.009531144984066486, 'min': -0.009531156159937382, 'median': 1.7361180653097108e-06, 'variance': 3.0303539460874163e-05}\n",
      "Name: model.layers.27.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.27.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.39453125, 'max': 0.80078125, 'min': 0.048828125, 'median': 0.390625, 'variance': 0.00144195556640625}\n",
      "Name: model.layers.27.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.3515625, 'max': 0.376953125, 'min': 0.019775390625, 'median': 0.353515625, 'variance': 0.000446319580078125}\n",
      "Name: model.layers.28.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.28.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.6528556443518028e-06, 'max': 0.0156248789280653, 'min': -0.015624945983290672, 'median': -2.086162567138672e-06, 'variance': 8.150609210133553e-05}\n",
      "Name: model.layers.28.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.28.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.28.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.0346766430302523e-06, 'max': 0.015624994412064552, 'min': -0.015624996274709702, 'median': 4.973262548446655e-06, 'variance': 8.133591472869739e-05}\n",
      "Name: model.layers.28.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.28.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.28.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -2.0622474039555527e-06, 'max': 0.015624966472387314, 'min': -0.015624985098838806, 'median': 1.0682269930839539e-05, 'variance': 8.127940964186564e-05}\n",
      "Name: model.layers.28.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.28.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.28.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 9.30838041313109e-07, 'max': 0.015624957159161568, 'min': -0.015624972060322762, 'median': -7.450580596923828e-09, 'variance': 8.118203550111502e-05}\n",
      "Name: model.layers.28.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.28.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.28.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 6.378921170835383e-06, 'max': 0.015624996274709702, 'min': -0.015625, 'median': 9.704381227493286e-06, 'variance': 8.133676601573825e-05}\n",
      "Name: model.layers.28.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.28.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.28.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.280757896893192e-05, 'max': 0.015624996274709702, 'min': -0.015624988824129105, 'median': 1.736357808113098e-05, 'variance': 8.161824371200055e-05}\n",
      "Name: model.layers.28.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.28.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.28.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.7727173826642684e-06, 'max': 0.009531151503324509, 'min': -0.009531114250421524, 'median': 6.635424938394863e-07, 'variance': 3.026959348062519e-05}\n",
      "Name: model.layers.28.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.28.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.39453125, 'max': 0.78515625, 'min': 0.061767578125, 'median': 0.392578125, 'variance': 0.001007080078125}\n",
      "Name: model.layers.28.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.369140625, 'max': 0.6328125, 'min': 0.0030975341796875, 'median': 0.37109375, 'variance': 0.0003948211669921875}\n",
      "Name: model.layers.29.self_attn.q_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.29.self_attn.q_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 4.792043910128996e-06, 'max': 0.015624994412064552, 'min': -0.015624899417161942, 'median': 9.071081876754761e-07, 'variance': 8.150818757712841e-05}\n",
      "Name: model.layers.29.self_attn.q_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.29.self_attn.k_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.29.self_attn.k_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.171306757896673e-05, 'max': 0.01562497578561306, 'min': -0.015624890103936195, 'median': -3.2028183341026306e-05, 'variance': 8.128420449793339e-05}\n",
      "Name: model.layers.29.self_attn.k_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.29.self_attn.v_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.29.self_attn.v_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -1.916887231345754e-05, 'max': 0.01562497764825821, 'min': -0.015624932944774628, 'median': -1.7346814274787903e-05, 'variance': 8.138992416206747e-05}\n",
      "Name: model.layers.29.self_attn.v_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.29.self_attn.o_proj.base_layer.weight Shape: torch.Size([8388608, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.29.self_attn.o_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -3.110462785116397e-06, 'max': 0.015624986961483955, 'min': -0.015624972060322762, 'median': 2.812594175338745e-07, 'variance': 8.138703560689464e-05}\n",
      "Name: model.layers.29.self_attn.o_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.29.mlp.gate_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.29.mlp.gate_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.019310366245918e-05, 'max': 0.015624960884451866, 'min': -0.01562497578561306, 'median': 2.220645546913147e-05, 'variance': 8.156947296811268e-05}\n",
      "Name: model.layers.29.mlp.gate_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.29.mlp.up_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.29.mlp.up_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 1.1240565982006956e-05, 'max': 0.015624826774001122, 'min': -0.015625, 'median': 8.247792720794678e-06, 'variance': 8.126270404318348e-05}\n",
      "Name: model.layers.29.mlp.up_proj.lora_B.peft_adapter1.weight Shape: torch.Size([11008, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.29.mlp.down_proj.base_layer.weight Shape: torch.Size([22544384, 1]) Type: <class 'bitsandbytes.nn.modules.Params4bit'>\n",
      "Name: model.layers.29.mlp.down_proj.lora_A.peft_adapter1.weight Shape: torch.Size([128, 11008]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': -9.054776910488727e-07, 'max': 0.009531150572001934, 'min': -0.009531151503324509, 'median': -3.915355136996368e-06, 'variance': 3.0234870791900903e-05}\n",
      "Name: model.layers.29.mlp.down_proj.lora_B.peft_adapter1.weight Shape: torch.Size([4096, 128]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0, 'max': 0.0, 'min': 0.0, 'median': 0.0, 'variance': 0.0}\n",
      "Name: model.layers.29.input_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.3828125, 'max': 0.70703125, 'min': 0.05126953125, 'median': 0.390625, 'variance': 0.00159454345703125}\n",
      "Name: model.layers.29.post_attention_layernorm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.35546875, 'max': 0.419921875, 'min': 0.041015625, 'median': 0.361328125, 'variance': 0.00091552734375}\n",
      "Name: model.norm.weight Shape: torch.Size([4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.294921875, 'max': 0.44140625, 'min': -0.003936767578125, 'median': 0.298828125, 'variance': 0.00060272216796875}\n",
      "Name: lm_head.weight Shape: torch.Size([102400, 4096]) Type: <class 'torch.nn.parameter.Parameter'> {'mean': 0.0026092529296875, 'max': 6.65625, 'min': -7.78125, 'median': 0.0031890869140625, 'variance': 0.0546875}\n",
      "参数可导信息已保存到 /mnt/data/deepseek-math-7b-it-Train10/model_parameters.json 文件中。\n"
     ]
    }
   ],
   "source": [
    "param_dict = {}\n",
    "param_stats = {}\n",
    "import json\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param_dict[name] = {'requires_grad': param.requires_grad}\n",
    "    if param.dtype not in [torch.uint8]:\n",
    "        param_stats[name] = {\n",
    "        'mean': torch.mean(param).item(),\n",
    "        'max': torch.max(param).item(),\n",
    "        'min': torch.min(param).item(),\n",
    "        'median': torch.median(param).item(),\n",
    "        'variance': torch.var(param).item(),\n",
    "#         '25th percentile': torch.quantile(param.to(torch.float32), 0.25),\n",
    "#         '75th percentile': torch.quantile(param.to(torch.float32), 0.75)\n",
    "        }\n",
    "        print(f\"Name: {name}\", f\"Shape: {param.shape}\", f\"Type: {type(param)}\", param_stats[name])\n",
    "    else:\n",
    "        print(f\"Name: {name}\", f\"Shape: {param.shape}\", f\"Type: {type(param)}\")\n",
    "    \n",
    "json_str = json.dumps(param_dict)\n",
    "with open(train_args.output_dir + '/model_parameters.json', 'w') as f:\n",
    "    f.write(json_str)\n",
    "\n",
    "print(\"参数可导信息已保存到 \"+ train_args.output_dir + \"/model_parameters.json 文件中。\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "param_dict = {}\n",
    "\n",
    "with open(train_args.output_dir + '/model_parameters.json', 'r') as file:  \n",
    "    param_dict = json.load(file)  \n",
    "\n",
    "print(param_dict),gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:39:40.527728Z",
     "iopub.status.busy": "2024-05-16T08:39:40.527336Z",
     "iopub.status.idle": "2024-05-16T08:39:40.549349Z",
     "shell.execute_reply": "2024-05-16T08:39:40.548821Z",
     "shell.execute_reply.started": "2024-05-16T08:39:40.527710Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: model.embed_tokens ,Weight Shape: torch.Size([102400, 4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.0.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.0.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.1.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.1.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.2.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.2.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.3.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.3.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.4.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.4.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.5.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.5.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.6.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.6.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.7.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.7.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.8.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.8.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.9.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.9.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.10.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.10.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.11.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.11.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.12.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.12.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.13.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.13.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.14.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.14.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.15.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.15.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.16.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.16.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.17.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.17.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.18.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.18.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.19.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.19.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.20.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.20.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.21.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.21.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.22.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.22.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.23.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.23.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.24.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.24.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.25.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.25.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.26.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.26.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.27.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.27.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.28.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.28.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.q_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.q_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.q_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.self_attn.q_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.self_attn.k_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.k_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.k_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.self_attn.k_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.self_attn.v_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.v_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.v_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.self_attn.v_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.self_attn.o_proj ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.o_proj.base_layer ,Weight Shape: torch.Size([8388608, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.self_attn.o_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.self_attn.o_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.mlp.gate_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.mlp.gate_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.mlp.gate_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.mlp.gate_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.mlp.up_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.mlp.up_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.mlp.up_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 4096]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.mlp.up_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([11008, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.mlp.down_proj ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.mlp.down_proj.base_layer ,Weight Shape: torch.Size([22544384, 1]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.mlp.down_proj.lora_A.peft_adapter1 ,Weight Shape: torch.Size([128, 11008]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.mlp.down_proj.lora_B.peft_adapter1 ,Weight Shape: torch.Size([4096, 128]) ,Weight requires_grad: True\n",
      "Layer Name: model.layers.29.input_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.layers.29.post_attention_layernorm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: model.norm ,Weight Shape: torch.Size([4096]) ,Weight requires_grad: False\n",
      "Layer Name: lm_head ,Weight Shape: torch.Size([102400, 4096]) ,Weight requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "for name, layer in model.named_modules():\n",
    "    if hasattr(layer, 'weight'):\n",
    "        print(f\"Layer Name: {name}\", f\",Weight Shape: {layer.weight.shape}\", f\",Weight requires_grad: {layer.weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:39:40.959475Z",
     "iopub.status.busy": "2024-05-16T08:39:40.959136Z",
     "iopub.status.idle": "2024-05-16T08:39:40.976736Z",
     "shell.execute_reply": "2024-05-16T08:39:40.976205Z",
     "shell.execute_reply.started": "2024-05-16T08:39:40.959459Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5653,  0.0944,  1.0561, -0.5761, -2.2156],\n",
      "        [-0.7554,  0.4029,  2.0111,  0.5498, -0.0501],\n",
      "        [-1.3394, -0.7353, -1.7051,  0.4580,  0.2896]], requires_grad=True)\n",
      "tensor([1, 3, 0])\n",
      "tensor(2.1309, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, tensor([1, 3, 0]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "print(target)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(loss)\n",
    "loss.backward(), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:39:47.705709Z",
     "iopub.status.busy": "2024-05-16T08:39:47.705384Z",
     "iopub.status.idle": "2024-05-16T08:39:47.712467Z",
     "shell.execute_reply": "2024-05-16T08:39:47.711974Z",
     "shell.execute_reply.started": "2024-05-16T08:39:47.705690Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits tensor([[[ 0.2853, -0.2949,  0.7317, -0.1566,  0.1362]],\n",
      "\n",
      "        [[-0.9048, -1.2314,  1.2278,  1.1932,  0.3981]],\n",
      "\n",
      "        [[ 0.2849,  0.2155,  0.2127,  0.0457,  0.4772]],\n",
      "\n",
      "        [[ 1.7091, -0.8062, -0.2040, -1.2841,  0.7576]],\n",
      "\n",
      "        [[ 0.6326,  1.2340,  0.5028,  0.0084, -0.5258]],\n",
      "\n",
      "        [[-0.7823, -1.1374,  0.7112, -0.5984, -0.9900]],\n",
      "\n",
      "        [[-0.8388, -1.0517,  1.6804,  0.5339, -0.3498]],\n",
      "\n",
      "        [[-0.8874,  0.2125, -1.6582, -0.4181, -0.7699]],\n",
      "\n",
      "        [[ 0.4796, -2.3274,  0.9537, -0.2509, -0.5704]],\n",
      "\n",
      "        [[-1.5211, -1.5746,  0.3632,  2.0650, -1.1210]]], requires_grad=True)\n",
      "targets tensor([[1, 3, 4, 1, 0, 4, 4, 3]])\n",
      "logits.log_softmax(2) tensor([[[0.2161, 0.1210, 0.3377, 0.1389, 0.1862]],\n",
      "\n",
      "        [[0.0455, 0.0328, 0.3837, 0.3707, 0.1674]],\n",
      "\n",
      "        [[0.2057, 0.1919, 0.1913, 0.1619, 0.2493]],\n",
      "\n",
      "        [[0.6007, 0.0486, 0.0887, 0.0301, 0.2320]],\n",
      "\n",
      "        [[0.2197, 0.4008, 0.1929, 0.1177, 0.0690]],\n",
      "\n",
      "        [[0.1224, 0.0858, 0.5451, 0.1471, 0.0995]],\n",
      "\n",
      "        [[0.0505, 0.0408, 0.6271, 0.1993, 0.0823]],\n",
      "\n",
      "        [[0.1391, 0.4178, 0.0643, 0.2224, 0.1564]],\n",
      "\n",
      "        [[0.2858, 0.0173, 0.4592, 0.1377, 0.1000]],\n",
      "\n",
      "        [[0.0217, 0.0206, 0.1427, 0.7827, 0.0324]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "CTC Loss: 1.7672935724258423\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# logits 是模型的输出，形状为 (max_seq_length, batch_size, num_classes)\n",
    "# targets 是真实的标签序列，形状为 (batch_size, target_length)\n",
    "# input_lengths 是每个样本在 logits 中的有效序列长度\n",
    "# target_lengths 是每个样本在 targets 中的有效序列长度\n",
    "batch_size = 1\n",
    "max_seq_length = 10\n",
    "num_classes = 5\n",
    "target_length = 8\n",
    "\n",
    "logits = torch.randn(max_seq_length, batch_size, num_classes, requires_grad=True)\n",
    "print(\"logits\", logits)\n",
    "targets = torch.randint(0, num_classes, (batch_size, target_length), dtype=torch.long)\n",
    "print(\"targets\", targets)\n",
    "\n",
    "input_lengths = (max_seq_length, )\n",
    "target_lengths = (target_length, )\n",
    "# 创建 CTCLoss 实例\n",
    "ctc_loss = nn.CTCLoss(zero_infinity=True)\n",
    "print(\"logits.log_softmax(2)\", logits.softmax(2))\n",
    "# 计算损失\n",
    "loss = ctc_loss(logits.log_softmax(2), targets, input_lengths, target_lengths,)\n",
    "\n",
    "# 打印损失\n",
    "print(f\"CTC Loss: {loss.item()}\")\n",
    "# 反向传播\n",
    "# optimizer = optim.Adam([logits])\n",
    "# optimizer.zero_grad()\n",
    "# loss.backward()\n",
    "# # 更新权重\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:45:56.406826Z",
     "iopub.status.busy": "2024-04-23T06:45:56.406534Z",
     "iopub.status.idle": "2024-04-23T06:45:59.954495Z",
     "shell.execute_reply": "2024-04-23T06:45:59.954027Z",
     "shell.execute_reply.started": "2024-04-23T06:45:56.406803Z"
    },
    "tags": []
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:25.721268Z",
     "iopub.status.busy": "2024-05-16T08:40:25.720932Z",
     "iopub.status.idle": "2024-05-16T08:40:25.725897Z",
     "shell.execute_reply": "2024-05-16T08:40:25.725419Z",
     "shell.execute_reply.started": "2024-05-16T08:40:25.721243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class SaveTrainingRecordCallback(TrainerCallback):\n",
    "    inputs = {}\n",
    "    \n",
    "    def on_step_end(self, args, state, control, **kwargs): \n",
    "        # print(\"on_step_end state\", state)\n",
    "        epoch = state.epoch\n",
    "        global_step = state.global_step\n",
    "        \n",
    "        if len(state.log_history) > 0 and state.log_history[-1].get(\"loss\") is not None:\n",
    "            loss = state.log_history[-1][\"loss\"]\n",
    "            grad_norm = state.log_history[-1][\"grad_norm\"]\n",
    "            learning_rate = state.log_history[-1][\"learning_rate\"]\n",
    "\n",
    "            if epoch > 0. and (loss > -1000.  or grad_norm > 0.01):#epoch>0.5 and (loss>-0.95 or grad_norm>0.15) | epoch>1. and (loss>-0.95 or grad_norm>0.09)\n",
    "                with open('largeLossRecords.deepseekmath.MetaMathQA' + str(shard) + '.json', 'a') as f:\n",
    "                    aim = {\"input_ids\" : SaveTrainingRecordCallback.inputs[\"input_ids\"].flatten().tolist(), \n",
    "                           \"labels\" : SaveTrainingRecordCallback.inputs[\"labels\"].flatten().tolist(), \"learning_rate\" : learning_rate, \n",
    "                           \"global_step\" : global_step, \"loss\" : loss, \"grad_norm\" : grad_norm, \"epoch\" : epoch}\n",
    "                    json.dump(aim, f)\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:26.297068Z",
     "iopub.status.busy": "2024-05-16T08:40:26.296748Z",
     "iopub.status.idle": "2024-05-16T08:40:26.301637Z",
     "shell.execute_reply": "2024-05-16T08:40:26.301223Z",
     "shell.execute_reply.started": "2024-05-16T08:40:26.297050Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6073, 0.8622]],\n",
       " \n",
       "         [[0.2123, 0.2941]],\n",
       " \n",
       "         [[0.3173, 0.2973]]]),\n",
       " torch.Size([3, 1, 2]),\n",
       " 3,\n",
       " torch.Size([3, 1, 2, 1]),\n",
       " 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "a=torch.rand(3,1,2)\n",
    "b = a.unsqueeze(-1)\n",
    "a,a.shape,len(a),b.shape,len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:27.150150Z",
     "iopub.status.busy": "2024-05-16T08:40:27.149828Z",
     "iopub.status.idle": "2024-05-16T08:40:27.154669Z",
     "shell.execute_reply": "2024-05-16T08:40:27.154267Z",
     "shell.execute_reply.started": "2024-05-16T08:40:27.150133Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6700/1624711620.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(torch.tensor([0.,0.,0.,1]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1749, 0.1749, 0.1749, 0.4754])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.softmax(torch.tensor([0.,0.,0.,1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-14T14:13:31.976126Z",
     "iopub.status.busy": "2024-05-14T14:13:31.975956Z",
     "iopub.status.idle": "2024-05-14T14:13:31.984887Z",
     "shell.execute_reply": "2024-05-14T14:13:31.984453Z",
     "shell.execute_reply.started": "2024-05-14T14:13:31.976111Z"
    },
    "tags": []
   },
   "source": [
    "from dataclasses import dataclass, field\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@dataclass\n",
    "class LabelSmoother:\n",
    "    \"\"\"\n",
    "    Adds label-smoothing on a pre-computed output from a Transformers model.\n",
    "    Args:\n",
    "        epsilon (`float`, *optional*, defaults to 0.1):\n",
    "            The label smoothing factor.\n",
    "        ignore_index (`int`, *optional*, defaults to -100):\n",
    "            The index in the labels to ignore when computing the loss.\n",
    "    \"\"\"\n",
    "    epsilon: float = 0.1\n",
    "    ignore_index: int = -100\n",
    "\n",
    "    def __call__(self, model_output, labels, shift_labels=False):\n",
    "        logits = model_output[\"logits\"] if isinstance(model_output, dict) else model_output[0]\n",
    "        # if shift_labels:\n",
    "        #     logits = logits[:-1, ..., :].contiguous()\n",
    "        #     labels = labels[1:, ...].contiguous()\n",
    "\n",
    "        log_probs = -nn.functional.softmax(logits, dim=-1) # log_softmax\n",
    "        \n",
    "        # labels.shape in LabelSmoother torch.Size([142, 1]) log_probs.shape torch.Size([107, 1, 32000])\n",
    "        # print(\"labels.shape in LabelSmoother\", labels.shape, \"log_probs.shape\", log_probs.shape, \"labels[1]\", labels[1])\n",
    "\n",
    "        logits_squeezed = log_probs.squeeze(1)  # logits的形状现在是[316, 32000]\n",
    "        labels_squeezed = labels.squeeze(1)  # labels的形状现在是[438]\n",
    "        # print(\"labels_squeezed.shape in LabelSmoother\", labels_squeezed.shape, \"logits_squeezed.shape\", logits_squeezed.shape)\n",
    "        # print(\"logits_squeezed[0]\", logits_squeezed[0], \"torch.sum(logits_squeezed[0])\", torch.sum(logits_squeezed[0]))\n",
    "\n",
    "        \n",
    "        # 确定新的第一个维度大小  填充的方法内存爆了 .最多填充到500, 再长内存爆了\n",
    "        new_first_dim = max(logits_squeezed.shape[0], labels_squeezed.shape[0])\n",
    "        # 计算logits需要在第一个维度上填充的大小  \n",
    "        padding_size_logits = new_first_dim - logits_squeezed.shape[0]  \n",
    "        if padding_size_logits > 0 :\n",
    "            # 使用pad函数在logits的第一个维度上进行填充，填充值为0（或其他合适的值）  \n",
    "            padding_logits = [0, 0, 0, padding_size_logits]   \n",
    "            padded_logits = F.pad(logits_squeezed, padding_logits, mode='constant', value=0)\n",
    "            # 调整padded_logits的形状以匹配所需维度[438, 32000]  \n",
    "            padded_logits = padded_logits.view(new_first_dim, -1)  \n",
    "        else:\n",
    "            padded_logits = logits_squeezed[:new_first_dim, :]\n",
    "        padding_size = new_first_dim - labels_squeezed.shape[0]  \n",
    "        if padding_size > 0:\n",
    "            padding_labels = [0, padding_size]  \n",
    "            padded_labels = F.pad(labels_squeezed, padding_labels, mode='constant', value=0)\n",
    "            padded_labels = padded_labels.view(new_first_dim)\n",
    "        else:\n",
    "            padded_labels = labels_squeezed[:new_first_dim]\n",
    "\n",
    "        \n",
    "        \n",
    "        B = torch.arange(2000, 2000 - padded_labels.shape[0], -1).to(\"cuda\")/2000.\n",
    "        B = B.unsqueeze(-1)\n",
    "        # print(\"B.shape\", B.shape, \"B[1]\", B[1]) # [141,1]\n",
    "\n",
    "        \n",
    "        if padded_labels.dim() == padded_logits.dim() - 1:\n",
    "            padded_labels = padded_labels.unsqueeze(-1)\n",
    "\n",
    "        \n",
    "        padded_labels = torch.clamp(padded_labels, min=0) # [141,1]\n",
    "        nll_loss = padded_logits.gather(dim=-1, index=padded_labels) # nll_loss[141,1]\n",
    "        # print(\"nll_loss\", nll_loss)\n",
    "        nll_loss = torch.mul(nll_loss, B)\n",
    "        \n",
    "        # works for fp16 input tensor too, by internally upcasting it to fp32\n",
    "        # smoothed_loss = padded_logits.sum(dim=-1, keepdim=True, dtype=torch.float32) # [141,1]\n",
    "        # print(\"smoothed_loss\", smoothed_loss)\n",
    "        # smoothed_loss = torch.mul(smoothed_loss, B)\n",
    "        # nll_loss.masked_fill_(padding_mask, 0.0)\n",
    "        # smoothed_loss.masked_fill_(padding_mask, 0.0)\n",
    "        \n",
    "        padding_mask = padded_labels.eq(0) # [141,1]\n",
    "        \n",
    "        # print(\"padded_labels.shape\", padded_labels.shape, \"padded_logits.shape\", \n",
    "              # padded_logits.shape, \"nll_loss.shape\", nll_loss.shape, \"padding_mask.shape\", padding_mask.shape)\n",
    "              # \"smoothed_loss.shape\", smoothed_loss.shape)\n",
    "        \n",
    "        # Take the mean over the label dimensions, then divide by the number of active elements (i.e. not-padded):\n",
    "        num_active_elements = padding_mask.numel() - padding_mask.long().sum()\n",
    "        num_active_elements = max(num_active_elements, 10)\n",
    "        \n",
    "        # print(\"num_active_elements\", num_active_elements)\n",
    "        nll_loss = nll_loss.sum() / num_active_elements\n",
    "        # smoothed_loss = smoothed_loss.sum() / (num_active_elements * padded_logits.shape[-1])\n",
    "        # print(\"(1-self.epsilon)*nll_loss\",((1-self.epsilon)*nll_loss).item(),)#\"self.epsilon*smoothed_loss/100.\", (self.epsilon*smoothed_loss).item()/100.,\"\\n\")\n",
    "\n",
    "        loss = (1 - self.epsilon) * nll_loss / 1. * 2000 #  when grad is small, from /20 to * 100 # + self.epsilon * smoothed_loss /100,this is no use,constant -1\n",
    "        \n",
    "        \n",
    "        if CustomTrainer.counter % train_args.gradient_accumulation_steps == 0:\n",
    "            grad_norms = [torch.norm(grad) for grad in model.parameters() if grad is not None and grad.dtype not in [torch.uint8] and grad.requires_grad]\n",
    "            mean_grad_norm = torch.mean(torch.stack(grad_norms))\n",
    "            loss=loss + mean_grad_norm / 10000.\n",
    "            print(\"custom_loss_function steps:\", CustomTrainer.counter, \"output dim:\", new_first_dim, \"loss:\", loss.item(), \"Mean Grad Norm:\", mean_grad_norm.item(),)\n",
    "            \n",
    "        CustomTrainer.counter = CustomTrainer.counter + 1\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "label_smoother = LabelSmoother(epsilon=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:27.802157Z",
     "iopub.status.busy": "2024-05-16T08:40:27.801827Z",
     "iopub.status.idle": "2024-05-16T08:40:27.813316Z",
     "shell.execute_reply": "2024-05-16T08:40:27.812881Z",
     "shell.execute_reply.started": "2024-05-16T08:40:27.802138Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    counter = 0\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        SaveTrainingRecordCallback.inputs = inputs\n",
    "        \n",
    "        if \"labels\" in inputs:\n",
    "            labels = inputs[\"labels\"]\n",
    "        else:\n",
    "            labels = None\n",
    "        outputs = model(**inputs)\n",
    "        # print(\"in compute_loss, labels.shape\",labels.shape, \"outputs['logits'].shape\", outputs['logits'].shape)\n",
    "        # Save past state if it exists   # TODO: this needs to be fixed and made cleaner later.\n",
    "        # if self.args.past_index >= 0:\n",
    "        #     self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if labels is not None and outputs[\"logits\"] is not None and len(outputs[\"logits\"]) > 0 and len(labels) > 0:\n",
    "            # loss = label_smoother(outputs, labels, shift_labels=False)\n",
    "            # loss = self.blend_loss( outputs[\"logits\"], labels, len(inputs[\"labels\"]), doPrint=True )\n",
    "            # print(\"outputs['logits'].shape\", outputs['logits'].shape, \"labels.shape\", labels.shape, \"outputs['logits'].softmax(2)\", outputs[\"logits\"].softmax(2))\n",
    "            loss = ctc_loss(outputs[\"logits\"].log_softmax(2), labels.view(1,-1), (len(inputs[\"input_ids\"]),), (len(inputs[\"labels\"]),))\n",
    "            new_first_dim = max(len(inputs[\"input_ids\"]), len(inputs[\"labels\"]))\n",
    "        else:\n",
    "            if isinstance(outputs, dict) and \"loss\" not in outputs:\n",
    "                return 0.\n",
    "                # raise ValueError(\n",
    "                #     \"The model did not return a loss from the inputs, only the following keys: \"\n",
    "                #     f\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\n",
    "                # )\n",
    "            loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "        if CustomTrainer.counter % train_args.gradient_accumulation_steps == 0:\n",
    "            grad_norms = [torch.norm(grad) for grad in model.parameters() if grad is not None and grad.dtype not in [torch.uint8] and grad.requires_grad]\n",
    "            mean_grad_norm = torch.mean(torch.stack(grad_norms))\n",
    "            loss=loss + mean_grad_norm / 10000.\n",
    "            print(\"custom_loss_function steps:\", CustomTrainer.counter, \"output dim:\", new_first_dim, \"loss:\", loss.item(), \"Mean Grad Norm:\", mean_grad_norm.item(),)\n",
    "            \n",
    "        CustomTrainer.counter = CustomTrainer.counter + 1\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def blend_loss(self, logits, labels, alength, doPrint=True):\n",
    "        # 预测的长度 > 问题的长度    训练数据labels的长度一定大于问题的长度\n",
    "        if len(logits) > alength:\n",
    "            loss = self.cosine_loss(logits, labels, doPrint=False) # logits[-alength:]\n",
    "            loss2 = 0. # self.cross_loss(logits[:alength], labels[:alength], doPrint=False)\n",
    "        elif len(logits) == alength: # 预测的长度 == 问题的长度\n",
    "            loss = self.cosine_loss(logits, labels, doPrint=False)\n",
    "            loss2 = 0.\n",
    "        else:\n",
    "            loss = self.cosine_loss(logits, labels, doPrint=False)\n",
    "            loss2 = 0.\n",
    "\n",
    "        result = 100000. * loss # -10. / (torch.sinh(loss - 1.1) ) - 7.487 # result 最小为 -5.001,其斜率为 2.562\n",
    "\n",
    "        mean_grad_norm = 0.\n",
    "        if doPrint:\n",
    "            if CustomTrainer.counter % train_args.gradient_accumulation_steps == 0:\n",
    "                grad_norms = [torch.norm(grad) for grad in model.parameters() if grad is not None and grad.dtype not in [torch.uint8] and grad.requires_grad]\n",
    "                mean_grad_norm = torch.mean(torch.stack(grad_norms))\n",
    "                print(\"custom_loss_function steps:\", CustomTrainer.counter, \"output dim:\", 4096, \"loss:\", result.item(), \"Mean Grad Norm:\", mean_grad_norm.item(),)\n",
    "\n",
    "            CustomTrainer.counter = CustomTrainer.counter + 1\n",
    "            # return result + loss2 / 10. + mean_grad_norm / 10000.\n",
    "\n",
    "        return result\n",
    "\n",
    "    def cosine_loss(self, logits, labels, doPrint=True):\n",
    "        # print(\"logits.shape\", logits.shape)\n",
    "        # print(\"labels.shape\", labels.shape)\n",
    "\n",
    "        logits_squeezed = logits.squeeze(1)  # logits的形状现在是[316, 32000]\n",
    "        # # 归一化 光归一化不好，求和可能大于1很多\n",
    "        # min_val = torch.min(logits_squeezed)\n",
    "        # max_val = torch.max(logits_squeezed)\n",
    "        # logits_squeezed = (logits_squeezed - min_val) / (max_val - min_val) \n",
    "        logits_squeezed = F.softmax(logits_squeezed, dim=1) # 这时候 logits_squeezed 才代表是每个标签或分类的概率\n",
    "        # print(\"logits_squeezed.shape\", logits_squeezed.shape)\n",
    "        # print(\"torch.sum(logits_squeezed,1)\", torch.sum(logits_squeezed,1) )\n",
    "        # model.embed_tokens.weight Shape: torch.Size([32000, 4096])\n",
    "        qz = model.get_parameter(\"model.embed_tokens.weight\")\n",
    "        logits_squeezed = logits_squeezed.to(qz.dtype)\n",
    "        logits_squeezed = torch.matmul(logits_squeezed, qz) # logits的形状现在是[316, 4096]\n",
    "        labels_squeezed = labels.squeeze(1)  # labels的形状现在是[438]\n",
    "\n",
    "        # 确定新的第一个维度大小  填充的方法内存爆了 .最多填充到100, 再长内存爆了\n",
    "        minToken = 4096 # 150很大，已经不能收敛，不能再调大。调大连loss都收敛不了。往小调整100太小。\n",
    "        new_first_dim = minToken # min(minToken, max(logits_squeezed.shape[0], labels_squeezed.shape[0]) )\n",
    "\n",
    "        embeddings2 = model.get_submodule(\"model.embed_tokens\").forward(labels_squeezed) # [438, 4096]\n",
    "\n",
    "        # 计算句子向量（这里取所有词向量的平均值）\n",
    "        sentence_vector1 = logits_squeezed.mean(dim=0) # shape 4096\n",
    "        sentence_vector2 = embeddings2.mean(dim=0) # shape 4096\n",
    "\n",
    "        logits_squeezed = sentence_vector1.to(torch.bfloat16)\n",
    "        labels_squeezed = sentence_vector2.to(torch.bfloat16)\n",
    "\n",
    "        padded_logits = logits_squeezed\n",
    "        padded_labels = labels_squeezed\n",
    "        # 计算余弦相似度\n",
    "        # loss = -torch.dot(padded_logits, padded_labels) / (torch.norm(padded_logits) * torch.norm(padded_labels))\n",
    "        loss = torch.mean( (padded_logits - padded_labels)**2 )\n",
    "\n",
    "        if doPrint:\n",
    "            if CustomTrainer.counter % train_args.gradient_accumulation_steps == 0:\n",
    "                grad_norms = [torch.norm(grad) for grad in model.parameters() if grad is not None and grad.dtype not in [torch.uint8] and grad.requires_grad]\n",
    "                mean_grad_norm = torch.mean(torch.stack(grad_norms))\n",
    "                print(\"custom_loss_function steps:\", CustomTrainer.counter, \"output dim:\", new_first_dim, \"loss:\", loss.item(), \"Mean Grad Norm:\", mean_grad_norm.item(),)\n",
    "\n",
    "            CustomTrainer.counter = CustomTrainer.counter + 1\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-05T04:13:21.316238Z",
     "iopub.status.busy": "2024-05-05T04:13:21.315752Z",
     "iopub.status.idle": "2024-05-05T04:13:21.335344Z",
     "shell.execute_reply": "2024-05-05T04:13:21.334814Z",
     "shell.execute_reply.started": "2024-05-05T04:13:21.316214Z"
    },
    "tags": []
   },
   "source": [
    "from transformers import Trainer\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    counter = 0\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \n",
    "        SaveTrainingRecordCallback.inputs = inputs\n",
    "        \n",
    "        # print(\"inputs\", inputs)\n",
    "        # 获取模型的输出\n",
    "        outputs = model(**inputs)\n",
    "        # print(\"outputs\", outputs)\n",
    "        labels = inputs.get(\"labels\")\n",
    "        loss = self.blend_loss( outputs[\"logits\"], labels, len(inputs[\"input_ids\"]) )\n",
    "        # 如果需要返回输出，用于评估或其它目的\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "\n",
    "    def cross_loss(self, logits, labels, doPrint=True):\n",
    "        # print(\"logits.shape\", logits.shape)\n",
    "        # print(\"labels.shape\", labels.shape)\n",
    "        logits_squeezed = logits.squeeze(1)  # logits的形状现在是[316, 32000]  \n",
    "        labels_squeezed = labels.squeeze(1)  # labels的形状现在是[438]  \n",
    "\n",
    "        # 使用较小的长度比较损失, 答案没比较全, 不能确定结果是对的\n",
    "        # min_dim = min(logits_squeezed.shape[0], labels_squeezed.shape[0])\n",
    "        # padded_logits = logits_squeezed[:min_dim]\n",
    "        # padded_labels = labels_squeezed[:min_dim]\n",
    "\n",
    "        # 确定新的第一个维度大小  填充的方法内存爆了 .最多填充到500, 再长内存爆了\n",
    "        new_first_dim = min(1000, max(logits_squeezed.shape[0], labels_squeezed.shape[0]) )\n",
    "        # 计算logits需要在第一个维度上填充的大小  \n",
    "        padding_size_logits = new_first_dim - logits_squeezed.shape[0]  \n",
    "        if padding_size_logits > 0 :\n",
    "            # 使用pad函数在logits的第一个维度上进行填充，填充值为0（或其他合适的值）  \n",
    "            padding_logits = [0, 0, 0, padding_size_logits]   \n",
    "            padded_logits = F.pad(logits_squeezed, padding_logits, mode='constant', value=0)\n",
    "            # 调整padded_logits的形状以匹配所需维度[438, 32000]  \n",
    "            padded_logits = padded_logits.view(new_first_dim, -1)  \n",
    "        else:\n",
    "            padded_logits = logits_squeezed[:new_first_dim, :]\n",
    "        padding_size = new_first_dim - labels_squeezed.shape[0]  \n",
    "        if padding_size > 0:\n",
    "            padding_labels = [0, padding_size]  \n",
    "            padded_labels = F.pad(labels_squeezed, padding_labels, mode='constant', value=0)\n",
    "            padded_labels = padded_labels.view(new_first_dim)\n",
    "        else:\n",
    "            padded_labels = labels_squeezed[:new_first_dim]\n",
    "        # 现在padded_logits和labels_squeezed都具有第一个维度为438或更大\n",
    "        # print(\"Padded logits shape:\", padded_logits.shape)\n",
    "        # print(\"Squeezed labels shape:\", labels_squeezed.shape)\n",
    "        loss = F.cross_entropy(padded_logits, padded_labels)\n",
    "        # loss.requires_grad_(True)\n",
    "\n",
    "        if doPrint:\n",
    "            if CustomTrainer.counter % train_args.gradient_accumulation_steps == 0:\n",
    "                grad_norms = [torch.norm(grad) for grad in model.parameters() if grad is not None and grad.dtype not in [torch.uint8] and grad.requires_grad]\n",
    "                mean_grad_norm = torch.mean(torch.stack(grad_norms))\n",
    "            #     param_dict = {}\n",
    "            #     name = \"lm_head.weight\"\n",
    "            #     param =  model.get_parameter(name)\n",
    "            #     if param.dtype not in [torch.uint8]:\n",
    "            #         param_stats[name] = {\n",
    "            #         'mean': torch.mean(param).item() ,\n",
    "            #         'max': torch.max(param).item(),\n",
    "            #         'min': torch.min(param).item(),\n",
    "            #         'median': torch.median(param).item(),\n",
    "            #         'variance': torch.var(param).item(),\n",
    "                    # }\n",
    "                print(\"custom_loss_function steps:\", CustomTrainer.counter, \"output dim:\", new_first_dim, \"loss:\", loss.item(), \"Mean Grad Norm:\", mean_grad_norm.item(),)\n",
    "\n",
    "            CustomTrainer.counter = CustomTrainer.counter + 1\n",
    "        return loss\n",
    "\n",
    "    def blend_loss(self, logits, labels, qlength, doPrint=True):\n",
    "#         logits_split_point = int(len(logits) * 1 / 5)\n",
    "#         logits1, logits2 = logits[:-logits_split_point], logits[-logits_split_point:]\n",
    "\n",
    "#         labels_split_point = int(len(labels) * 1 / 5)\n",
    "#         labels1, labels2 = labels[:-labels_split_point], labels[-labels_split_point:]\n",
    "\n",
    "        # 预测的长度 > 问题的长度    训练数据labels的长度一定大于问题的长度\n",
    "        if len(logits) > qlength:\n",
    "            loss = self.cosine_loss(logits[qlength:], labels[qlength:], doPrint=False)\n",
    "            loss2 = self.cross_loss(logits[:qlength], labels[:qlength], doPrint=False)\n",
    "        elif len(logits) == qlength: # 预测的长度 == 问题的长度\n",
    "            loss = self.cosine_loss(logits, labels, doPrint=False)\n",
    "            loss2 = 0.\n",
    "        else:\n",
    "            loss = self.cosine_loss(logits, labels, doPrint=False)\n",
    "            loss2 = 0.\n",
    "\n",
    "        result = -10. / (torch.sinh(loss - 1.1) ) - 7.487 # result 最小为 -5.001,其斜率为 2.562\n",
    "\n",
    "        mean_grad_norm = 0.\n",
    "        if doPrint:\n",
    "            if CustomTrainer.counter % train_args.gradient_accumulation_steps == 0:\n",
    "                grad_norms = [torch.norm(grad) for grad in model.parameters() if grad is not None and grad.dtype not in [torch.uint8] and grad.requires_grad]\n",
    "                mean_grad_norm = torch.mean(torch.stack(grad_norms))\n",
    "            #     param_dict = {}\n",
    "            #     name = \"lm_head.weight\"\n",
    "            #     param =  model.get_parameter(name)\n",
    "            #     if param.dtype not in [torch.uint8]:\n",
    "            #         param_stats[name] = {\n",
    "            #         'mean': torch.mean(param).item() ,\n",
    "            #         'max': torch.max(param).item(),\n",
    "            #         'min': torch.min(param).item(),\n",
    "            #         'median': torch.median(param).item(),\n",
    "            #         'variance': torch.var(param).item(),\n",
    "                    # }\n",
    "                print(\"custom_loss_function steps:\", CustomTrainer.counter, \"output dim:\", 4096, \"loss:\", result.item(), \"Mean Grad Norm:\", mean_grad_norm.item(),)\n",
    "                # writer.add_scalar('Mean Grad Norm', mean_grad_norm.item(), CustomTrainer.counter)\n",
    "                # for i, grad_norm in enumerate(grad_norms):\n",
    "                #     writer.add_scalar(f'Grad Norm {i}', grad_norm.item(), CustomTrainer.counter)\n",
    "\n",
    "            CustomTrainer.counter = CustomTrainer.counter + 1\n",
    "\n",
    "            return result + loss2 / 10. + mean_grad_norm / 100.\n",
    "\n",
    "    def cosine_loss(self, logits, labels, doPrint=True):\n",
    "        # print(\"logits.shape\", logits.shape)\n",
    "        # print(\"labels.shape\", labels.shape)\n",
    "        \n",
    "        logits_squeezed = logits.squeeze(1)  # logits的形状现在是[316, 32000]\n",
    "        # # 归一化 光归一化不好，求和可能大于1很多\n",
    "        # min_val = torch.min(logits_squeezed)\n",
    "        # max_val = torch.max(logits_squeezed)\n",
    "        # logits_squeezed = (logits_squeezed - min_val) / (max_val - min_val) \n",
    "        logits_squeezed = F.softmax(logits_squeezed, dim=1) # 这时候 logits_squeezed 才代表是每个标签或分类的概率\n",
    "        # print(\"logits_squeezed.shape\", logits_squeezed.shape)\n",
    "        # print(\"torch.sum(logits_squeezed,1)\", torch.sum(logits_squeezed,1) )\n",
    "        # model.embed_tokens.weight Shape: torch.Size([32000, 4096])\n",
    "        qz = model.get_parameter(\"model.embed_tokens.weight\")\n",
    "        logits_squeezed = logits_squeezed.to(qz.dtype)\n",
    "        logits_squeezed = torch.matmul(logits_squeezed, qz) # logits的形状现在是[316, 4096]\n",
    "        labels_squeezed = labels.squeeze(1)  # labels的形状现在是[438]\n",
    "        \n",
    "        # 使用较小的长度比较损失, 答案没比较全, 不能确定结果是对的\n",
    "        # new_first_dim = min(logits_squeezed.shape[0], labels_squeezed.shape[0])\n",
    "        # padded_logits = logits_squeezed[:new_first_dim]\n",
    "        # padded_labels = labels_squeezed[:new_first_dim]\n",
    "\n",
    "        # 确定新的第一个维度大小  填充的方法内存爆了 .最多填充到100, 再长内存爆了\n",
    "        minToken = 4096 # 150很大，已经不能收敛，不能再调大。调大连loss都收敛不了。往小调整100太小。\n",
    "        new_first_dim = minToken # min(minToken, max(logits_squeezed.shape[0], labels_squeezed.shape[0]) )\n",
    "\n",
    "        # max_indices = torch.argmax(logits_squeezed, dim=1) # 应该输出 torch.Size([316])  argmax 不能方向求导\n",
    "        # preTxt = tokenizer.decode(max_indices, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        embeddings2 = model.get_submodule(\"model.embed_tokens\").forward(labels_squeezed) # [438, 4096]\n",
    "        # embeddings2.requires_grad=False\n",
    "        # print(\"embeddings2.requires_grad\", embeddings2.requires_grad)\n",
    "        # 计算句子向量（这里取所有词向量的平均值）\n",
    "        sentence_vector1 = logits_squeezed.mean(dim=0) # shape 4096\n",
    "        sentence_vector2 = embeddings2.mean(dim=0) # shape 4096\n",
    "        \n",
    "        # 应用最大池化来获得句子的句向量\n",
    "        # 在dim=0上应用最大池化，即沿着词的维度\n",
    "        # sentence_vector, _ = torch.max(word_vectors, dim=0)\n",
    "        \n",
    "        # print(\"sentence_vector1.shape\",sentence_vector1.shape)\n",
    "        # print(\"sentence_vector2.shape\",sentence_vector2.shape)\n",
    "        logits_squeezed = sentence_vector1.to(torch.bfloat16)\n",
    "        labels_squeezed = sentence_vector2.to(torch.bfloat16)\n",
    "        # print(\"sentence_vector2\", sentence_vector2)\n",
    "        # print(\"sentence_vector2.shape\", sentence_vector2.shape)\n",
    "\n",
    "        # 计算logits需要在第一个维度上填充的大小\n",
    "        # padding_size_logits = new_first_dim - logits_squeezed.shape[0]\n",
    "        # if padding_size_logits > 0:\n",
    "        #     # 使用pad函数在logits的第一个维度上进行填充，填充值为0（或其他合适的值）\n",
    "        #     padding_logits = [0, padding_size_logits]\n",
    "        #     padded_logits = F.pad(logits_squeezed, padding_logits, mode='constant', value=0)\n",
    "        #     # 调整padded_logits的形状以匹配所需维度[438, 32000]\n",
    "        #     padded_logits = padded_logits.view(new_first_dim) # , -1\n",
    "        # else:\n",
    "        #     padded_logits = logits_squeezed[:new_first_dim] # ,:\n",
    "        # padding_size = new_first_dim - labels_squeezed.shape[0]\n",
    "        # if padding_size > 0:\n",
    "        #     padding_labels = [0, padding_size]\n",
    "        #     padded_labels = F.pad(labels_squeezed, padding_labels, mode='constant', value=0)\n",
    "        #     padded_labels = padded_labels.view(new_first_dim)\n",
    "        # else:\n",
    "        #     padded_labels = labels_squeezed[:new_first_dim]\n",
    "        # 现在padded_logits和labels_squeezed都具有第一个维度为438或更大\n",
    "        # print(\"Padded logits shape:\", padded_logits.shape)\n",
    "        # print(\"Squeezed labels shape:\", labels_squeezed.shape)\n",
    "        # loss = F.cross_entropy(padded_logits, padded_labels)\n",
    "        # loss.requires_grad_(True)\n",
    "\n",
    "        padded_logits = logits_squeezed\n",
    "        padded_labels = labels_squeezed\n",
    "        # 计算余弦相似度\n",
    "        loss = -torch.dot(padded_logits, padded_labels) / (torch.norm(padded_logits) * torch.norm(padded_labels))\n",
    "        \n",
    "        if doPrint:\n",
    "            if CustomTrainer.counter % train_args.gradient_accumulation_steps == 0:\n",
    "                grad_norms = [torch.norm(grad) for grad in model.parameters() if grad is not None and grad.dtype not in [torch.uint8] and grad.requires_grad]\n",
    "                mean_grad_norm = torch.mean(torch.stack(grad_norms))\n",
    "            #     param_dict = {}\n",
    "            #     name = \"lm_head.weight\"\n",
    "            #     param =  model.get_parameter(name)\n",
    "            #     if param.dtype not in [torch.uint8]:\n",
    "            #         param_stats[name] = {\n",
    "            #         'mean': torch.mean(param).item() ,\n",
    "            #         'max': torch.max(param).item(),\n",
    "            #         'min': torch.min(param).item(),\n",
    "            #         'median': torch.median(param).item(),\n",
    "            #         'variance': torch.var(param).item(),\n",
    "                    # }\n",
    "                print(\"custom_loss_function steps:\", CustomTrainer.counter, \"output dim:\", new_first_dim, \"loss:\", loss.item(), \"Mean Grad Norm:\", mean_grad_norm.item(),)\n",
    "                      # f\"Name: {name}\", f\"Shape: {param.shape}\", f\"Type: {type(param)}\", param_stats[name])\n",
    "                # writer.add_scalar('Mean Grad Norm', mean_grad_norm.item(), CustomTrainer.counter)\n",
    "                # for i, grad_norm in enumerate(grad_norms):\n",
    "                #     writer.add_scalar(f'Grad Norm {i}', grad_norm.item(), CustomTrainer.counter)\n",
    "\n",
    "            CustomTrainer.counter = CustomTrainer.counter + 1\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:29.928035Z",
     "iopub.status.busy": "2024-05-16T08:40:29.927722Z",
     "iopub.status.idle": "2024-05-16T08:40:30.056682Z",
     "shell.execute_reply": "2024-05-16T08:40:30.056222Z",
     "shell.execute_reply.started": "2024-05-16T08:40:29.928018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.CustomTrainer at 0x7fd650356410>, 40)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "# trainer = Trainer(model=model, tokenizer=tokenizer, args=args, **data_module) 必须使用自己的类才能自定义损失函数\n",
    "trainer = CustomTrainer(model=model, tokenizer=tokenizer, args=train_args, **data_module,\n",
    "                       callbacks=[SaveTrainingRecordCallback()])\n",
    "model.config.use_cache = False\n",
    "trainer,gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:30.191754Z",
     "iopub.status.busy": "2024-05-16T08:40:30.191391Z",
     "iopub.status.idle": "2024-05-16T08:40:30.314450Z",
     "shell.execute_reply": "2024-05-16T08:40:30.314002Z",
     "shell.execute_reply.started": "2024-05-16T08:40:30.191737Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.training,gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:30.404814Z",
     "iopub.status.busy": "2024-05-16T08:40:30.404436Z",
     "iopub.status.idle": "2024-05-16T08:40:30.408577Z",
     "shell.execute_reply": "2024-05-16T08:40:30.408200Z",
     "shell.execute_reply.started": "2024-05-16T08:40:30.404796Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peft_adapter1']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.active_adapters()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainer.train(resume_from_checkpoint = 'checkpoint目录') # 可以从检查点恢复训练. 不用这个,从检查点加载模型就行."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-16T08:40:32.598025Z",
     "iopub.status.busy": "2024-05-16T08:40:32.597690Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 0 output dim: 151 loss: 0.0003265986160840839 Mean Grad Norm: 3.265986204147339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2079' max='12318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2079/12318 28:39:13 < 141:15:18, 0.02 it/s, Epoch 0.34/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>879</td>\n",
       "      <td>0.680300</td>\n",
       "      <td>0.646730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1758</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.554162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 128 output dim: 173 loss: 0.0003265986160840839 Mean Grad Norm: 3.265986204147339\n",
      "custom_loss_function steps: 256 output dim: 497 loss: 50.42435073852539 Mean Grad Norm: 3.265986680984497\n",
      "custom_loss_function steps: 384 output dim: 112 loss: 0.0003265987033955753 Mean Grad Norm: 3.2659871578216553\n",
      "custom_loss_function steps: 512 output dim: 239 loss: 0.0003265988198108971 Mean Grad Norm: 3.265988349914551\n",
      "custom_loss_function steps: 640 output dim: 256 loss: 0.0003265990235377103 Mean Grad Norm: 3.2659902572631836\n",
      "custom_loss_function steps: 768 output dim: 308 loss: 0.00032659919816069305 Mean Grad Norm: 3.2659921646118164\n",
      "custom_loss_function steps: 896 output dim: 168 loss: 0.00032659946009516716 Mean Grad Norm: 3.2659947872161865\n",
      "custom_loss_function steps: 1024 output dim: 186 loss: 0.00032659975113347173 Mean Grad Norm: 3.2659976482391357\n",
      "custom_loss_function steps: 1152 output dim: 98 loss: 0.0003266001003794372 Mean Grad Norm: 3.266000986099243\n",
      "custom_loss_function steps: 1280 output dim: 114 loss: 0.00032660042052157223 Mean Grad Norm: 3.2660043239593506\n",
      "custom_loss_function steps: 1408 output dim: 269 loss: 0.0003266008279751986 Mean Grad Norm: 3.2660083770751953\n",
      "custom_loss_function steps: 1536 output dim: 88 loss: 9.926617622375488 Mean Grad Norm: 3.266012668609619\n",
      "custom_loss_function steps: 1664 output dim: 121 loss: 0.0003266017301939428 Mean Grad Norm: 3.266017436981201\n",
      "custom_loss_function steps: 1792 output dim: 141 loss: 0.000326602254062891 Mean Grad Norm: 3.2660226821899414\n",
      "custom_loss_function steps: 1920 output dim: 352 loss: 0.0003266028652433306 Mean Grad Norm: 3.266028642654419\n",
      "custom_loss_function steps: 2048 output dim: 330 loss: 0.0003266034182161093 Mean Grad Norm: 3.2660343647003174\n",
      "custom_loss_function steps: 2176 output dim: 124 loss: 0.0003266040585003793 Mean Grad Norm: 3.266040802001953\n",
      "custom_loss_function steps: 2304 output dim: 134 loss: 0.00032660472788847983 Mean Grad Norm: 3.266047239303589\n",
      "custom_loss_function steps: 2432 output dim: 106 loss: 0.0003266054263804108 Mean Grad Norm: 3.266054391860962\n",
      "custom_loss_function steps: 2560 output dim: 155 loss: 0.0003266062121838331 Mean Grad Norm: 3.2660622596740723\n",
      "custom_loss_function steps: 2688 output dim: 172 loss: 0.0003266070270910859 Mean Grad Norm: 3.2660703659057617\n",
      "custom_loss_function steps: 2816 output dim: 110 loss: 0.0003266078419983387 Mean Grad Norm: 3.266078472137451\n",
      "custom_loss_function steps: 2944 output dim: 152 loss: 0.0003266087151132524 Mean Grad Norm: 3.266087293624878\n",
      "custom_loss_function steps: 3072 output dim: 266 loss: 0.0003266096755396575 Mean Grad Norm: 3.266096830368042\n",
      "custom_loss_function steps: 3200 output dim: 271 loss: 0.00032661063596606255 Mean Grad Norm: 3.266106367111206\n",
      "custom_loss_function steps: 3328 output dim: 167 loss: 0.00032661165460012853 Mean Grad Norm: 3.2661166191101074\n",
      "custom_loss_function steps: 3456 output dim: 109 loss: 0.00032661273144185543 Mean Grad Norm: 3.266127347946167\n",
      "custom_loss_function steps: 3584 output dim: 599 loss: 0.0003266138373874128 Mean Grad Norm: 3.2661383152008057\n",
      "custom_loss_function steps: 3712 output dim: 181 loss: 0.00032661500154063106 Mean Grad Norm: 3.2661499977111816\n",
      "custom_loss_function steps: 3840 output dim: 217 loss: 0.0003266161947976798 Mean Grad Norm: 3.2661619186401367\n",
      "custom_loss_function steps: 3968 output dim: 179 loss: 0.0003266174462623894 Mean Grad Norm: 3.266174554824829\n",
      "custom_loss_function steps: 4096 output dim: 63 loss: 9.419519424438477 Mean Grad Norm: 3.2661871910095215\n",
      "custom_loss_function steps: 4224 output dim: 240 loss: 0.00032661997829563916 Mean Grad Norm: 3.266199827194214\n",
      "custom_loss_function steps: 4352 output dim: 120 loss: 0.00032662125886417925 Mean Grad Norm: 3.2662127017974854\n",
      "custom_loss_function steps: 4480 output dim: 244 loss: 0.0003266226267442107 Mean Grad Norm: 3.266226291656494\n",
      "custom_loss_function steps: 4608 output dim: 136 loss: 0.0003266239946242422 Mean Grad Norm: 3.266240119934082\n",
      "custom_loss_function steps: 4736 output dim: 185 loss: 0.00032662542071193457 Mean Grad Norm: 3.266254186630249\n",
      "custom_loss_function steps: 4864 output dim: 129 loss: 0.00032662684679962695 Mean Grad Norm: 3.266268491744995\n",
      "custom_loss_function steps: 4992 output dim: 138 loss: 8.808334350585938 Mean Grad Norm: 3.2662839889526367\n",
      "custom_loss_function steps: 5120 output dim: 224 loss: 0.00032662993180565536 Mean Grad Norm: 3.2662994861602783\n",
      "custom_loss_function steps: 5248 output dim: 188 loss: 0.0003266315034125 Mean Grad Norm: 3.266315221786499\n",
      "custom_loss_function steps: 5376 output dim: 117 loss: 0.00032663310412317514 Mean Grad Norm: 3.266331195831299\n",
      "custom_loss_function steps: 5504 output dim: 175 loss: 13.591002464294434 Mean Grad Norm: 3.266347646713257\n",
      "custom_loss_function steps: 5632 output dim: 221 loss: 0.0003266364801675081 Mean Grad Norm: 3.266364812850952\n",
      "custom_loss_function steps: 5760 output dim: 316 loss: 0.00032663822639733553 Mean Grad Norm: 3.2663824558258057\n",
      "custom_loss_function steps: 5888 output dim: 209 loss: 0.0003266400599386543 Mean Grad Norm: 3.2664005756378174\n",
      "custom_loss_function steps: 6016 output dim: 214 loss: 0.00032664192258380353 Mean Grad Norm: 3.2664191722869873\n",
      "custom_loss_function steps: 6144 output dim: 142 loss: 0.0003266438143327832 Mean Grad Norm: 3.2664382457733154\n",
      "custom_loss_function steps: 6272 output dim: 104 loss: 0.0003266457642894238 Mean Grad Norm: 3.2664577960968018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 6400 output dim: 296 loss: 0.00032664777245372534 Mean Grad Norm: 3.2664778232574463\n",
      "custom_loss_function steps: 6528 output dim: 101 loss: 0.00032664983882568777 Mean Grad Norm: 3.266498565673828\n",
      "custom_loss_function steps: 6656 output dim: 231 loss: 0.0003266519051976502 Mean Grad Norm: 3.266519069671631\n",
      "custom_loss_function steps: 6784 output dim: 81 loss: 9.358227729797363 Mean Grad Norm: 3.266540765762329\n",
      "custom_loss_function steps: 6912 output dim: 188 loss: 0.00032665624166838825 Mean Grad Norm: 3.2665624618530273\n",
      "custom_loss_function steps: 7040 output dim: 88 loss: 10.285002708435059 Mean Grad Norm: 3.266584873199463\n",
      "custom_loss_function steps: 7168 output dim: 160 loss: 0.0003266607818659395 Mean Grad Norm: 3.2666077613830566\n",
      "custom_loss_function steps: 7296 output dim: 95 loss: 0.0003266630519647151 Mean Grad Norm: 3.2666306495666504\n",
      "custom_loss_function steps: 7424 output dim: 136 loss: 0.00032666538027115166 Mean Grad Norm: 3.2666540145874023\n",
      "custom_loss_function steps: 7552 output dim: 274 loss: 0.0003266677667852491 Mean Grad Norm: 3.2666778564453125\n",
      "custom_loss_function steps: 7680 output dim: 170 loss: 0.0003266702115070075 Mean Grad Norm: 3.266702175140381\n",
      "custom_loss_function steps: 7808 output dim: 119 loss: 0.00032667271443642676 Mean Grad Norm: 3.2667272090911865\n",
      "custom_loss_function steps: 7936 output dim: 102 loss: 0.00032667527557350695 Mean Grad Norm: 3.2667527198791504\n",
      "custom_loss_function steps: 8064 output dim: 130 loss: 0.00032667783671058714 Mean Grad Norm: 3.2667784690856934\n",
      "custom_loss_function steps: 8192 output dim: 136 loss: 0.0003266804269514978 Mean Grad Norm: 3.2668042182922363\n",
      "custom_loss_function steps: 8320 output dim: 94 loss: 0.00032668307540006936 Mean Grad Norm: 3.2668309211730957\n",
      "custom_loss_function steps: 8448 output dim: 183 loss: 0.0003266857238486409 Mean Grad Norm: 3.266857385635376\n",
      "custom_loss_function steps: 8576 output dim: 224 loss: 0.000326688343193382 Mean Grad Norm: 3.266883611679077\n",
      "custom_loss_function steps: 8704 output dim: 338 loss: 0.00032669102074578404 Mean Grad Norm: 3.2669103145599365\n",
      "custom_loss_function steps: 8832 output dim: 149 loss: 0.00032669364009052515 Mean Grad Norm: 3.2669365406036377\n",
      "custom_loss_function steps: 8960 output dim: 159 loss: 0.00032669625943526626 Mean Grad Norm: 3.266962766647339\n",
      "custom_loss_function steps: 9088 output dim: 203 loss: 0.0003266989369876683 Mean Grad Norm: 3.2669894695281982\n",
      "custom_loss_function steps: 9216 output dim: 148 loss: 0.00032670170185156167 Mean Grad Norm: 3.267017126083374\n",
      "custom_loss_function steps: 9344 output dim: 91 loss: 0.0003267045540269464 Mean Grad Norm: 3.267045736312866\n",
      "custom_loss_function steps: 9472 output dim: 444 loss: 0.0003267074644099921 Mean Grad Norm: 3.2670748233795166\n",
      "custom_loss_function steps: 9600 output dim: 314 loss: 0.00032671040389686823 Mean Grad Norm: 3.267104148864746\n",
      "custom_loss_function steps: 9728 output dim: 319 loss: 0.00032671340159140527 Mean Grad Norm: 3.267134189605713\n",
      "custom_loss_function steps: 9856 output dim: 153 loss: 0.00032671642838977277 Mean Grad Norm: 3.267164468765259\n",
      "custom_loss_function steps: 9984 output dim: 91 loss: 9.013803482055664 Mean Grad Norm: 3.267195224761963\n",
      "custom_loss_function steps: 10112 output dim: 156 loss: 0.0003267225401941687 Mean Grad Norm: 3.267225503921509\n",
      "custom_loss_function steps: 10240 output dim: 188 loss: 0.000326725683407858 Mean Grad Norm: 3.26725697517395\n",
      "custom_loss_function steps: 10368 output dim: 89 loss: 0.0003267289139330387 Mean Grad Norm: 3.267289161682129\n",
      "custom_loss_function steps: 10496 output dim: 289 loss: 0.00032673205714672804 Mean Grad Norm: 3.2673206329345703\n",
      "custom_loss_function steps: 10624 output dim: 220 loss: 0.0003267353167757392 Mean Grad Norm: 3.2673532962799072\n",
      "custom_loss_function steps: 10752 output dim: 102 loss: 0.0003267386637162417 Mean Grad Norm: 3.2673866748809814\n",
      "custom_loss_function steps: 10880 output dim: 396 loss: 0.00032674206886440516 Mean Grad Norm: 3.267420768737793\n",
      "custom_loss_function steps: 11008 output dim: 249 loss: 0.00032674550311639905 Mean Grad Norm: 3.2674551010131836\n",
      "custom_loss_function steps: 11136 output dim: 307 loss: 0.00032674899557605386 Mean Grad Norm: 3.2674899101257324\n",
      "custom_loss_function steps: 11264 output dim: 361 loss: 0.00032675242982804775 Mean Grad Norm: 3.267524242401123\n",
      "custom_loss_function steps: 11392 output dim: 126 loss: 0.0003267558931838721 Mean Grad Norm: 3.267559051513672\n",
      "custom_loss_function steps: 11520 output dim: 148 loss: 0.0003267594729550183 Mean Grad Norm: 3.267594814300537\n",
      "custom_loss_function steps: 11648 output dim: 126 loss: 0.0003267631691414863 Mean Grad Norm: 3.267631769180298\n",
      "custom_loss_function steps: 11776 output dim: 179 loss: 0.00032676689443178475 Mean Grad Norm: 3.2676689624786377\n",
      "custom_loss_function steps: 11904 output dim: 223 loss: 0.00032677047420293093 Mean Grad Norm: 3.267704963684082\n",
      "custom_loss_function steps: 12032 output dim: 202 loss: 0.00032677422859705985 Mean Grad Norm: 3.267742395401001\n",
      "custom_loss_function steps: 12160 output dim: 189 loss: 0.0003267780120950192 Mean Grad Norm: 3.267780065536499\n",
      "custom_loss_function steps: 12288 output dim: 71 loss: 0.00032678182469680905 Mean Grad Norm: 3.2678182125091553\n",
      "custom_loss_function steps: 12416 output dim: 288 loss: 0.00032678578281775117 Mean Grad Norm: 3.267857789993286\n",
      "custom_loss_function steps: 12544 output dim: 70 loss: 8.108125686645508 Mean Grad Norm: 3.267897844314575\n",
      "custom_loss_function steps: 12672 output dim: 159 loss: 0.0003267936990596354 Mean Grad Norm: 3.267937183380127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 12800 output dim: 141 loss: 8.315474510192871 Mean Grad Norm: 3.267972946166992\n",
      "custom_loss_function steps: 12928 output dim: 222 loss: 0.00032680106232874095 Mean Grad Norm: 3.2680106163024902\n",
      "custom_loss_function steps: 13056 output dim: 115 loss: 0.0003268047876190394 Mean Grad Norm: 3.268048048019409\n",
      "custom_loss_function steps: 13184 output dim: 83 loss: 7.87680721282959 Mean Grad Norm: 3.2680866718292236\n",
      "custom_loss_function steps: 13312 output dim: 278 loss: 0.0003268125874456018 Mean Grad Norm: 3.2681260108947754\n",
      "custom_loss_function steps: 13440 output dim: 290 loss: 0.0003268166328780353 Mean Grad Norm: 3.2681663036346436\n",
      "custom_loss_function steps: 13568 output dim: 102 loss: 0.0003268207365181297 Mean Grad Norm: 3.268207311630249\n",
      "custom_loss_function steps: 13696 output dim: 218 loss: 0.0003268247819505632 Mean Grad Norm: 3.2682478427886963\n",
      "custom_loss_function steps: 13824 output dim: 124 loss: 0.00032682897290214896 Mean Grad Norm: 3.268289804458618\n",
      "custom_loss_function steps: 13952 output dim: 108 loss: 0.0003268332511652261 Mean Grad Norm: 3.2683324813842773\n",
      "custom_loss_function steps: 14080 output dim: 186 loss: 0.0003268376167397946 Mean Grad Norm: 3.268376350402832\n",
      "custom_loss_function steps: 14208 output dim: 111 loss: 0.00032684209872968495 Mean Grad Norm: 3.268420934677124\n",
      "custom_loss_function steps: 14336 output dim: 81 loss: 0.00032684655161574483 Mean Grad Norm: 3.268465518951416\n",
      "custom_loss_function steps: 14464 output dim: 267 loss: 0.00032685112091712654 Mean Grad Norm: 3.2685112953186035\n",
      "custom_loss_function steps: 14592 output dim: 83 loss: 0.00032685569021850824 Mean Grad Norm: 3.268557071685791\n",
      "custom_loss_function steps: 14720 output dim: 220 loss: 0.00032686046324670315 Mean Grad Norm: 3.2686047554016113\n",
      "custom_loss_function steps: 14848 output dim: 113 loss: 0.00032686503254808486 Mean Grad Norm: 3.268650531768799\n",
      "custom_loss_function steps: 14976 output dim: 214 loss: 0.0003268696600571275 Mean Grad Norm: 3.2686965465545654\n",
      "custom_loss_function steps: 15104 output dim: 129 loss: 0.00032687437487766147 Mean Grad Norm: 3.2687437534332275\n",
      "custom_loss_function steps: 15232 output dim: 481 loss: 0.00032687914790585637 Mean Grad Norm: 3.268791437149048\n",
      "custom_loss_function steps: 15360 output dim: 70 loss: 0.0003268840373493731 Mean Grad Norm: 3.2688403129577637\n",
      "custom_loss_function steps: 15488 output dim: 368 loss: 0.0003268890141043812 Mean Grad Norm: 3.268890142440796\n",
      "custom_loss_function steps: 15616 output dim: 162 loss: 8.592591285705566 Mean Grad Norm: 3.2689411640167236\n",
      "custom_loss_function steps: 15744 output dim: 125 loss: 0.0003268992295488715 Mean Grad Norm: 3.2689924240112305\n",
      "custom_loss_function steps: 15872 output dim: 101 loss: 0.00032690446823835373 Mean Grad Norm: 3.269044876098633\n",
      "custom_loss_function steps: 16000 output dim: 216 loss: 0.00032690956140868366 Mean Grad Norm: 3.2690956592559814\n",
      "custom_loss_function steps: 16128 output dim: 161 loss: 0.0003269147127866745 Mean Grad Norm: 3.2691471576690674\n",
      "custom_loss_function steps: 16256 output dim: 79 loss: 9.019635200500488 Mean Grad Norm: 3.2691993713378906\n",
      "custom_loss_function steps: 16384 output dim: 278 loss: 9.077550888061523 Mean Grad Norm: 3.269252300262451\n",
      "custom_loss_function steps: 16512 output dim: 264 loss: 0.0003269305743742734 Mean Grad Norm: 3.269305944442749\n",
      "custom_loss_function steps: 16640 output dim: 314 loss: 0.0003269360458943993 Mean Grad Norm: 3.2693605422973633\n",
      "custom_loss_function steps: 16768 output dim: 137 loss: 0.0003269414301030338 Mean Grad Norm: 3.2694144248962402\n",
      "custom_loss_function steps: 16896 output dim: 113 loss: 8.31304931640625 Mean Grad Norm: 3.2694692611694336\n",
      "custom_loss_function steps: 17024 output dim: 73 loss: 8.10526180267334 Mean Grad Norm: 3.2695250511169434\n",
      "custom_loss_function steps: 17152 output dim: 338 loss: 0.00032695819390937686 Mean Grad Norm: 3.2695820331573486\n",
      "custom_loss_function steps: 17280 output dim: 850 loss: 0.00032696392736397684 Mean Grad Norm: 3.269639253616333\n",
      "custom_loss_function steps: 17408 output dim: 90 loss: 0.0003269697481300682 Mean Grad Norm: 3.269697427749634\n",
      "custom_loss_function steps: 17536 output dim: 111 loss: 0.0003269755106884986 Mean Grad Norm: 3.2697551250457764\n",
      "custom_loss_function steps: 17664 output dim: 120 loss: 0.00032698141876608133 Mean Grad Norm: 3.2698142528533936\n",
      "custom_loss_function steps: 17792 output dim: 197 loss: 0.00032698726863600314 Mean Grad Norm: 3.2698726654052734\n",
      "custom_loss_function steps: 17920 output dim: 78 loss: 8.041038513183594 Mean Grad Norm: 3.269930601119995\n",
      "custom_loss_function steps: 18048 output dim: 183 loss: 0.0003269988810643554 Mean Grad Norm: 3.269988775253296\n",
      "custom_loss_function steps: 18176 output dim: 169 loss: 0.00032700481824576855 Mean Grad Norm: 3.2700483798980713\n",
      "custom_loss_function steps: 18304 output dim: 98 loss: 0.00032701066811569035 Mean Grad Norm: 3.270106792449951\n",
      "custom_loss_function steps: 18432 output dim: 173 loss: 0.0003270165470894426 Mean Grad Norm: 3.27016544342041\n",
      "custom_loss_function steps: 18560 output dim: 130 loss: 0.0003270225424785167 Mean Grad Norm: 3.2702255249023438\n",
      "custom_loss_function steps: 18688 output dim: 187 loss: 0.0003270283923484385 Mean Grad Norm: 3.2702839374542236\n",
      "custom_loss_function steps: 18816 output dim: 354 loss: 0.0003270343877375126 Mean Grad Norm: 3.2703440189361572\n",
      "custom_loss_function steps: 18944 output dim: 110 loss: 0.0003270405577495694 Mean Grad Norm: 3.2704055309295654\n",
      "custom_loss_function steps: 19072 output dim: 167 loss: 0.0003270467568654567 Mean Grad Norm: 3.270467519760132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 19200 output dim: 313 loss: 0.00032705310150049627 Mean Grad Norm: 3.270531177520752\n",
      "custom_loss_function steps: 19328 output dim: 556 loss: 0.00032705950434319675 Mean Grad Norm: 3.270595073699951\n",
      "custom_loss_function steps: 19456 output dim: 160 loss: 8.90515422821045 Mean Grad Norm: 3.270657539367676\n",
      "custom_loss_function steps: 19584 output dim: 261 loss: 0.0003270721063017845 Mean Grad Norm: 3.270721197128296\n",
      "custom_loss_function steps: 19712 output dim: 189 loss: 0.00032707859645597637 Mean Grad Norm: 3.2707860469818115\n",
      "custom_loss_function steps: 19840 output dim: 95 loss: 0.00032708479557186365 Mean Grad Norm: 3.270848035812378\n",
      "custom_loss_function steps: 19968 output dim: 181 loss: 0.0003270911402069032 Mean Grad Norm: 3.270911455154419\n",
      "custom_loss_function steps: 20096 output dim: 264 loss: 0.00032709745573811233 Mean Grad Norm: 3.270974636077881\n",
      "custom_loss_function steps: 20224 output dim: 120 loss: 8.619855880737305 Mean Grad Norm: 3.271038293838501\n",
      "custom_loss_function steps: 20352 output dim: 509 loss: 0.00032711043604649603 Mean Grad Norm: 3.271104335784912\n",
      "custom_loss_function steps: 20480 output dim: 131 loss: 0.00032711715903133154 Mean Grad Norm: 3.271171808242798\n",
      "custom_loss_function steps: 20608 output dim: 142 loss: 0.0003271239693276584 Mean Grad Norm: 3.271239757537842\n",
      "custom_loss_function steps: 20736 output dim: 120 loss: 0.0003271308960393071 Mean Grad Norm: 3.2713091373443604\n",
      "custom_loss_function steps: 20864 output dim: 158 loss: 0.0003271379100624472 Mean Grad Norm: 3.271379232406616\n",
      "custom_loss_function steps: 20992 output dim: 172 loss: 0.00032714486587792635 Mean Grad Norm: 3.271448850631714\n",
      "custom_loss_function steps: 21120 output dim: 159 loss: 0.00032715179258957505 Mean Grad Norm: 3.2715179920196533\n",
      "custom_loss_function steps: 21248 output dim: 131 loss: 0.0003271587484050542 Mean Grad Norm: 3.271587610244751\n",
      "custom_loss_function steps: 21376 output dim: 164 loss: 0.000327165937051177 Mean Grad Norm: 3.2716593742370605\n",
      "custom_loss_function steps: 21504 output dim: 291 loss: 0.0003271729510743171 Mean Grad Norm: 3.2717294692993164\n",
      "custom_loss_function steps: 21632 output dim: 176 loss: 0.000327180081512779 Mean Grad Norm: 3.2718007564544678\n",
      "custom_loss_function steps: 21760 output dim: 266 loss: 0.0003271872701589018 Mean Grad Norm: 3.2718727588653564\n",
      "custom_loss_function steps: 21888 output dim: 189 loss: 0.00032719410955905914 Mean Grad Norm: 3.2719411849975586\n",
      "custom_loss_function steps: 22016 output dim: 344 loss: 0.000327200919855386 Mean Grad Norm: 3.2720093727111816\n",
      "custom_loss_function steps: 22144 output dim: 137 loss: 0.0003272077883593738 Mean Grad Norm: 3.272078037261963\n",
      "custom_loss_function steps: 22272 output dim: 122 loss: 0.00032721488969400525 Mean Grad Norm: 3.272148847579956\n",
      "custom_loss_function steps: 22400 output dim: 138 loss: 0.000327222136547789 Mean Grad Norm: 3.272221565246582\n",
      "custom_loss_function steps: 22528 output dim: 108 loss: 0.0003272294707130641 Mean Grad Norm: 3.272294759750366\n",
      "custom_loss_function steps: 22656 output dim: 299 loss: 0.00032723689218983054 Mean Grad Norm: 3.272368907928467\n",
      "custom_loss_function steps: 22784 output dim: 128 loss: 9.204435348510742 Mean Grad Norm: 3.272444725036621\n",
      "custom_loss_function steps: 22912 output dim: 359 loss: 0.0003272522008046508 Mean Grad Norm: 3.272522211074829\n",
      "custom_loss_function steps: 23040 output dim: 210 loss: 0.0003272597095929086 Mean Grad Norm: 3.272597074508667\n",
      "custom_loss_function steps: 23168 output dim: 110 loss: 0.00032726730569265783 Mean Grad Norm: 3.2726731300354004\n",
      "custom_loss_function steps: 23296 output dim: 111 loss: 0.0003272750764153898 Mean Grad Norm: 3.2727508544921875\n",
      "custom_loss_function steps: 23424 output dim: 281 loss: 0.00032728290534578264 Mean Grad Norm: 3.272829055786133\n",
      "custom_loss_function steps: 23552 output dim: 105 loss: 0.00032729096710681915 Mean Grad Norm: 3.272909641265869\n",
      "custom_loss_function steps: 23680 output dim: 102 loss: 0.00032729911617934704 Mean Grad Norm: 3.272991180419922\n",
      "custom_loss_function steps: 23808 output dim: 166 loss: 0.0003273069451097399 Mean Grad Norm: 3.2730696201324463\n",
      "custom_loss_function steps: 23936 output dim: 116 loss: 0.00032731486135162413 Mean Grad Norm: 3.273148775100708\n",
      "custom_loss_function steps: 24064 output dim: 125 loss: 0.0003273228940088302 Mean Grad Norm: 3.273228883743286\n",
      "custom_loss_function steps: 24192 output dim: 134 loss: 0.00032733107218518853 Mean Grad Norm: 3.273310899734497\n",
      "custom_loss_function steps: 24320 output dim: 90 loss: 0.00032733933767303824 Mean Grad Norm: 3.273393392562866\n",
      "custom_loss_function steps: 24448 output dim: 387 loss: 0.0003273472539149225 Mean Grad Norm: 3.273472547531128\n",
      "custom_loss_function steps: 24576 output dim: 212 loss: 0.00032735508284531534 Mean Grad Norm: 3.2735509872436523\n",
      "custom_loss_function steps: 24704 output dim: 91 loss: 0.0003273630572948605 Mean Grad Norm: 3.2736306190490723\n",
      "custom_loss_function steps: 24832 output dim: 375 loss: 0.0003273706533946097 Mean Grad Norm: 3.2737066745758057\n",
      "custom_loss_function steps: 24960 output dim: 212 loss: 0.0003273783077020198 Mean Grad Norm: 3.2737832069396973\n",
      "custom_loss_function steps: 25088 output dim: 109 loss: 0.00032738613663241267 Mean Grad Norm: 3.2738614082336426\n",
      "custom_loss_function steps: 25216 output dim: 188 loss: 0.00032739396556280553 Mean Grad Norm: 3.273939847946167\n",
      "custom_loss_function steps: 25344 output dim: 138 loss: 0.0003274019982200116 Mean Grad Norm: 3.274019956588745\n",
      "custom_loss_function steps: 25472 output dim: 249 loss: 0.0003274098562542349 Mean Grad Norm: 3.2740986347198486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 25600 output dim: 132 loss: 0.0003274179471191019 Mean Grad Norm: 3.274179697036743\n",
      "custom_loss_function steps: 25728 output dim: 100 loss: 0.00032742609619162977 Mean Grad Norm: 3.274260997772217\n",
      "custom_loss_function steps: 25856 output dim: 131 loss: 9.264164924621582 Mean Grad Norm: 3.274340867996216\n",
      "custom_loss_function steps: 25984 output dim: 94 loss: 0.0003274423652328551 Mean Grad Norm: 3.274423599243164\n",
      "custom_loss_function steps: 26112 output dim: 265 loss: 0.00032745065982453525 Mean Grad Norm: 3.2745065689086914\n",
      "custom_loss_function steps: 26240 output dim: 506 loss: 0.00032745924545452 Mean Grad Norm: 3.274592638015747\n",
      "custom_loss_function steps: 26368 output dim: 128 loss: 0.00032746780198067427 Mean Grad Norm: 3.2746779918670654\n",
      "custom_loss_function steps: 26496 output dim: 201 loss: 0.0003274766495451331 Mean Grad Norm: 3.274766445159912\n",
      "custom_loss_function steps: 26624 output dim: 183 loss: 0.00032748523517511785 Mean Grad Norm: 3.2748525142669678\n",
      "custom_loss_function steps: 26752 output dim: 85 loss: 8.95112133026123 Mean Grad Norm: 3.274937629699707\n",
      "custom_loss_function steps: 26880 output dim: 414 loss: 0.00032750237733125687 Mean Grad Norm: 3.275023937225342\n",
      "custom_loss_function steps: 27008 output dim: 198 loss: 0.00032751119579188526 Mean Grad Norm: 3.2751119136810303\n",
      "custom_loss_function steps: 27136 output dim: 293 loss: 0.0003275201306678355 Mean Grad Norm: 3.2752013206481934\n",
      "custom_loss_function steps: 27264 output dim: 251 loss: 0.00032752915285527706 Mean Grad Norm: 3.275291681289673\n",
      "custom_loss_function steps: 27392 output dim: 218 loss: 0.0003275380877312273 Mean Grad Norm: 3.275380849838257\n",
      "custom_loss_function steps: 27520 output dim: 233 loss: 0.0003275471390224993 Mean Grad Norm: 3.2754714488983154\n",
      "custom_loss_function steps: 27648 output dim: 168 loss: 0.0003275560156907886 Mean Grad Norm: 3.2755603790283203\n",
      "custom_loss_function steps: 27776 output dim: 102 loss: 0.0003275644266977906 Mean Grad Norm: 3.275644302368164\n",
      "custom_loss_function steps: 27904 output dim: 158 loss: 0.00032757301232777536 Mean Grad Norm: 3.2757301330566406\n",
      "custom_loss_function steps: 28032 output dim: 46 loss: 11.07859992980957 Mean Grad Norm: 3.2758185863494873\n",
      "custom_loss_function steps: 28160 output dim: 94 loss: 0.00032759085297584534 Mean Grad Norm: 3.2759084701538086\n",
      "custom_loss_function steps: 28288 output dim: 133 loss: 0.0003276000206824392 Mean Grad Norm: 3.2760002613067627\n",
      "custom_loss_function steps: 28416 output dim: 264 loss: 0.00032760942121967673 Mean Grad Norm: 3.2760941982269287\n",
      "custom_loss_function steps: 28544 output dim: 199 loss: 0.0003276189381722361 Mean Grad Norm: 3.2761893272399902\n",
      "custom_loss_function steps: 28672 output dim: 113 loss: 0.0003276286879554391 Mean Grad Norm: 3.2762868404388428\n",
      "custom_loss_function steps: 28800 output dim: 173 loss: 0.00032763811759650707 Mean Grad Norm: 3.276381254196167\n",
      "custom_loss_function steps: 28928 output dim: 86 loss: 0.00032764754723757505 Mean Grad Norm: 3.276475667953491\n",
      "custom_loss_function steps: 29056 output dim: 305 loss: 0.0003276571223977953 Mean Grad Norm: 3.276571273803711\n",
      "custom_loss_function steps: 29184 output dim: 210 loss: 0.0003276668721809983 Mean Grad Norm: 3.2766687870025635\n",
      "custom_loss_function steps: 29312 output dim: 356 loss: 0.000327676156302914 Mean Grad Norm: 3.276761531829834\n",
      "custom_loss_function steps: 29440 output dim: 118 loss: 0.00032768570235930383 Mean Grad Norm: 3.2768571376800537\n",
      "custom_loss_function steps: 29568 output dim: 100 loss: 0.0003276954230386764 Mean Grad Norm: 3.276954412460327\n",
      "custom_loss_function steps: 29696 output dim: 374 loss: 0.0003277054347563535 Mean Grad Norm: 3.2770543098449707\n",
      "custom_loss_function steps: 29824 output dim: 100 loss: 0.00032771550468169153 Mean Grad Norm: 3.2771551609039307\n",
      "custom_loss_function steps: 29952 output dim: 218 loss: 0.00032772563281469047 Mean Grad Norm: 3.277256488800049\n",
      "custom_loss_function steps: 30080 output dim: 118 loss: 0.0003277354990132153 Mean Grad Norm: 3.2773549556732178\n",
      "custom_loss_function steps: 30208 output dim: 128 loss: 0.00032774562714621425 Mean Grad Norm: 3.277456283569336\n",
      "custom_loss_function steps: 30336 output dim: 231 loss: 0.00032775592990219593 Mean Grad Norm: 3.277559280395508\n",
      "custom_loss_function steps: 30464 output dim: 94 loss: 0.00032776634907349944 Mean Grad Norm: 3.277663469314575\n",
      "custom_loss_function steps: 30592 output dim: 196 loss: 0.0003277769428677857 Mean Grad Norm: 3.2777695655822754\n",
      "custom_loss_function steps: 30720 output dim: 109 loss: 0.0003277876821812242 Mean Grad Norm: 3.277876853942871\n",
      "custom_loss_function steps: 30848 output dim: 131 loss: 0.0003277985379099846 Mean Grad Norm: 3.2779853343963623\n",
      "custom_loss_function steps: 30976 output dim: 243 loss: 0.0003278093645349145 Mean Grad Norm: 3.2780938148498535\n",
      "custom_loss_function steps: 31104 output dim: 80 loss: 9.043985366821289 Mean Grad Norm: 3.2782044410705566\n",
      "custom_loss_function steps: 31232 output dim: 596 loss: 0.00032783171627670527 Mean Grad Norm: 3.2783172130584717\n",
      "custom_loss_function steps: 31360 output dim: 181 loss: 0.00032784309587441385 Mean Grad Norm: 3.2784311771392822\n",
      "custom_loss_function steps: 31488 output dim: 193 loss: 0.00032785453367978334 Mean Grad Norm: 3.278545379638672\n",
      "custom_loss_function steps: 31616 output dim: 374 loss: 0.00032786556403152645 Mean Grad Norm: 3.278655767440796\n",
      "custom_loss_function steps: 31744 output dim: 221 loss: 0.0003278766816947609 Mean Grad Norm: 3.2787668704986572\n",
      "custom_loss_function steps: 31872 output dim: 54 loss: 0.0003278877993579954 Mean Grad Norm: 3.2788779735565186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 32000 output dim: 161 loss: 0.0003278988879173994 Mean Grad Norm: 3.278988838195801\n",
      "custom_loss_function steps: 32128 output dim: 226 loss: 0.00032791023841127753 Mean Grad Norm: 3.279102325439453\n",
      "custom_loss_function steps: 32256 output dim: 126 loss: 0.0003279215598013252 Mean Grad Norm: 3.2792155742645264\n",
      "custom_loss_function steps: 32384 output dim: 273 loss: 0.0003279330558143556 Mean Grad Norm: 3.2793307304382324\n",
      "custom_loss_function steps: 32512 output dim: 90 loss: 8.313007354736328 Mean Grad Norm: 3.279447555541992\n",
      "custom_loss_function steps: 32640 output dim: 378 loss: 0.000327956659020856 Mean Grad Norm: 3.279566764831543\n",
      "custom_loss_function steps: 32768 output dim: 113 loss: 0.000327968766214326 Mean Grad Norm: 3.2796876430511475\n",
      "custom_loss_function steps: 32896 output dim: 146 loss: 0.0003279810189269483 Mean Grad Norm: 3.2798101902008057\n",
      "custom_loss_function steps: 33024 output dim: 411 loss: 0.0003279933298472315 Mean Grad Norm: 3.279933452606201\n",
      "custom_loss_function steps: 33152 output dim: 336 loss: 0.00032800526241771877 Mean Grad Norm: 3.280052661895752\n",
      "custom_loss_function steps: 33280 output dim: 131 loss: 0.00032801731140352786 Mean Grad Norm: 3.2801730632781982\n",
      "custom_loss_function steps: 33408 output dim: 110 loss: 8.92202091217041 Mean Grad Norm: 3.2802939414978027\n",
      "custom_loss_function steps: 33536 output dim: 109 loss: 0.0003280413511674851 Mean Grad Norm: 3.2804136276245117\n",
      "custom_loss_function steps: 33664 output dim: 152 loss: 0.00032805357477627695 Mean Grad Norm: 3.280535936355591\n",
      "custom_loss_function steps: 33792 output dim: 213 loss: 0.00032806582748889923 Mean Grad Norm: 3.280658483505249\n",
      "custom_loss_function steps: 33920 output dim: 245 loss: 0.0003280783421359956 Mean Grad Norm: 3.2807834148406982\n",
      "custom_loss_function steps: 34048 output dim: 160 loss: 0.00032809030381031334 Mean Grad Norm: 3.2809031009674072\n",
      "custom_loss_function steps: 34176 output dim: 149 loss: 0.00032810246921144426 Mean Grad Norm: 3.281024694442749\n",
      "custom_loss_function steps: 34304 output dim: 162 loss: 0.00032811396522447467 Mean Grad Norm: 3.281139612197876\n",
      "custom_loss_function steps: 34432 output dim: 104 loss: 0.0003281257813796401 Mean Grad Norm: 3.2812578678131104\n",
      "custom_loss_function steps: 34560 output dim: 130 loss: 0.0003281376848462969 Mean Grad Norm: 3.281376838684082\n",
      "custom_loss_function steps: 34688 output dim: 73 loss: 6.568285942077637 Mean Grad Norm: 3.281496524810791\n",
      "custom_loss_function steps: 34816 output dim: 149 loss: 0.00032816192833706737 Mean Grad Norm: 3.2816193103790283\n",
      "custom_loss_function steps: 34944 output dim: 456 loss: 0.000328174268361181 Mean Grad Norm: 3.281742811203003\n",
      "custom_loss_function steps: 35072 output dim: 303 loss: 0.0003281867248006165 Mean Grad Norm: 3.281867265701294\n",
      "custom_loss_function steps: 35200 output dim: 155 loss: 0.0003281992394477129 Mean Grad Norm: 3.2819924354553223\n",
      "custom_loss_function steps: 35328 output dim: 181 loss: 0.00032821172499097884 Mean Grad Norm: 3.2821173667907715\n",
      "custom_loss_function steps: 35456 output dim: 154 loss: 0.0003282238612882793 Mean Grad Norm: 3.282238721847534\n",
      "custom_loss_function steps: 35584 output dim: 142 loss: 0.00032823620131239295 Mean Grad Norm: 3.282362222671509\n",
      "custom_loss_function steps: 35712 output dim: 229 loss: 0.0003282483376096934 Mean Grad Norm: 3.2824833393096924\n",
      "custom_loss_function steps: 35840 output dim: 310 loss: 0.0003282605030108243 Mean Grad Norm: 3.2826051712036133\n",
      "custom_loss_function steps: 35968 output dim: 96 loss: 0.0003282730467617512 Mean Grad Norm: 3.2827305793762207\n",
      "custom_loss_function steps: 36096 output dim: 146 loss: 0.00032828564872033894 Mean Grad Norm: 3.2828567028045654\n",
      "custom_loss_function steps: 36224 output dim: 251 loss: 0.00032829836709424853 Mean Grad Norm: 3.2829837799072266\n",
      "custom_loss_function steps: 36352 output dim: 255 loss: 0.0003283105615992099 Mean Grad Norm: 3.2831056118011475\n",
      "custom_loss_function steps: 36480 output dim: 335 loss: 0.000328322930727154 Mean Grad Norm: 3.283229351043701\n",
      "custom_loss_function steps: 36608 output dim: 255 loss: 0.00032833515433594584 Mean Grad Norm: 3.2833516597747803\n",
      "custom_loss_function steps: 36736 output dim: 141 loss: 0.00032834685407578945 Mean Grad Norm: 3.283468723297119\n",
      "custom_loss_function steps: 36864 output dim: 165 loss: 0.00032835843740031123 Mean Grad Norm: 3.2835845947265625\n",
      "custom_loss_function steps: 36992 output dim: 144 loss: 0.0003283698169980198 Mean Grad Norm: 3.283698320388794\n",
      "custom_loss_function steps: 37120 output dim: 203 loss: 0.0003283810510765761 Mean Grad Norm: 3.283810615539551\n",
      "custom_loss_function steps: 37248 output dim: 144 loss: 0.0003283925470896065 Mean Grad Norm: 3.2839255332946777\n",
      "custom_loss_function steps: 37376 output dim: 264 loss: 0.0003284043341409415 Mean Grad Norm: 3.284043550491333\n",
      "custom_loss_function steps: 37504 output dim: 119 loss: 0.0003284165868535638 Mean Grad Norm: 3.284165859222412\n",
      "custom_loss_function steps: 37632 output dim: 266 loss: 0.00032842904329299927 Mean Grad Norm: 3.2842905521392822\n",
      "custom_loss_function steps: 37760 output dim: 198 loss: 0.0003284404519945383 Mean Grad Norm: 3.2844045162200928\n",
      "custom_loss_function steps: 37888 output dim: 107 loss: 7.6453704833984375 Mean Grad Norm: 3.284522533416748\n",
      "custom_loss_function steps: 38016 output dim: 312 loss: 0.0003284644626546651 Mean Grad Norm: 3.284644842147827\n",
      "custom_loss_function steps: 38144 output dim: 168 loss: 0.00032847642432898283 Mean Grad Norm: 3.284764289855957\n",
      "custom_loss_function steps: 38272 output dim: 283 loss: 0.0003284884733147919 Mean Grad Norm: 3.2848849296569824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 38400 output dim: 257 loss: 0.0003285005805082619 Mean Grad Norm: 3.285005807876587\n",
      "custom_loss_function steps: 38528 output dim: 196 loss: 0.0003285129205323756 Mean Grad Norm: 3.2851293087005615\n",
      "custom_loss_function steps: 38656 output dim: 240 loss: 0.0003285255515947938 Mean Grad Norm: 3.2852556705474854\n",
      "custom_loss_function steps: 38784 output dim: 139 loss: 0.0003285384736955166 Mean Grad Norm: 3.2853848934173584\n",
      "custom_loss_function steps: 38912 output dim: 202 loss: 0.0003285511047579348 Mean Grad Norm: 3.285511016845703\n",
      "custom_loss_function steps: 39040 output dim: 82 loss: 8.7376708984375 Mean Grad Norm: 3.285640239715576\n",
      "custom_loss_function steps: 39168 output dim: 166 loss: 12.081089973449707 Mean Grad Norm: 3.2857725620269775\n",
      "custom_loss_function steps: 39296 output dim: 164 loss: 0.00032859083148650825 Mean Grad Norm: 3.2859084606170654\n",
      "custom_loss_function steps: 39424 output dim: 85 loss: 7.7744669914245605 Mean Grad Norm: 3.286045551300049\n",
      "custom_loss_function steps: 39552 output dim: 139 loss: 0.0003286183637101203 Mean Grad Norm: 3.2861835956573486\n",
      "custom_loss_function steps: 39680 output dim: 67 loss: 0.00032863233354873955 Mean Grad Norm: 3.286323308944702\n",
      "custom_loss_function steps: 39808 output dim: 139 loss: 0.0003286463615950197 Mean Grad Norm: 3.286463737487793\n",
      "custom_loss_function steps: 39936 output dim: 67 loss: 0.00032866070978343487 Mean Grad Norm: 3.286607265472412\n",
      "custom_loss_function steps: 40064 output dim: 180 loss: 0.00032867526169866323 Mean Grad Norm: 3.286752700805664\n",
      "custom_loss_function steps: 40192 output dim: 99 loss: 0.0003286900755483657 Mean Grad Norm: 3.286900758743286\n",
      "custom_loss_function steps: 40320 output dim: 67 loss: 0.00032870518043637276 Mean Grad Norm: 3.2870519161224365\n",
      "custom_loss_function steps: 40448 output dim: 113 loss: 0.00032871990697458386 Mean Grad Norm: 3.2871992588043213\n",
      "custom_loss_function steps: 40576 output dim: 274 loss: 0.00032873477903194726 Mean Grad Norm: 3.2873477935791016\n",
      "custom_loss_function steps: 40704 output dim: 383 loss: 0.0003287498257122934 Mean Grad Norm: 3.2874984741210938\n",
      "custom_loss_function steps: 40832 output dim: 221 loss: 0.00032876513432711363 Mean Grad Norm: 3.287651300430298\n",
      "custom_loss_function steps: 40960 output dim: 189 loss: 0.0003287805011495948 Mean Grad Norm: 3.2878050804138184\n",
      "custom_loss_function steps: 41088 output dim: 274 loss: 0.00032879557693377137 Mean Grad Norm: 3.2879557609558105\n",
      "custom_loss_function steps: 41216 output dim: 271 loss: 0.0003288105071987957 Mean Grad Norm: 3.288105010986328\n",
      "custom_loss_function steps: 41344 output dim: 232 loss: 0.00032882567029446363 Mean Grad Norm: 3.2882566452026367\n",
      "custom_loss_function steps: 41472 output dim: 70 loss: 0.0003288407460786402 Mean Grad Norm: 3.288407564163208\n",
      "custom_loss_function steps: 41600 output dim: 387 loss: 0.0003288559091743082 Mean Grad Norm: 3.2885591983795166\n",
      "custom_loss_function steps: 41728 output dim: 226 loss: 0.0003288713051006198 Mean Grad Norm: 3.288713216781616\n",
      "custom_loss_function steps: 41856 output dim: 177 loss: 0.0003288865846116096 Mean Grad Norm: 3.288865804672241\n",
      "custom_loss_function steps: 41984 output dim: 189 loss: 0.0003289019223302603 Mean Grad Norm: 3.2890193462371826\n",
      "custom_loss_function steps: 42112 output dim: 68 loss: 7.317643642425537 Mean Grad Norm: 3.2891690731048584\n",
      "custom_loss_function steps: 42240 output dim: 143 loss: 8.452885627746582 Mean Grad Norm: 3.289318323135376\n",
      "custom_loss_function steps: 42368 output dim: 289 loss: 0.0003289464220870286 Mean Grad Norm: 3.289464235305786\n",
      "custom_loss_function steps: 42496 output dim: 143 loss: 0.0003289613523520529 Mean Grad Norm: 3.289613723754883\n",
      "custom_loss_function steps: 42624 output dim: 103 loss: 0.00032897628261707723 Mean Grad Norm: 3.2897629737854004\n",
      "custom_loss_function steps: 42752 output dim: 292 loss: 0.00032899106736294925 Mean Grad Norm: 3.2899107933044434\n",
      "custom_loss_function steps: 42880 output dim: 124 loss: 9.668256759643555 Mean Grad Norm: 3.2900547981262207\n",
      "custom_loss_function steps: 43008 output dim: 119 loss: 0.0003290200256742537 Mean Grad Norm: 3.2902002334594727\n",
      "custom_loss_function steps: 43136 output dim: 135 loss: 0.0003290345484856516 Mean Grad Norm: 3.2903454303741455\n",
      "custom_loss_function steps: 43264 output dim: 88 loss: 0.00032904924592003226 Mean Grad Norm: 3.290492534637451\n",
      "custom_loss_function steps: 43392 output dim: 342 loss: 0.0003290640306659043 Mean Grad Norm: 3.290640354156494\n",
      "custom_loss_function steps: 43520 output dim: 198 loss: 0.0003290789027232677 Mean Grad Norm: 3.2907891273498535\n",
      "custom_loss_function steps: 43648 output dim: 233 loss: 0.0003290938038844615 Mean Grad Norm: 3.290938138961792\n",
      "custom_loss_function steps: 43776 output dim: 81 loss: 0.00032910870504565537 Mean Grad Norm: 3.2910871505737305\n",
      "custom_loss_function steps: 43904 output dim: 94 loss: 0.0003291236353106797 Mean Grad Norm: 3.291236400604248\n",
      "custom_loss_function steps: 44032 output dim: 110 loss: 0.0003291385364718735 Mean Grad Norm: 3.2913854122161865\n",
      "custom_loss_function steps: 44160 output dim: 85 loss: 0.0003291538741905242 Mean Grad Norm: 3.291538953781128\n",
      "custom_loss_function steps: 44288 output dim: 416 loss: 0.0003291695611551404 Mean Grad Norm: 3.2916958332061768\n",
      "custom_loss_function steps: 44416 output dim: 181 loss: 0.0003291846951469779 Mean Grad Norm: 3.291846990585327\n",
      "custom_loss_function steps: 44544 output dim: 163 loss: 0.00032920006196945906 Mean Grad Norm: 3.2920007705688477\n",
      "custom_loss_function steps: 44672 output dim: 89 loss: 0.0003292156907264143 Mean Grad Norm: 3.292156934738159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 44800 output dim: 100 loss: 0.0003292315232101828 Mean Grad Norm: 3.2923152446746826\n",
      "custom_loss_function steps: 44928 output dim: 151 loss: 0.0003292470646556467 Mean Grad Norm: 3.292470693588257\n",
      "custom_loss_function steps: 45056 output dim: 106 loss: 7.847816467285156 Mean Grad Norm: 3.2926275730133057\n",
      "custom_loss_function steps: 45184 output dim: 123 loss: 0.0003292784676887095 Mean Grad Norm: 3.2927846908569336\n",
      "custom_loss_function steps: 45312 output dim: 318 loss: 0.00032929424196481705 Mean Grad Norm: 3.292942523956299\n",
      "custom_loss_function steps: 45440 output dim: 92 loss: 0.00032931030727922916 Mean Grad Norm: 3.2931032180786133\n",
      "custom_loss_function steps: 45568 output dim: 123 loss: 0.00032932584872469306 Mean Grad Norm: 3.2932584285736084\n",
      "custom_loss_function steps: 45696 output dim: 54 loss: 0.00032934112823568285 Mean Grad Norm: 3.2934112548828125\n",
      "custom_loss_function steps: 45824 output dim: 126 loss: 0.0003293563495390117 Mean Grad Norm: 3.2935636043548584\n",
      "custom_loss_function steps: 45952 output dim: 598 loss: 0.0003293715708423406 Mean Grad Norm: 3.293715715408325\n",
      "custom_loss_function steps: 46080 output dim: 63 loss: 8.846161842346191 Mean Grad Norm: 3.2938687801361084\n",
      "custom_loss_function steps: 46208 output dim: 153 loss: 0.0003294018970336765 Mean Grad Norm: 3.2940189838409424\n",
      "custom_loss_function steps: 46336 output dim: 267 loss: 0.00032941726385615766 Mean Grad Norm: 3.294172763824463\n",
      "custom_loss_function steps: 46464 output dim: 178 loss: 0.0003294327179901302 Mean Grad Norm: 3.2943272590637207\n",
      "custom_loss_function steps: 46592 output dim: 205 loss: 0.0003294483758509159 Mean Grad Norm: 3.2944839000701904\n",
      "custom_loss_function steps: 46720 output dim: 272 loss: 0.00032946435385383666 Mean Grad Norm: 3.2946436405181885\n",
      "custom_loss_function steps: 46848 output dim: 262 loss: 0.00032948044827207923 Mean Grad Norm: 3.294804573059082\n",
      "custom_loss_function steps: 46976 output dim: 149 loss: 0.00032949645537883043 Mean Grad Norm: 3.294964551925659\n",
      "custom_loss_function steps: 47104 output dim: 180 loss: 0.0003295117639936507 Mean Grad Norm: 3.2951178550720215\n",
      "custom_loss_function steps: 47232 output dim: 150 loss: 0.000329526694258675 Mean Grad Norm: 3.295267105102539\n",
      "custom_loss_function steps: 47360 output dim: 91 loss: 0.00032954177004285157 Mean Grad Norm: 3.2954177856445312\n",
      "custom_loss_function steps: 47488 output dim: 303 loss: 0.0003295570204500109 Mean Grad Norm: 3.2955703735351562\n",
      "custom_loss_function steps: 47616 output dim: 95 loss: 0.0003295723581686616 Mean Grad Norm: 3.2957236766815186\n",
      "custom_loss_function steps: 47744 output dim: 89 loss: 9.043347358703613 Mean Grad Norm: 3.2958757877349854\n",
      "custom_loss_function steps: 47872 output dim: 106 loss: 0.00032960341195575893 Mean Grad Norm: 3.296034097671509\n",
      "custom_loss_function steps: 48000 output dim: 129 loss: 0.00032961912802420557 Mean Grad Norm: 3.296191453933716\n",
      "custom_loss_function steps: 48128 output dim: 57 loss: 8.502900123596191 Mean Grad Norm: 3.296348810195923\n",
      "custom_loss_function steps: 48256 output dim: 215 loss: 0.00032965061836875975 Mean Grad Norm: 3.296506404876709\n",
      "custom_loss_function steps: 48384 output dim: 99 loss: 0.00032966621802188456 Mean Grad Norm: 3.2966623306274414\n",
      "custom_loss_function steps: 48512 output dim: 230 loss: 0.00032968170125968754 Mean Grad Norm: 3.2968170642852783\n",
      "custom_loss_function steps: 48640 output dim: 155 loss: 0.00032969698077067733 Mean Grad Norm: 3.2969698905944824\n",
      "custom_loss_function steps: 48768 output dim: 172 loss: 0.0003297126677352935 Mean Grad Norm: 3.2971267700195312\n",
      "custom_loss_function steps: 48896 output dim: 179 loss: 0.00032972870394587517 Mean Grad Norm: 3.2972869873046875\n",
      "custom_loss_function steps: 49024 output dim: 74 loss: 0.00032974500209093094 Mean Grad Norm: 3.297450065612793\n",
      "custom_loss_function steps: 49152 output dim: 343 loss: 0.00032976147485896945 Mean Grad Norm: 3.297614812850952\n",
      "custom_loss_function steps: 49280 output dim: 357 loss: 0.0003297783841844648 Mean Grad Norm: 3.297783851623535\n",
      "custom_loss_function steps: 49408 output dim: 161 loss: 0.00032979456591419876 Mean Grad Norm: 3.297945737838745\n",
      "custom_loss_function steps: 49536 output dim: 276 loss: 0.00032981092226691544 Mean Grad Norm: 3.298109292984009\n",
      "custom_loss_function steps: 49664 output dim: 192 loss: 0.00032982707489281893 Mean Grad Norm: 3.2982707023620605\n",
      "custom_loss_function steps: 49792 output dim: 82 loss: 0.0003298427618574351 Mean Grad Norm: 3.2984278202056885\n",
      "custom_loss_function steps: 49920 output dim: 163 loss: 0.00032985873986035585 Mean Grad Norm: 3.2985875606536865\n",
      "custom_loss_function steps: 50048 output dim: 277 loss: 0.00032987454324029386 Mean Grad Norm: 3.298745632171631\n",
      "custom_loss_function steps: 50176 output dim: 526 loss: 0.0003298908704891801 Mean Grad Norm: 3.2989087104797363\n",
      "custom_loss_function steps: 50304 output dim: 124 loss: 0.0003299068193882704 Mean Grad Norm: 3.2990682125091553\n",
      "custom_loss_function steps: 50432 output dim: 436 loss: 0.00032992332126013935 Mean Grad Norm: 3.2992334365844727\n",
      "custom_loss_function steps: 50560 output dim: 230 loss: 0.0003299395029898733 Mean Grad Norm: 3.2993950843811035\n",
      "custom_loss_function steps: 50688 output dim: 179 loss: 0.0003299559757579118 Mean Grad Norm: 3.2995598316192627\n",
      "custom_loss_function steps: 50816 output dim: 275 loss: 0.0003299723321106285 Mean Grad Norm: 3.2997233867645264\n",
      "custom_loss_function steps: 50944 output dim: 235 loss: 0.00032998836832121015 Mean Grad Norm: 3.2998838424682617\n",
      "custom_loss_function steps: 51072 output dim: 140 loss: 0.0003300036187283695 Mean Grad Norm: 3.3000361919403076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 51200 output dim: 186 loss: 0.0003300191310700029 Mean Grad Norm: 3.3001914024353027\n",
      "custom_loss_function steps: 51328 output dim: 175 loss: 0.00033003505086526275 Mean Grad Norm: 3.3003506660461426\n",
      "custom_loss_function steps: 51456 output dim: 127 loss: 0.000330051378114149 Mean Grad Norm: 3.300513982772827\n",
      "custom_loss_function steps: 51584 output dim: 371 loss: 0.0003300681128166616 Mean Grad Norm: 3.3006811141967773\n",
      "custom_loss_function steps: 51712 output dim: 195 loss: 0.0003300849930383265 Mean Grad Norm: 3.3008499145507812\n",
      "custom_loss_function steps: 51840 output dim: 228 loss: 0.00033010169863700867 Mean Grad Norm: 3.3010170459747314\n",
      "custom_loss_function steps: 51968 output dim: 62 loss: 8.284482955932617 Mean Grad Norm: 3.301187753677368\n",
      "custom_loss_function steps: 52096 output dim: 500 loss: 0.00033013575011864305 Mean Grad Norm: 3.3013575077056885\n",
      "custom_loss_function steps: 52224 output dim: 220 loss: 0.00033015210647135973 Mean Grad Norm: 3.301521062850952\n",
      "custom_loss_function steps: 52352 output dim: 278 loss: 0.00033016857923939824 Mean Grad Norm: 3.3016858100891113\n",
      "custom_loss_function steps: 52480 output dim: 251 loss: 0.00033018484828062356 Mean Grad Norm: 3.3018486499786377\n",
      "custom_loss_function steps: 52608 output dim: 757 loss: 0.0003302015538793057 Mean Grad Norm: 3.302015542984009\n",
      "custom_loss_function steps: 52736 output dim: 116 loss: 0.00033021788112819195 Mean Grad Norm: 3.3021788597106934\n",
      "custom_loss_function steps: 52864 output dim: 279 loss: 0.0003302334516774863 Mean Grad Norm: 3.3023345470428467\n",
      "custom_loss_function steps: 52992 output dim: 119 loss: 0.000330248789396137 Mean Grad Norm: 3.302488088607788\n",
      "custom_loss_function steps: 53120 output dim: 114 loss: 0.00033026456367224455 Mean Grad Norm: 3.302645683288574\n",
      "custom_loss_function steps: 53248 output dim: 179 loss: 0.0003302806580904871 Mean Grad Norm: 3.3028066158294678\n",
      "custom_loss_function steps: 53376 output dim: 110 loss: 0.0003302969562355429 Mean Grad Norm: 3.3029696941375732\n",
      "custom_loss_function steps: 53504 output dim: 132 loss: 0.0003303128178231418 Mean Grad Norm: 3.303128242492676\n",
      "custom_loss_function steps: 53632 output dim: 196 loss: 0.0003303287085145712 Mean Grad Norm: 3.3032870292663574\n",
      "custom_loss_function steps: 53760 output dim: 241 loss: 0.0003303449193481356 Mean Grad Norm: 3.3034491539001465\n",
      "custom_loss_function steps: 53888 output dim: 62 loss: 7.405072212219238 Mean Grad Norm: 3.3036081790924072\n",
      "custom_loss_function steps: 54016 output dim: 108 loss: 0.00033037696266546845 Mean Grad Norm: 3.303769588470459\n",
      "custom_loss_function steps: 54144 output dim: 112 loss: 0.0003303934063296765 Mean Grad Norm: 3.303934097290039\n",
      "custom_loss_function steps: 54272 output dim: 93 loss: 0.0003304097626823932 Mean Grad Norm: 3.3040976524353027\n",
      "custom_loss_function steps: 54400 output dim: 80 loss: 0.00033042579889297485 Mean Grad Norm: 3.304258108139038\n",
      "custom_loss_function steps: 54528 output dim: 210 loss: 0.0003304414567537606 Mean Grad Norm: 3.304414749145508\n",
      "custom_loss_function steps: 54656 output dim: 306 loss: 0.0003304573765490204 Mean Grad Norm: 3.3045737743377686\n",
      "custom_loss_function steps: 54784 output dim: 110 loss: 0.0003304731799289584 Mean Grad Norm: 3.304731845855713\n",
      "custom_loss_function steps: 54912 output dim: 98 loss: 0.00033048971090465784 Mean Grad Norm: 3.3048970699310303\n",
      "custom_loss_function steps: 55040 output dim: 102 loss: 0.000330505397869274 Mean Grad Norm: 3.305054187774658\n",
      "custom_loss_function steps: 55168 output dim: 153 loss: 0.0003305204736534506 Mean Grad Norm: 3.3052048683166504\n",
      "custom_loss_function steps: 55296 output dim: 437 loss: 0.00033053572406060994 Mean Grad Norm: 3.3053572177886963\n",
      "custom_loss_function steps: 55424 output dim: 113 loss: 0.00033055152744054794 Mean Grad Norm: 3.3055152893066406\n",
      "custom_loss_function steps: 55552 output dim: 186 loss: 0.0003305672435089946 Mean Grad Norm: 3.3056724071502686\n",
      "custom_loss_function steps: 55680 output dim: 224 loss: 0.0003305833088234067 Mean Grad Norm: 3.305833101272583\n",
      "custom_loss_function steps: 55808 output dim: 89 loss: 0.00033059975248761475 Mean Grad Norm: 3.305997610092163\n",
      "custom_loss_function steps: 55936 output dim: 345 loss: 0.0003306160506326705 Mean Grad Norm: 3.3061606884002686\n",
      "custom_loss_function steps: 56064 output dim: 75 loss: 0.0003306316211819649 Mean Grad Norm: 3.306316375732422\n",
      "custom_loss_function steps: 56192 output dim: 103 loss: 0.000330647686496377 Mean Grad Norm: 3.3064768314361572\n",
      "custom_loss_function steps: 56320 output dim: 98 loss: 0.0003306638391222805 Mean Grad Norm: 3.306638479232788\n",
      "custom_loss_function steps: 56448 output dim: 133 loss: 0.0003306791768409312 Mean Grad Norm: 3.3067917823791504\n",
      "custom_loss_function steps: 56576 output dim: 282 loss: 0.0003306946309749037 Mean Grad Norm: 3.306946277618408\n",
      "custom_loss_function steps: 56704 output dim: 63 loss: 7.800923824310303 Mean Grad Norm: 3.3071045875549316\n",
      "custom_loss_function steps: 56832 output dim: 256 loss: 0.0003307264996692538 Mean Grad Norm: 3.307265043258667\n",
      "custom_loss_function steps: 56960 output dim: 252 loss: 0.00033074268139898777 Mean Grad Norm: 3.307426929473877\n",
      "custom_loss_function steps: 57088 output dim: 85 loss: 0.0003307582519482821 Mean Grad Norm: 3.3075826168060303\n",
      "custom_loss_function steps: 57216 output dim: 278 loss: 0.0003307741426397115 Mean Grad Norm: 3.307741641998291\n",
      "custom_loss_function steps: 57344 output dim: 187 loss: 0.0003307907609269023 Mean Grad Norm: 3.3079075813293457\n",
      "custom_loss_function steps: 57472 output dim: 109 loss: 0.0003308072919026017 Mean Grad Norm: 3.308073043823242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 57600 output dim: 75 loss: 0.00033082376467064023 Mean Grad Norm: 3.3082377910614014\n",
      "custom_loss_function steps: 57728 output dim: 140 loss: 0.0003308399172965437 Mean Grad Norm: 3.308399200439453\n",
      "custom_loss_function steps: 57856 output dim: 74 loss: 10.938331604003906 Mean Grad Norm: 3.3085601329803467\n",
      "custom_loss_function steps: 57984 output dim: 149 loss: 0.0003308729501441121 Mean Grad Norm: 3.308729648590088\n",
      "custom_loss_function steps: 58112 output dim: 260 loss: 0.00033089006319642067 Mean Grad Norm: 3.3089005947113037\n",
      "custom_loss_function steps: 58240 output dim: 277 loss: 0.0003309075254946947 Mean Grad Norm: 3.309075355529785\n",
      "custom_loss_function steps: 58368 output dim: 233 loss: 0.0003309250751044601 Mean Grad Norm: 3.309250831604004\n",
      "custom_loss_function steps: 58496 output dim: 200 loss: 0.0003309430612716824 Mean Grad Norm: 3.3094308376312256\n",
      "custom_loss_function steps: 58624 output dim: 104 loss: 0.0003309610183350742 Mean Grad Norm: 3.309610366821289\n",
      "custom_loss_function steps: 58752 output dim: 111 loss: 0.0003309784806333482 Mean Grad Norm: 3.3097848892211914\n",
      "custom_loss_function steps: 58880 output dim: 377 loss: 0.0003309957101009786 Mean Grad Norm: 3.309957265853882\n",
      "custom_loss_function steps: 59008 output dim: 120 loss: 0.00033101311419159174 Mean Grad Norm: 3.310131311416626\n",
      "custom_loss_function steps: 59136 output dim: 125 loss: 0.00033102993620559573 Mean Grad Norm: 3.3102993965148926\n",
      "custom_loss_function steps: 59264 output dim: 95 loss: 0.00033104620524682105 Mean Grad Norm: 3.310462236404419\n",
      "custom_loss_function steps: 59392 output dim: 137 loss: 0.00033106235787272453 Mean Grad Norm: 3.3106236457824707\n",
      "custom_loss_function steps: 59520 output dim: 150 loss: 0.00033107836497947574 Mean Grad Norm: 3.310783624649048\n",
      "custom_loss_function steps: 59648 output dim: 101 loss: 0.0003310944593977183 Mean Grad Norm: 3.3109447956085205\n",
      "custom_loss_function steps: 59776 output dim: 162 loss: 0.0003311102045699954 Mean Grad Norm: 3.3111021518707275\n",
      "custom_loss_function steps: 59904 output dim: 193 loss: 0.00033112545497715473 Mean Grad Norm: 3.3112547397613525\n",
      "custom_loss_function steps: 60032 output dim: 100 loss: 0.000331140763591975 Mean Grad Norm: 3.3114078044891357\n",
      "custom_loss_function steps: 60160 output dim: 199 loss: 8.952351570129395 Mean Grad Norm: 3.3115592002868652\n",
      "custom_loss_function steps: 60288 output dim: 83 loss: 7.028526782989502 Mean Grad Norm: 3.3117077350616455\n",
      "custom_loss_function steps: 60416 output dim: 194 loss: 0.00033118651481345296 Mean Grad Norm: 3.3118650913238525\n",
      "custom_loss_function steps: 60544 output dim: 196 loss: 0.00033120240550488234 Mean Grad Norm: 3.3120241165161133\n",
      "custom_loss_function steps: 60672 output dim: 110 loss: 0.000331218761857599 Mean Grad Norm: 3.312187671661377\n",
      "custom_loss_function steps: 60800 output dim: 92 loss: 0.00033123503089882433 Mean Grad Norm: 3.3123505115509033\n",
      "custom_loss_function steps: 60928 output dim: 195 loss: 0.0003312516782898456 Mean Grad Norm: 3.312516927719116\n",
      "custom_loss_function steps: 61056 output dim: 248 loss: 0.000331268209265545 Mean Grad Norm: 3.3126821517944336\n",
      "custom_loss_function steps: 61184 output dim: 186 loss: 0.000331284711137414 Mean Grad Norm: 3.312847137451172\n",
      "custom_loss_function steps: 61312 output dim: 203 loss: 0.0003313013294246048 Mean Grad Norm: 3.3130133152008057\n",
      "custom_loss_function steps: 61440 output dim: 298 loss: 0.00033131756936199963 Mean Grad Norm: 3.313175916671753\n",
      "custom_loss_function steps: 61568 output dim: 431 loss: 0.0003313335473649204 Mean Grad Norm: 3.313335657119751\n",
      "custom_loss_function steps: 61696 output dim: 131 loss: 0.0003313495544716716 Mean Grad Norm: 3.313495635986328\n",
      "custom_loss_function steps: 61824 output dim: 124 loss: 0.0003313646884635091 Mean Grad Norm: 3.3136470317840576\n",
      "custom_loss_function steps: 61952 output dim: 93 loss: 7.681271076202393 Mean Grad Norm: 3.313791513442993\n",
      "custom_loss_function steps: 62080 output dim: 106 loss: 0.00033139431616291404 Mean Grad Norm: 3.313943386077881\n",
      "custom_loss_function steps: 62208 output dim: 58 loss: 7.242653846740723 Mean Grad Norm: 3.3140978813171387\n",
      "custom_loss_function steps: 62336 output dim: 282 loss: 0.00033142536995001137 Mean Grad Norm: 3.314253807067871\n",
      "custom_loss_function steps: 62464 output dim: 125 loss: 0.00033144073677249253 Mean Grad Norm: 3.3144073486328125\n",
      "custom_loss_function steps: 62592 output dim: 280 loss: 0.00033145659836009145 Mean Grad Norm: 3.314566135406494\n",
      "custom_loss_function steps: 62720 output dim: 220 loss: 0.00033147187787108123 Mean Grad Norm: 3.3147189617156982\n",
      "custom_loss_function steps: 62848 output dim: 153 loss: 0.0003314868954475969 Mean Grad Norm: 3.3148691654205322\n",
      "custom_loss_function steps: 62976 output dim: 135 loss: 0.00033150194212794304 Mean Grad Norm: 3.315019369125366\n",
      "custom_loss_function steps: 63104 output dim: 286 loss: 0.0003315149515401572 Mean Grad Norm: 3.3151495456695557\n",
      "custom_loss_function steps: 63232 output dim: 85 loss: 0.00033152842661365867 Mean Grad Norm: 3.315284490585327\n",
      "custom_loss_function steps: 63360 output dim: 127 loss: 0.00033154190168716013 Mean Grad Norm: 3.3154189586639404\n",
      "custom_loss_function steps: 63488 output dim: 145 loss: 0.00033155534765683115 Mean Grad Norm: 3.315553665161133\n",
      "custom_loss_function steps: 63616 output dim: 79 loss: 7.173846244812012 Mean Grad Norm: 3.315687894821167\n",
      "custom_loss_function steps: 63744 output dim: 262 loss: 0.00033158267615363 Mean Grad Norm: 3.315826892852783\n",
      "custom_loss_function steps: 63872 output dim: 97 loss: 0.0003315966168884188 Mean Grad Norm: 3.3159663677215576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 64000 output dim: 118 loss: 0.00033161125611513853 Mean Grad Norm: 3.316112756729126\n",
      "custom_loss_function steps: 64128 output dim: 280 loss: 0.00033162624458782375 Mean Grad Norm: 3.3162624835968018\n",
      "custom_loss_function steps: 64256 output dim: 320 loss: 0.00033164091291837394 Mean Grad Norm: 3.316409111022949\n",
      "custom_loss_function steps: 64384 output dim: 174 loss: 0.0003316558140795678 Mean Grad Norm: 3.3165581226348877\n",
      "custom_loss_function steps: 64512 output dim: 189 loss: 0.0003316686488687992 Mean Grad Norm: 3.3166866302490234\n",
      "custom_loss_function steps: 64640 output dim: 140 loss: 0.00033168165828101337 Mean Grad Norm: 3.316816806793213\n",
      "custom_loss_function steps: 64768 output dim: 134 loss: 0.00033169559901580215 Mean Grad Norm: 3.316956043243408\n",
      "custom_loss_function steps: 64896 output dim: 179 loss: 0.0003317094233352691 Mean Grad Norm: 3.317094326019287\n",
      "custom_loss_function steps: 65024 output dim: 206 loss: 0.00033172284020110965 Mean Grad Norm: 3.3172285556793213\n",
      "custom_loss_function steps: 65152 output dim: 101 loss: 0.00033173643168993294 Mean Grad Norm: 3.317364454269409\n",
      "custom_loss_function steps: 65280 output dim: 340 loss: 0.00033175013959407806 Mean Grad Norm: 3.3175015449523926\n",
      "custom_loss_function steps: 65408 output dim: 278 loss: 0.00033176341094076633 Mean Grad Norm: 3.317634105682373\n",
      "custom_loss_function steps: 65536 output dim: 98 loss: 0.00033177685691043735 Mean Grad Norm: 3.3177685737609863\n",
      "custom_loss_function steps: 65664 output dim: 130 loss: 0.0003317907394375652 Mean Grad Norm: 3.3179073333740234\n",
      "custom_loss_function steps: 65792 output dim: 149 loss: 0.000331803981680423 Mean Grad Norm: 3.318039894104004\n",
      "custom_loss_function steps: 65920 output dim: 266 loss: 0.0003318180388305336 Mean Grad Norm: 3.318180561065674\n",
      "custom_loss_function steps: 66048 output dim: 178 loss: 0.0003318319213576615 Mean Grad Norm: 3.318319320678711\n",
      "custom_loss_function steps: 66176 output dim: 152 loss: 0.0003318465023767203 Mean Grad Norm: 3.318465232849121\n",
      "custom_loss_function steps: 66304 output dim: 443 loss: 0.00033186099608428776 Mean Grad Norm: 3.3186099529266357\n",
      "custom_loss_function steps: 66432 output dim: 147 loss: 0.0003318751114420593 Mean Grad Norm: 3.318751096725464\n",
      "custom_loss_function steps: 66560 output dim: 85 loss: 0.00033188884845003486 Mean Grad Norm: 3.3188884258270264\n",
      "custom_loss_function steps: 66688 output dim: 214 loss: 0.00033190191606990993 Mean Grad Norm: 3.319019317626953\n",
      "custom_loss_function steps: 66816 output dim: 83 loss: 0.00033191469265148044 Mean Grad Norm: 3.3191471099853516\n",
      "custom_loss_function steps: 66944 output dim: 253 loss: 0.00033192746923305094 Mean Grad Norm: 3.319274663925171\n",
      "custom_loss_function steps: 67072 output dim: 100 loss: 0.0003319403331261128 Mean Grad Norm: 3.3194034099578857\n",
      "custom_loss_function steps: 67200 output dim: 74 loss: 0.0003319544775877148 Mean Grad Norm: 3.319544792175293\n",
      "custom_loss_function steps: 67328 output dim: 84 loss: 0.00033196923322975636 Mean Grad Norm: 3.319692373275757\n",
      "custom_loss_function steps: 67456 output dim: 100 loss: 6.449239253997803 Mean Grad Norm: 3.3198435306549072\n",
      "custom_loss_function steps: 67584 output dim: 224 loss: 0.00033199958852492273 Mean Grad Norm: 3.319995880126953\n",
      "custom_loss_function steps: 67712 output dim: 181 loss: 0.00033201489713974297 Mean Grad Norm: 3.3201489448547363\n",
      "custom_loss_function steps: 67840 output dim: 119 loss: 0.0003320300893392414 Mean Grad Norm: 3.320301055908203\n",
      "custom_loss_function steps: 67968 output dim: 156 loss: 0.0003320458927191794 Mean Grad Norm: 3.3204591274261475\n",
      "custom_loss_function steps: 68096 output dim: 240 loss: 0.00033206198713742197 Mean Grad Norm: 3.320620059967041\n",
      "custom_loss_function steps: 68224 output dim: 182 loss: 0.00033207799424417317 Mean Grad Norm: 3.320780038833618\n",
      "custom_loss_function steps: 68352 output dim: 109 loss: 0.0003320937103126198 Mean Grad Norm: 3.320937156677246\n",
      "custom_loss_function steps: 68480 output dim: 497 loss: 0.0003321100084576756 Mean Grad Norm: 3.3211002349853516\n",
      "custom_loss_function steps: 68608 output dim: 112 loss: 0.0003321260155644268 Mean Grad Norm: 3.3212602138519287\n",
      "custom_loss_function steps: 68736 output dim: 124 loss: 7.475627422332764 Mean Grad Norm: 3.321425676345825\n",
      "custom_loss_function steps: 68864 output dim: 309 loss: 0.00033215832081623375 Mean Grad Norm: 3.3215832710266113\n",
      "custom_loss_function steps: 68992 output dim: 100 loss: 0.00033217360032722354 Mean Grad Norm: 3.3217360973358154\n",
      "custom_loss_function steps: 69120 output dim: 227 loss: 0.0003321890835650265 Mean Grad Norm: 3.3218908309936523\n",
      "custom_loss_function steps: 69248 output dim: 133 loss: 0.00033220427576452494 Mean Grad Norm: 3.322042942047119\n",
      "custom_loss_function steps: 69376 output dim: 99 loss: 0.00033221879857592285 Mean Grad Norm: 3.322188138961792\n",
      "custom_loss_function steps: 69504 output dim: 70 loss: 7.631135940551758 Mean Grad Norm: 3.322331190109253\n",
      "custom_loss_function steps: 69632 output dim: 101 loss: 0.00033224717481061816 Mean Grad Norm: 3.322471857070923\n",
      "custom_loss_function steps: 69760 output dim: 290 loss: 0.00033226163941435516 Mean Grad Norm: 3.3226165771484375\n",
      "custom_loss_function steps: 69888 output dim: 146 loss: 0.00033227651147171855 Mean Grad Norm: 3.3227651119232178\n",
      "custom_loss_function steps: 70016 output dim: 131 loss: 0.0003322920820210129 Mean Grad Norm: 3.322920799255371\n",
      "custom_loss_function steps: 70144 output dim: 305 loss: 0.00033230677945539355 Mean Grad Norm: 3.3230679035186768\n",
      "custom_loss_function steps: 70272 output dim: 95 loss: 0.0003323211276438087 Mean Grad Norm: 3.323211431503296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /mnt/data/deepseek-math-7b-it-Train10/checkpoint-550 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 170624 output dim: 212 loss: 0.0003401315480004996 Mean Grad Norm: 3.401315689086914\n",
      "custom_loss_function steps: 170752 output dim: 81 loss: 6.341129302978516 Mean Grad Norm: 3.4013874530792236\n",
      "custom_loss_function steps: 170880 output dim: 116 loss: 0.0003401456633582711 Mean Grad Norm: 3.401456594467163\n",
      "custom_loss_function steps: 171008 output dim: 154 loss: 5.660290241241455 Mean Grad Norm: 3.401524782180786\n",
      "custom_loss_function steps: 171136 output dim: 178 loss: 0.00034015881828963757 Mean Grad Norm: 3.401588201522827\n",
      "custom_loss_function steps: 171264 output dim: 313 loss: 0.00034016495919786394 Mean Grad Norm: 3.4016497135162354\n",
      "custom_loss_function steps: 171392 output dim: 168 loss: 0.00034017045982182026 Mean Grad Norm: 3.401704788208008\n",
      "custom_loss_function steps: 171520 output dim: 338 loss: 0.00034017552388831973 Mean Grad Norm: 3.4017553329467773\n",
      "custom_loss_function steps: 171648 output dim: 151 loss: 0.0003401807334739715 Mean Grad Norm: 3.4018075466156006\n",
      "custom_loss_function steps: 171776 output dim: 201 loss: 0.0003401855647098273 Mean Grad Norm: 3.401855707168579\n",
      "custom_loss_function steps: 171904 output dim: 88 loss: 0.0003401897556614131 Mean Grad Norm: 3.401897668838501\n",
      "custom_loss_function steps: 172032 output dim: 206 loss: 0.0003401936264708638 Mean Grad Norm: 3.4019362926483154\n",
      "custom_loss_function steps: 172160 output dim: 175 loss: 0.0003401980211492628 Mean Grad Norm: 3.401980400085449\n",
      "custom_loss_function steps: 172288 output dim: 161 loss: 0.0003402034053578973 Mean Grad Norm: 3.402034044265747\n",
      "custom_loss_function steps: 172416 output dim: 90 loss: 0.00034020934253931046 Mean Grad Norm: 3.4020934104919434\n",
      "custom_loss_function steps: 172544 output dim: 79 loss: 6.687315940856934 Mean Grad Norm: 3.4021506309509277\n",
      "custom_loss_function steps: 172672 output dim: 366 loss: 0.0003402208967600018 Mean Grad Norm: 3.4022090435028076\n",
      "custom_loss_function steps: 172800 output dim: 343 loss: 0.0003402267175260931 Mean Grad Norm: 3.4022672176361084\n",
      "custom_loss_function steps: 172928 output dim: 284 loss: 0.00034023201442323625 Mean Grad Norm: 3.402320146560669\n",
      "custom_loss_function steps: 173056 output dim: 187 loss: 0.0003402371658012271 Mean Grad Norm: 3.402371883392334\n",
      "custom_loss_function steps: 173184 output dim: 347 loss: 0.00034024211345240474 Mean Grad Norm: 3.402421236038208\n",
      "custom_loss_function steps: 173312 output dim: 75 loss: 0.0003402471775189042 Mean Grad Norm: 3.4024717807769775\n",
      "custom_loss_function steps: 173440 output dim: 109 loss: 6.184332370758057 Mean Grad Norm: 3.402519464492798\n",
      "custom_loss_function steps: 173568 output dim: 86 loss: 5.656685829162598 Mean Grad Norm: 3.4025676250457764\n",
      "custom_loss_function steps: 173696 output dim: 349 loss: 0.0003402623115107417 Mean Grad Norm: 3.402623176574707\n",
      "custom_loss_function steps: 173824 output dim: 214 loss: 0.00034026868524961174 Mean Grad Norm: 3.402686834335327\n",
      "custom_loss_function steps: 173952 output dim: 265 loss: 0.00034027572837658226 Mean Grad Norm: 3.402757406234741\n",
      "custom_loss_function steps: 174080 output dim: 174 loss: 0.00034028227673843503 Mean Grad Norm: 3.402822971343994\n",
      "custom_loss_function steps: 174208 output dim: 245 loss: 0.0003402882139198482 Mean Grad Norm: 3.4028820991516113\n",
      "custom_loss_function steps: 174336 output dim: 110 loss: 0.000340293743647635 Mean Grad Norm: 3.402937412261963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 174464 output dim: 76 loss: 0.00034029874950647354 Mean Grad Norm: 3.402987480163574\n",
      "custom_loss_function steps: 174592 output dim: 276 loss: 0.0003403050359338522 Mean Grad Norm: 3.403050422668457\n",
      "custom_loss_function steps: 174720 output dim: 230 loss: 0.00034031111863441765 Mean Grad Norm: 3.403111219406128\n",
      "custom_loss_function steps: 174848 output dim: 163 loss: 0.0003403167356736958 Mean Grad Norm: 3.403167486190796\n",
      "custom_loss_function steps: 174976 output dim: 324 loss: 0.00034032188705168664 Mean Grad Norm: 3.403218984603882\n",
      "custom_loss_function steps: 175104 output dim: 126 loss: 0.00034032727126032114 Mean Grad Norm: 3.403272867202759\n",
      "custom_loss_function steps: 175232 output dim: 499 loss: 0.00034033338306471705 Mean Grad Norm: 3.403333902359009\n",
      "custom_loss_function steps: 175360 output dim: 140 loss: 0.0003403390874154866 Mean Grad Norm: 3.403390884399414\n",
      "custom_loss_function steps: 175488 output dim: 169 loss: 0.00034034429700113833 Mean Grad Norm: 3.4034430980682373\n",
      "custom_loss_function steps: 175616 output dim: 127 loss: 0.00034034979762509465 Mean Grad Norm: 3.4034979343414307\n",
      "custom_loss_function steps: 175744 output dim: 121 loss: 0.00034035553107969463 Mean Grad Norm: 3.403555393218994\n",
      "custom_loss_function steps: 175872 output dim: 236 loss: 0.00034036143915727735 Mean Grad Norm: 3.4036145210266113\n",
      "custom_loss_function steps: 176000 output dim: 99 loss: 5.828446865081787 Mean Grad Norm: 3.4036765098571777\n",
      "custom_loss_function steps: 176128 output dim: 167 loss: 0.00034037407021969557 Mean Grad Norm: 3.403740644454956\n",
      "custom_loss_function steps: 176256 output dim: 486 loss: 0.0003403799782972783 Mean Grad Norm: 3.4038000106811523\n",
      "custom_loss_function steps: 176384 output dim: 73 loss: 0.0003403856244403869 Mean Grad Norm: 3.4038562774658203\n",
      "custom_loss_function steps: 176512 output dim: 128 loss: 0.0003403908631298691 Mean Grad Norm: 3.4039087295532227\n",
      "custom_loss_function steps: 176640 output dim: 183 loss: 6.045191764831543 Mean Grad Norm: 3.4039576053619385\n",
      "custom_loss_function steps: 176768 output dim: 113 loss: 0.00034040043829008937 Mean Grad Norm: 3.4040045738220215\n",
      "custom_loss_function steps: 176896 output dim: 277 loss: 0.00034040529862977564 Mean Grad Norm: 3.404053211212158\n",
      "custom_loss_function steps: 177024 output dim: 116 loss: 0.0003404100425541401 Mean Grad Norm: 3.4041004180908203\n",
      "custom_loss_function steps: 177152 output dim: 89 loss: 0.00034041484468616545 Mean Grad Norm: 3.404148578643799\n",
      "custom_loss_function steps: 177280 output dim: 196 loss: 0.0003404193848837167 Mean Grad Norm: 3.404193878173828\n",
      "custom_loss_function steps: 177408 output dim: 190 loss: 0.0003404250892344862 Mean Grad Norm: 3.4042510986328125\n",
      "custom_loss_function steps: 177536 output dim: 59 loss: 5.662100791931152 Mean Grad Norm: 3.4043052196502686\n",
      "custom_loss_function steps: 177664 output dim: 69 loss: 0.00034043562482111156 Mean Grad Norm: 3.4043562412261963\n",
      "custom_loss_function steps: 177792 output dim: 230 loss: 0.000340440368745476 Mean Grad Norm: 3.4044036865234375\n",
      "custom_loss_function steps: 177920 output dim: 149 loss: 0.000340444763423875 Mean Grad Norm: 3.4044477939605713\n",
      "custom_loss_function steps: 178048 output dim: 108 loss: 0.00034044909989461303 Mean Grad Norm: 3.4044909477233887\n",
      "custom_loss_function steps: 178176 output dim: 112 loss: 0.0003404543094802648 Mean Grad Norm: 3.404543161392212\n",
      "custom_loss_function steps: 178304 output dim: 135 loss: 0.00034046030486933887 Mean Grad Norm: 3.4046030044555664\n",
      "custom_loss_function steps: 178432 output dim: 210 loss: 0.0003404661256354302 Mean Grad Norm: 3.4046614170074463\n",
      "custom_loss_function steps: 178560 output dim: 277 loss: 0.0003404720046091825 Mean Grad Norm: 3.4047200679779053\n",
      "custom_loss_function steps: 178688 output dim: 83 loss: 0.0003404785238672048 Mean Grad Norm: 3.404785394668579\n",
      "custom_loss_function steps: 178816 output dim: 565 loss: 8.818987846374512 Mean Grad Norm: 3.4048514366149902\n",
      "custom_loss_function steps: 178944 output dim: 388 loss: 0.0003404922899790108 Mean Grad Norm: 3.4049229621887207\n",
      "custom_loss_function steps: 179072 output dim: 79 loss: 0.0003405000315979123 Mean Grad Norm: 3.4050004482269287\n",
      "custom_loss_function steps: 179200 output dim: 397 loss: 0.0003405076276976615 Mean Grad Norm: 3.405076503753662\n",
      "custom_loss_function steps: 179328 output dim: 257 loss: 0.00034051589318551123 Mean Grad Norm: 3.4051589965820312\n",
      "custom_loss_function steps: 179456 output dim: 256 loss: 0.0003405247116461396 Mean Grad Norm: 3.405247211456299\n",
      "custom_loss_function steps: 179584 output dim: 225 loss: 0.00034053262788802385 Mean Grad Norm: 3.4053263664245605\n",
      "custom_loss_function steps: 179712 output dim: 88 loss: 5.890897750854492 Mean Grad Norm: 3.405412197113037\n",
      "custom_loss_function steps: 179840 output dim: 403 loss: 0.0003405489260330796 Mean Grad Norm: 3.405489206314087\n",
      "custom_loss_function steps: 179968 output dim: 107 loss: 5.457095623016357 Mean Grad Norm: 3.4055604934692383\n",
      "custom_loss_function steps: 180096 output dim: 138 loss: 0.0003405635361559689 Mean Grad Norm: 3.405635356903076\n",
      "custom_loss_function steps: 180224 output dim: 322 loss: 0.000340570550179109 Mean Grad Norm: 3.405705451965332\n",
      "custom_loss_function steps: 180352 output dim: 777 loss: 0.0003405775350984186 Mean Grad Norm: 3.405775308609009\n",
      "custom_loss_function steps: 180480 output dim: 232 loss: 0.0003405844036024064 Mean Grad Norm: 3.405844211578369\n",
      "custom_loss_function steps: 180608 output dim: 120 loss: 0.0003405905736144632 Mean Grad Norm: 3.4059059619903564\n",
      "custom_loss_function steps: 180736 output dim: 97 loss: 0.0003405962488614023 Mean Grad Norm: 3.4059624671936035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 180864 output dim: 154 loss: 0.0003406012838240713 Mean Grad Norm: 3.406013011932373\n",
      "custom_loss_function steps: 180992 output dim: 311 loss: 0.00034060594043694437 Mean Grad Norm: 3.406059503555298\n",
      "custom_loss_function steps: 181120 output dim: 786 loss: 10.201491355895996 Mean Grad Norm: 3.4061009883880615\n",
      "custom_loss_function steps: 181248 output dim: 123 loss: 0.00034061510814353824 Mean Grad Norm: 3.406151294708252\n",
      "custom_loss_function steps: 181376 output dim: 104 loss: 0.0003406201140023768 Mean Grad Norm: 3.406201124191284\n",
      "custom_loss_function steps: 181504 output dim: 474 loss: 0.00034062567283399403 Mean Grad Norm: 3.406256914138794\n",
      "custom_loss_function steps: 181632 output dim: 141 loss: 0.0003406318719498813 Mean Grad Norm: 3.4063186645507812\n",
      "custom_loss_function steps: 181760 output dim: 161 loss: 0.00034063748898915946 Mean Grad Norm: 3.406374931335449\n",
      "custom_loss_function steps: 181888 output dim: 268 loss: 0.00034064296050928533 Mean Grad Norm: 3.4064297676086426\n",
      "custom_loss_function steps: 182016 output dim: 160 loss: 0.00034064779174514115 Mean Grad Norm: 3.406477928161621\n",
      "custom_loss_function steps: 182144 output dim: 203 loss: 0.00034065230283886194 Mean Grad Norm: 3.4065232276916504\n",
      "custom_loss_function steps: 182272 output dim: 210 loss: 0.00034065707586705685 Mean Grad Norm: 3.4065709114074707\n",
      "custom_loss_function steps: 182400 output dim: 114 loss: 0.0003406611504033208 Mean Grad Norm: 3.406611680984497\n",
      "custom_loss_function steps: 182528 output dim: 256 loss: 0.0003406655159778893 Mean Grad Norm: 3.4066553115844727\n",
      "custom_loss_function steps: 182656 output dim: 135 loss: 0.00034067060914821923 Mean Grad Norm: 3.4067060947418213\n",
      "custom_loss_function steps: 182784 output dim: 291 loss: 0.00034067538217641413 Mean Grad Norm: 3.4067540168762207\n",
      "custom_loss_function steps: 182912 output dim: 111 loss: 0.00034068035893142223 Mean Grad Norm: 3.406803607940674\n",
      "custom_loss_function steps: 183040 output dim: 164 loss: 0.0003406846371944994 Mean Grad Norm: 3.406846523284912\n",
      "custom_loss_function steps: 183168 output dim: 127 loss: 6.093471527099609 Mean Grad Norm: 3.406888484954834\n",
      "custom_loss_function steps: 183296 output dim: 82 loss: 0.0003406936302781105 Mean Grad Norm: 3.4069364070892334\n",
      "custom_loss_function steps: 183424 output dim: 86 loss: 6.084517002105713 Mean Grad Norm: 3.406978130340576\n",
      "custom_loss_function steps: 183552 output dim: 121 loss: 0.0003407029144000262 Mean Grad Norm: 3.407029151916504\n",
      "custom_loss_function steps: 183680 output dim: 140 loss: 0.00034070792025886476 Mean Grad Norm: 3.4070792198181152\n",
      "custom_loss_function steps: 183808 output dim: 237 loss: 0.0003407125186640769 Mean Grad Norm: 3.407125234603882\n",
      "custom_loss_function steps: 183936 output dim: 66 loss: 5.873826026916504 Mean Grad Norm: 3.4071731567382812\n",
      "custom_loss_function steps: 184064 output dim: 239 loss: 0.0003407228796277195 Mean Grad Norm: 3.407228946685791\n",
      "custom_loss_function steps: 184192 output dim: 98 loss: 0.0003407280601095408 Mean Grad Norm: 3.407280683517456\n",
      "custom_loss_function steps: 184320 output dim: 112 loss: 6.21342134475708 Mean Grad Norm: 3.407327175140381\n",
      "custom_loss_function steps: 184448 output dim: 244 loss: 0.00034073705319315195 Mean Grad Norm: 3.4073705673217773\n",
      "custom_loss_function steps: 184576 output dim: 108 loss: 6.285727024078369 Mean Grad Norm: 3.407416820526123\n",
      "custom_loss_function steps: 184704 output dim: 294 loss: 0.0003407459589652717 Mean Grad Norm: 3.4074597358703613\n",
      "custom_loss_function steps: 184832 output dim: 279 loss: 0.0003407500043977052 Mean Grad Norm: 3.4075002670288086\n",
      "custom_loss_function steps: 184960 output dim: 122 loss: 0.00034075393341481686 Mean Grad Norm: 3.4075393676757812\n",
      "custom_loss_function steps: 185088 output dim: 151 loss: 0.0003407581243664026 Mean Grad Norm: 3.407581329345703\n",
      "custom_loss_function steps: 185216 output dim: 190 loss: 0.00034076301380991936 Mean Grad Norm: 3.407630205154419\n",
      "custom_loss_function steps: 185344 output dim: 174 loss: 0.00034076787414960563 Mean Grad Norm: 3.4076788425445557\n",
      "custom_loss_function steps: 185472 output dim: 174 loss: 0.00034077223972417414 Mean Grad Norm: 3.4077224731445312\n",
      "custom_loss_function steps: 185600 output dim: 67 loss: 0.00034077680902555585 Mean Grad Norm: 3.4077682495117188\n",
      "custom_loss_function steps: 185728 output dim: 166 loss: 6.57996129989624 Mean Grad Norm: 3.4078123569488525\n",
      "custom_loss_function steps: 185856 output dim: 138 loss: 0.0003407853946555406 Mean Grad Norm: 3.4078540802001953\n",
      "custom_loss_function steps: 185984 output dim: 162 loss: 0.00034078938188031316 Mean Grad Norm: 3.4078938961029053\n",
      "custom_loss_function steps: 186112 output dim: 172 loss: 0.00034079374745488167 Mean Grad Norm: 3.407937526702881\n",
      "custom_loss_function steps: 186240 output dim: 116 loss: 0.00034079854958690703 Mean Grad Norm: 3.4079854488372803\n",
      "custom_loss_function steps: 186368 output dim: 315 loss: 0.000340802944265306 Mean Grad Norm: 3.408029556274414\n",
      "custom_loss_function steps: 186496 output dim: 106 loss: 0.0003408072516322136 Mean Grad Norm: 3.4080724716186523\n",
      "custom_loss_function steps: 186624 output dim: 85 loss: 0.00034081138437613845 Mean Grad Norm: 3.408113956451416\n",
      "custom_loss_function steps: 186752 output dim: 174 loss: 0.00034081569174304605 Mean Grad Norm: 3.4081571102142334\n",
      "custom_loss_function steps: 186880 output dim: 155 loss: 0.00034081964986398816 Mean Grad Norm: 3.4081966876983643\n",
      "custom_loss_function steps: 187008 output dim: 95 loss: 0.00034082384081557393 Mean Grad Norm: 3.408238410949707\n",
      "custom_loss_function steps: 187136 output dim: 174 loss: 0.0003408278280403465 Mean Grad Norm: 3.408278226852417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 187264 output dim: 87 loss: 6.389671325683594 Mean Grad Norm: 3.4083259105682373\n",
      "custom_loss_function steps: 187392 output dim: 163 loss: 0.00034083740320056677 Mean Grad Norm: 3.408374071121216\n",
      "custom_loss_function steps: 187520 output dim: 228 loss: 0.0003408427583053708 Mean Grad Norm: 3.4084277153015137\n",
      "custom_loss_function steps: 187648 output dim: 70 loss: 0.0003408477932680398 Mean Grad Norm: 3.408478021621704\n",
      "custom_loss_function steps: 187776 output dim: 323 loss: 0.00034085355582647026 Mean Grad Norm: 3.4085357189178467\n",
      "custom_loss_function steps: 187904 output dim: 156 loss: 0.00034085914376191795 Mean Grad Norm: 3.4085915088653564\n",
      "custom_loss_function steps: 188032 output dim: 164 loss: 0.0003408654883969575 Mean Grad Norm: 3.4086549282073975\n",
      "custom_loss_function steps: 188160 output dim: 399 loss: 0.0003408720367588103 Mean Grad Norm: 3.4087204933166504\n",
      "custom_loss_function steps: 188288 output dim: 82 loss: 0.0003408780030440539 Mean Grad Norm: 3.408780097961426\n",
      "custom_loss_function steps: 188416 output dim: 169 loss: 0.0003408839402254671 Mean Grad Norm: 3.408839464187622\n",
      "custom_loss_function steps: 188544 output dim: 169 loss: 0.00034088935353793204 Mean Grad Norm: 3.408893585205078\n",
      "custom_loss_function steps: 188672 output dim: 86 loss: 0.0003408943011891097 Mean Grad Norm: 3.4089431762695312\n",
      "custom_loss_function steps: 188800 output dim: 105 loss: 0.000340898783179 Mean Grad Norm: 3.4089879989624023\n",
      "custom_loss_function steps: 188928 output dim: 139 loss: 0.00034090346889570355 Mean Grad Norm: 3.4090347290039062\n",
      "custom_loss_function steps: 189056 output dim: 82 loss: 5.720098495483398 Mean Grad Norm: 3.4090774059295654\n",
      "custom_loss_function steps: 189184 output dim: 133 loss: 0.00034091182169504464 Mean Grad Norm: 3.409118175506592\n",
      "custom_loss_function steps: 189312 output dim: 201 loss: 0.0003409166820347309 Mean Grad Norm: 3.4091670513153076\n",
      "custom_loss_function steps: 189440 output dim: 467 loss: 0.0003409221535548568 Mean Grad Norm: 3.409221649169922\n",
      "custom_loss_function steps: 189568 output dim: 80 loss: 5.600061416625977 Mean Grad Norm: 3.4092750549316406\n",
      "custom_loss_function steps: 189696 output dim: 251 loss: 6.23370361328125 Mean Grad Norm: 3.4093267917633057\n",
      "custom_loss_function steps: 189824 output dim: 192 loss: 0.0003409386845305562 Mean Grad Norm: 3.4093868732452393\n",
      "custom_loss_function steps: 189952 output dim: 101 loss: 0.00034094424336217344 Mean Grad Norm: 3.409442663192749\n",
      "custom_loss_function steps: 190080 output dim: 112 loss: 0.000340950267855078 Mean Grad Norm: 3.4095027446746826\n",
      "custom_loss_function steps: 190208 output dim: 243 loss: 0.00034095681621693075 Mean Grad Norm: 3.4095683097839355\n",
      "custom_loss_function steps: 190336 output dim: 279 loss: 0.0003409628407098353 Mean Grad Norm: 3.409628391265869\n",
      "custom_loss_function steps: 190464 output dim: 68 loss: 5.772068023681641 Mean Grad Norm: 3.409684419631958\n",
      "custom_loss_function steps: 190592 output dim: 182 loss: 0.00034097471507266164 Mean Grad Norm: 3.4097471237182617\n",
      "custom_loss_function steps: 190720 output dim: 121 loss: 0.00034098158357664943 Mean Grad Norm: 3.409815788269043\n",
      "custom_loss_function steps: 190848 output dim: 155 loss: 0.00034098842297680676 Mean Grad Norm: 3.409884452819824\n",
      "custom_loss_function steps: 190976 output dim: 63 loss: 0.00034099508775398135 Mean Grad Norm: 3.4099509716033936\n",
      "custom_loss_function steps: 191104 output dim: 94 loss: 0.0003410012577660382 Mean Grad Norm: 3.410012722015381\n",
      "custom_loss_function steps: 191232 output dim: 128 loss: 0.00034100760240107775 Mean Grad Norm: 3.410076141357422\n",
      "custom_loss_function steps: 191360 output dim: 318 loss: 0.0003410135395824909 Mean Grad Norm: 3.410135507583618\n",
      "custom_loss_function steps: 191488 output dim: 75 loss: 0.00034101883647963405 Mean Grad Norm: 3.4101884365081787\n",
      "custom_loss_function steps: 191616 output dim: 292 loss: 0.00034102381323464215 Mean Grad Norm: 3.410238265991211\n",
      "custom_loss_function steps: 191744 output dim: 98 loss: 5.6960296630859375 Mean Grad Norm: 3.410290002822876\n",
      "custom_loss_function steps: 191872 output dim: 111 loss: 0.00034103382495231926 Mean Grad Norm: 3.4103384017944336\n",
      "custom_loss_function steps: 192000 output dim: 174 loss: 0.00034103941288776696 Mean Grad Norm: 3.4103941917419434\n",
      "custom_loss_function steps: 192128 output dim: 188 loss: 0.00034104473888874054 Mean Grad Norm: 3.410447597503662\n",
      "custom_loss_function steps: 192256 output dim: 318 loss: 0.0003410510835237801 Mean Grad Norm: 3.410511016845703\n",
      "custom_loss_function steps: 192384 output dim: 180 loss: 0.00034105792292393744 Mean Grad Norm: 3.4105794429779053\n",
      "custom_loss_function steps: 192512 output dim: 307 loss: 0.0003410641511436552 Mean Grad Norm: 3.410641670227051\n",
      "custom_loss_function steps: 192640 output dim: 208 loss: 0.00034106997190974653 Mean Grad Norm: 3.4106998443603516\n",
      "custom_loss_function steps: 192768 output dim: 185 loss: 0.00034107512328773737 Mean Grad Norm: 3.4107513427734375\n",
      "custom_loss_function steps: 192896 output dim: 223 loss: 0.00034108012914657593 Mean Grad Norm: 3.410801410675049\n",
      "custom_loss_function steps: 193024 output dim: 189 loss: 0.00034108469844795763 Mean Grad Norm: 3.4108469486236572\n",
      "custom_loss_function steps: 193152 output dim: 138 loss: 0.00034108918043784797 Mean Grad Norm: 3.4108917713165283\n",
      "custom_loss_function steps: 193280 output dim: 189 loss: 0.0003410939534660429 Mean Grad Norm: 3.4109396934509277\n",
      "custom_loss_function steps: 193408 output dim: 150 loss: 0.00034109875559806824 Mean Grad Norm: 3.410987615585327\n",
      "custom_loss_function steps: 193536 output dim: 135 loss: 0.00034110393607988954 Mean Grad Norm: 3.411039352416992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 193664 output dim: 461 loss: 0.0003411102807149291 Mean Grad Norm: 3.4111030101776123\n",
      "custom_loss_function steps: 193792 output dim: 82 loss: 5.533032417297363 Mean Grad Norm: 3.411166191101074\n",
      "custom_loss_function steps: 193920 output dim: 352 loss: 0.00034112241701222956 Mean Grad Norm: 3.411224126815796\n",
      "custom_loss_function steps: 194048 output dim: 93 loss: 0.0003411284415051341 Mean Grad Norm: 3.4112844467163086\n",
      "custom_loss_function steps: 194176 output dim: 326 loss: 0.00034113560104742646 Mean Grad Norm: 3.411356210708618\n",
      "custom_loss_function steps: 194304 output dim: 329 loss: 0.0003411422367207706 Mean Grad Norm: 3.4114224910736084\n",
      "custom_loss_function steps: 194432 output dim: 201 loss: 0.00034114852314814925 Mean Grad Norm: 3.411485433578491\n",
      "custom_loss_function steps: 194560 output dim: 115 loss: 0.00034115472226403654 Mean Grad Norm: 3.4115474224090576\n",
      "custom_loss_function steps: 194688 output dim: 85 loss: 4.770191669464111 Mean Grad Norm: 3.4116032123565674\n",
      "custom_loss_function steps: 194816 output dim: 153 loss: 0.0003411658981349319 Mean Grad Norm: 3.411659002304077\n",
      "custom_loss_function steps: 194944 output dim: 118 loss: 0.0003411710204090923 Mean Grad Norm: 3.411710262298584\n",
      "custom_loss_function steps: 195072 output dim: 92 loss: 0.0003411762008909136 Mean Grad Norm: 3.411762237548828\n",
      "custom_loss_function steps: 195200 output dim: 226 loss: 0.00034118094481527805 Mean Grad Norm: 3.4118094444274902\n",
      "custom_loss_function steps: 195328 output dim: 153 loss: 0.0003411859506741166 Mean Grad Norm: 3.4118595123291016\n",
      "custom_loss_function steps: 195456 output dim: 169 loss: 0.00034119095653295517 Mean Grad Norm: 3.411909580230713\n",
      "custom_loss_function steps: 195584 output dim: 77 loss: 0.0003411965153645724 Mean Grad Norm: 3.4119653701782227\n",
      "custom_loss_function steps: 195712 output dim: 186 loss: 0.00034120233613066375 Mean Grad Norm: 3.4120235443115234\n",
      "custom_loss_function steps: 195840 output dim: 209 loss: 0.00034120844793505967 Mean Grad Norm: 3.4120845794677734\n",
      "custom_loss_function steps: 195968 output dim: 120 loss: 0.00034121418138965964 Mean Grad Norm: 3.412142038345337\n",
      "custom_loss_function steps: 196096 output dim: 107 loss: 0.0003412194491829723 Mean Grad Norm: 3.4121944904327393\n",
      "custom_loss_function steps: 196224 output dim: 371 loss: 0.0003412245714571327 Mean Grad Norm: 3.412245750427246\n",
      "custom_loss_function steps: 196352 output dim: 135 loss: 0.0003412295482121408 Mean Grad Norm: 3.4122955799102783\n",
      "custom_loss_function steps: 196480 output dim: 96 loss: 0.00034123423392884433 Mean Grad Norm: 3.4123425483703613\n",
      "custom_loss_function steps: 196608 output dim: 266 loss: 0.0003412386286072433 Mean Grad Norm: 3.412386417388916\n",
      "custom_loss_function steps: 196736 output dim: 296 loss: 0.00034124281955882907 Mean Grad Norm: 3.412428140640259\n",
      "custom_loss_function steps: 196864 output dim: 64 loss: 5.007075309753418 Mean Grad Norm: 3.412466526031494\n",
      "custom_loss_function steps: 196992 output dim: 172 loss: 0.0003412503865547478 Mean Grad Norm: 3.412503957748413\n",
      "custom_loss_function steps: 197120 output dim: 144 loss: 0.0003412541118450463 Mean Grad Norm: 3.412541151046753\n",
      "custom_loss_function steps: 197248 output dim: 177 loss: 5.698037624359131 Mean Grad Norm: 3.412588119506836\n",
      "custom_loss_function steps: 197376 output dim: 117 loss: 6.613846778869629 Mean Grad Norm: 3.4126341342926025\n",
      "custom_loss_function steps: 197504 output dim: 131 loss: 0.0003412687801755965 Mean Grad Norm: 3.4126877784729004\n",
      "custom_loss_function steps: 197632 output dim: 266 loss: 0.00034127419348806143 Mean Grad Norm: 3.4127418994903564\n",
      "custom_loss_function steps: 197760 output dim: 297 loss: 0.0003412803926039487 Mean Grad Norm: 3.412803888320923\n",
      "custom_loss_function steps: 197888 output dim: 155 loss: 0.00034128609695471823 Mean Grad Norm: 3.4128611087799072\n",
      "custom_loss_function steps: 198016 output dim: 115 loss: 0.0003412920341361314 Mean Grad Norm: 3.4129204750061035\n",
      "custom_loss_function steps: 198144 output dim: 142 loss: 0.00034129759296774864 Mean Grad Norm: 3.412976026535034\n",
      "custom_loss_function steps: 198272 output dim: 590 loss: 0.0003413028025534004 Mean Grad Norm: 3.4130280017852783\n",
      "custom_loss_function steps: 198400 output dim: 326 loss: 0.00034130795393139124 Mean Grad Norm: 3.4130797386169434\n",
      "custom_loss_function steps: 198528 output dim: 98 loss: 0.0003413129597902298 Mean Grad Norm: 3.4131295680999756\n",
      "custom_loss_function steps: 198656 output dim: 312 loss: 0.00034131770371459424 Mean Grad Norm: 3.413177013397217\n",
      "custom_loss_function steps: 198784 output dim: 250 loss: 0.0003413221566006541 Mean Grad Norm: 3.413221597671509\n",
      "custom_loss_function steps: 198912 output dim: 462 loss: 0.0003413262020330876 Mean Grad Norm: 3.413262128829956\n",
      "custom_loss_function steps: 199040 output dim: 71 loss: 0.0003413299273233861 Mean Grad Norm: 3.413299322128296\n",
      "custom_loss_function steps: 199168 output dim: 375 loss: 0.00034133336157537997 Mean Grad Norm: 3.4133336544036865\n",
      "custom_loss_function steps: 199296 output dim: 75 loss: 6.226215362548828 Mean Grad Norm: 3.4133689403533936\n",
      "custom_loss_function steps: 199424 output dim: 397 loss: 0.00034134165616706014 Mean Grad Norm: 3.413416624069214\n",
      "custom_loss_function steps: 199552 output dim: 131 loss: 0.0003413470112718642 Mean Grad Norm: 3.4134702682495117\n",
      "custom_loss_function steps: 199680 output dim: 60 loss: 5.1125054359436035 Mean Grad Norm: 3.4135191440582275\n",
      "custom_loss_function steps: 199808 output dim: 396 loss: 0.0003413574886508286 Mean Grad Norm: 3.4135749340057373\n",
      "custom_loss_function steps: 199936 output dim: 266 loss: 0.00034136243630200624 Mean Grad Norm: 3.4136245250701904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 200064 output dim: 130 loss: 0.00034136726753786206 Mean Grad Norm: 3.413672685623169\n",
      "custom_loss_function steps: 200192 output dim: 170 loss: 0.00034137218608520925 Mean Grad Norm: 3.413722038269043\n",
      "custom_loss_function steps: 200320 output dim: 105 loss: 0.00034137690090574324 Mean Grad Norm: 3.413769006729126\n",
      "custom_loss_function steps: 200448 output dim: 92 loss: 5.990914344787598 Mean Grad Norm: 3.413813829421997\n",
      "custom_loss_function steps: 200576 output dim: 98 loss: 0.0003413856029510498 Mean Grad Norm: 3.413856029510498\n",
      "custom_loss_function steps: 200704 output dim: 107 loss: 0.0003413893864490092 Mean Grad Norm: 3.413893938064575\n",
      "custom_loss_function steps: 200832 output dim: 126 loss: 0.00034139305353164673 Mean Grad Norm: 3.413930654525757\n",
      "custom_loss_function steps: 200960 output dim: 133 loss: 0.0003413965168874711 Mean Grad Norm: 3.4139652252197266\n",
      "custom_loss_function steps: 201088 output dim: 182 loss: 0.0003413996601011604 Mean Grad Norm: 3.413996696472168\n",
      "custom_loss_function steps: 201216 output dim: 209 loss: 0.0003414033562876284 Mean Grad Norm: 3.4140336513519287\n",
      "custom_loss_function steps: 201344 output dim: 88 loss: 0.0003414069360587746 Mean Grad Norm: 3.414069414138794\n",
      "custom_loss_function steps: 201472 output dim: 146 loss: 0.0003414104285184294 Mean Grad Norm: 3.414104461669922\n",
      "custom_loss_function steps: 201600 output dim: 98 loss: 0.000341413717251271 Mean Grad Norm: 3.414137125015259\n",
      "custom_loss_function steps: 201728 output dim: 87 loss: 0.00034141691867262125 Mean Grad Norm: 3.4141693115234375\n",
      "custom_loss_function steps: 201856 output dim: 110 loss: 0.0003414203820284456 Mean Grad Norm: 3.4142038822174072\n",
      "custom_loss_function steps: 201984 output dim: 82 loss: 6.076162815093994 Mean Grad Norm: 3.414241075515747\n",
      "custom_loss_function steps: 202112 output dim: 130 loss: 0.0003414281236473471 Mean Grad Norm: 3.4142813682556152\n",
      "custom_loss_function steps: 202240 output dim: 216 loss: 0.0003414326929487288 Mean Grad Norm: 3.4143269062042236\n",
      "custom_loss_function steps: 202368 output dim: 137 loss: 0.0003414370585232973 Mean Grad Norm: 3.4143707752227783\n",
      "custom_loss_function steps: 202496 output dim: 146 loss: 0.00034144113305956125 Mean Grad Norm: 3.4144113063812256\n",
      "custom_loss_function steps: 202624 output dim: 84 loss: 5.272160053253174 Mean Grad Norm: 3.414459705352783\n",
      "custom_loss_function steps: 202752 output dim: 87 loss: 0.00034145041718147695 Mean Grad Norm: 3.414504289627075\n",
      "custom_loss_function steps: 202880 output dim: 161 loss: 0.0003414548409637064 Mean Grad Norm: 3.414548635482788\n",
      "custom_loss_function steps: 203008 output dim: 128 loss: 0.0003414587408769876 Mean Grad Norm: 3.4145874977111816\n",
      "custom_loss_function steps: 203136 output dim: 162 loss: 0.00034146339748986065 Mean Grad Norm: 3.4146339893341064\n",
      "custom_loss_function steps: 203264 output dim: 243 loss: 0.00034146811231039464 Mean Grad Norm: 3.4146811962127686\n",
      "custom_loss_function steps: 203392 output dim: 150 loss: 0.00034147268161177635 Mean Grad Norm: 3.414726972579956\n",
      "custom_loss_function steps: 203520 output dim: 247 loss: 0.0003414774837438017 Mean Grad Norm: 3.4147748947143555\n",
      "custom_loss_function steps: 203648 output dim: 251 loss: 0.00034148202394135296 Mean Grad Norm: 3.414820432662964\n",
      "custom_loss_function steps: 203776 output dim: 98 loss: 5.263429164886475 Mean Grad Norm: 3.4148623943328857\n",
      "custom_loss_function steps: 203904 output dim: 149 loss: 0.0003414912207517773 Mean Grad Norm: 3.414912223815918\n",
      "custom_loss_function steps: 204032 output dim: 117 loss: 0.00034149576094932854 Mean Grad Norm: 3.4149577617645264\n",
      "custom_loss_function steps: 204160 output dim: 119 loss: 0.0003415009705349803 Mean Grad Norm: 3.4150097370147705\n",
      "custom_loss_function steps: 204288 output dim: 127 loss: 0.00034150577266700566 Mean Grad Norm: 3.415057897567749\n",
      "custom_loss_function steps: 204416 output dim: 275 loss: 0.00034151141881011426 Mean Grad Norm: 3.415114164352417\n",
      "custom_loss_function steps: 204544 output dim: 216 loss: 0.0003415171231608838 Mean Grad Norm: 3.4151713848114014\n",
      "custom_loss_function steps: 204672 output dim: 348 loss: 0.00034152239095419645 Mean Grad Norm: 3.415224075317383\n",
      "custom_loss_function steps: 204800 output dim: 82 loss: 5.511391639709473 Mean Grad Norm: 3.415281057357788\n",
      "custom_loss_function steps: 204928 output dim: 107 loss: 0.00034153330489061773 Mean Grad Norm: 3.4153332710266113\n",
      "custom_loss_function steps: 205056 output dim: 299 loss: 5.380723476409912 Mean Grad Norm: 3.415379524230957\n",
      "custom_loss_function steps: 205184 output dim: 257 loss: 0.0003415424143895507 Mean Grad Norm: 3.415424108505249\n",
      "custom_loss_function steps: 205312 output dim: 100 loss: 5.962996482849121 Mean Grad Norm: 3.4154653549194336\n",
      "custom_loss_function steps: 205440 output dim: 87 loss: 5.519369125366211 Mean Grad Norm: 3.415513515472412\n",
      "custom_loss_function steps: 205568 output dim: 123 loss: 0.0003415559767745435 Mean Grad Norm: 3.415559768676758\n",
      "custom_loss_function steps: 205696 output dim: 75 loss: 0.00034156025503762066 Mean Grad Norm: 3.415602684020996\n",
      "custom_loss_function steps: 205824 output dim: 87 loss: 0.00034156409674324095 Mean Grad Norm: 3.4156410694122314\n",
      "custom_loss_function steps: 205952 output dim: 332 loss: 0.0003415677638258785 Mean Grad Norm: 3.415677785873413\n",
      "custom_loss_function steps: 206080 output dim: 248 loss: 0.000341572129400447 Mean Grad Norm: 3.4157214164733887\n",
      "custom_loss_function steps: 206208 output dim: 109 loss: 0.00034157605841755867 Mean Grad Norm: 3.4157607555389404\n",
      "custom_loss_function steps: 206336 output dim: 148 loss: 0.0003415800165385008 Mean Grad Norm: 3.4158003330230713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 206464 output dim: 303 loss: 0.0003415838291402906 Mean Grad Norm: 3.4158384799957275\n",
      "custom_loss_function steps: 206592 output dim: 186 loss: 0.0003415872633922845 Mean Grad Norm: 3.415872812271118\n",
      "custom_loss_function steps: 206720 output dim: 321 loss: 0.00034159093047492206 Mean Grad Norm: 3.4159092903137207\n",
      "custom_loss_function steps: 206848 output dim: 109 loss: 0.00034159462666139007 Mean Grad Norm: 3.4159464836120605\n",
      "custom_loss_function steps: 206976 output dim: 101 loss: 5.1047492027282715 Mean Grad Norm: 3.4159796237945557\n",
      "custom_loss_function steps: 207104 output dim: 226 loss: 0.0003416021354496479 Mean Grad Norm: 3.4160215854644775\n",
      "custom_loss_function steps: 207232 output dim: 130 loss: 0.0003416059771552682 Mean Grad Norm: 3.416059970855713\n",
      "custom_loss_function steps: 207360 output dim: 188 loss: 0.00034161057556048036 Mean Grad Norm: 3.4161057472229004\n",
      "custom_loss_function steps: 207488 output dim: 104 loss: 0.0003416147956158966 Mean Grad Norm: 3.4161479473114014\n",
      "custom_loss_function steps: 207616 output dim: 148 loss: 0.0003416187537368387 Mean Grad Norm: 3.4161877632141113\n",
      "custom_loss_function steps: 207744 output dim: 205 loss: 0.0003416228573769331 Mean Grad Norm: 3.4162285327911377\n",
      "custom_loss_function steps: 207872 output dim: 170 loss: 0.00034162684460170567 Mean Grad Norm: 3.4162685871124268\n",
      "custom_loss_function steps: 208000 output dim: 137 loss: 0.0003416308027226478 Mean Grad Norm: 3.4163081645965576\n",
      "custom_loss_function steps: 208128 output dim: 106 loss: 6.068526744842529 Mean Grad Norm: 3.416346549987793\n",
      "custom_loss_function steps: 208256 output dim: 142 loss: 0.00034163863165304065 Mean Grad Norm: 3.416386365890503\n",
      "custom_loss_function steps: 208384 output dim: 297 loss: 6.893996715545654 Mean Grad Norm: 3.4164280891418457\n",
      "custom_loss_function steps: 208512 output dim: 211 loss: 0.00034164678072556853 Mean Grad Norm: 3.4164679050445557\n",
      "custom_loss_function steps: 208640 output dim: 135 loss: 0.00034165068063884974 Mean Grad Norm: 3.416506767272949\n",
      "custom_loss_function steps: 208768 output dim: 161 loss: 0.0003416540566831827 Mean Grad Norm: 3.4165406227111816\n",
      "custom_loss_function steps: 208896 output dim: 89 loss: 0.0003416572290007025 Mean Grad Norm: 3.416572332382202\n",
      "custom_loss_function steps: 209024 output dim: 109 loss: 0.00034166089608334005 Mean Grad Norm: 3.416609048843384\n",
      "custom_loss_function steps: 209152 output dim: 137 loss: 0.0003416644758544862 Mean Grad Norm: 3.416644811630249\n",
      "custom_loss_function steps: 209280 output dim: 233 loss: 0.00034166828845627606 Mean Grad Norm: 3.4166829586029053\n",
      "custom_loss_function steps: 209408 output dim: 119 loss: 0.0003416718100197613 Mean Grad Norm: 3.4167182445526123\n",
      "custom_loss_function steps: 209536 output dim: 152 loss: 0.0003416749823372811 Mean Grad Norm: 3.416749954223633\n",
      "custom_loss_function steps: 209664 output dim: 274 loss: 0.0003416781546548009 Mean Grad Norm: 3.4167816638946533\n",
      "custom_loss_function steps: 209792 output dim: 122 loss: 0.00034168121055699885 Mean Grad Norm: 3.4168121814727783\n",
      "custom_loss_function steps: 209920 output dim: 91 loss: 0.0003416844119783491 Mean Grad Norm: 3.416844129562378\n",
      "custom_loss_function steps: 210048 output dim: 64 loss: 0.00034168772981502116 Mean Grad Norm: 3.416877269744873\n",
      "custom_loss_function steps: 210176 output dim: 335 loss: 0.0003416911931708455 Mean Grad Norm: 3.416912078857422\n",
      "custom_loss_function steps: 210304 output dim: 290 loss: 0.0003416954423300922 Mean Grad Norm: 3.416954517364502\n",
      "custom_loss_function steps: 210432 output dim: 195 loss: 0.0003416994004510343 Mean Grad Norm: 3.416994094848633\n",
      "custom_loss_function steps: 210560 output dim: 164 loss: 0.000341703969752416 Mean Grad Norm: 3.4170398712158203\n",
      "custom_loss_function steps: 210688 output dim: 78 loss: 0.00034170830622315407 Mean Grad Norm: 3.4170830249786377\n",
      "custom_loss_function steps: 210816 output dim: 390 loss: 0.0003417125844862312 Mean Grad Norm: 3.417125940322876\n",
      "custom_loss_function steps: 210944 output dim: 127 loss: 0.00034171718289144337 Mean Grad Norm: 3.4171719551086426\n",
      "custom_loss_function steps: 211072 output dim: 135 loss: 0.00034172250889241695 Mean Grad Norm: 3.4172251224517822\n",
      "custom_loss_function steps: 211200 output dim: 63 loss: 6.164456367492676 Mean Grad Norm: 3.4172823429107666\n",
      "custom_loss_function steps: 211328 output dim: 160 loss: 0.000341733917593956 Mean Grad Norm: 3.417339324951172\n",
      "custom_loss_function steps: 211456 output dim: 92 loss: 0.0003417392144910991 Mean Grad Norm: 3.4173922538757324\n",
      "custom_loss_function steps: 211584 output dim: 210 loss: 0.0003417440166231245 Mean Grad Norm: 3.417440176010132\n",
      "custom_loss_function steps: 211712 output dim: 261 loss: 0.0003417493135202676 Mean Grad Norm: 3.4174931049346924\n",
      "custom_loss_function steps: 211840 output dim: 110 loss: 0.0003417539410293102 Mean Grad Norm: 3.417539596557617\n",
      "custom_loss_function steps: 211968 output dim: 234 loss: 0.00034175871405750513 Mean Grad Norm: 3.4175872802734375\n",
      "custom_loss_function steps: 212096 output dim: 334 loss: 0.00034176307963207364 Mean Grad Norm: 3.417630910873413\n",
      "custom_loss_function steps: 212224 output dim: 271 loss: 0.0003417671250645071 Mean Grad Norm: 3.4176714420318604\n",
      "custom_loss_function steps: 212352 output dim: 211 loss: 0.00034177082125097513 Mean Grad Norm: 3.417708396911621\n",
      "custom_loss_function steps: 212480 output dim: 312 loss: 0.00034177477937191725 Mean Grad Norm: 3.417747974395752\n",
      "custom_loss_function steps: 212608 output dim: 160 loss: 0.00034177873749285936 Mean Grad Norm: 3.417787551879883\n",
      "custom_loss_function steps: 212736 output dim: 118 loss: 0.0003417827538214624 Mean Grad Norm: 3.417827606201172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 212864 output dim: 141 loss: 0.0003417865082155913 Mean Grad Norm: 3.417865037918091\n",
      "custom_loss_function steps: 212992 output dim: 76 loss: 0.00034178985515609384 Mean Grad Norm: 3.417898654937744\n",
      "custom_loss_function steps: 213120 output dim: 77 loss: 0.0003417928237468004 Mean Grad Norm: 3.4179282188415527\n",
      "custom_loss_function steps: 213248 output dim: 76 loss: 5.557329177856445 Mean Grad Norm: 3.4179673194885254\n",
      "custom_loss_function steps: 213376 output dim: 198 loss: 0.00034180073998868465 Mean Grad Norm: 3.4180076122283936\n",
      "custom_loss_function steps: 213504 output dim: 79 loss: 0.00034180449438281357 Mean Grad Norm: 3.4180450439453125\n",
      "custom_loss_function steps: 213632 output dim: 282 loss: 0.0003418079868424684 Mean Grad Norm: 3.4180798530578613\n",
      "custom_loss_function steps: 213760 output dim: 95 loss: 0.00034181130467914045 Mean Grad Norm: 3.4181129932403564\n",
      "custom_loss_function steps: 213888 output dim: 227 loss: 0.00034181433147750795 Mean Grad Norm: 3.4181435108184814\n",
      "custom_loss_function steps: 214016 output dim: 107 loss: 0.0003418172418605536 Mean Grad Norm: 3.4181723594665527\n",
      "custom_loss_function steps: 214144 output dim: 467 loss: 0.00034182018134742975 Mean Grad Norm: 3.4182019233703613\n",
      "custom_loss_function steps: 214272 output dim: 149 loss: 0.0003418241685722023 Mean Grad Norm: 3.4182417392730713\n",
      "custom_loss_function steps: 214400 output dim: 207 loss: 0.0003418285632506013 Mean Grad Norm: 3.418285608291626\n",
      "custom_loss_function steps: 214528 output dim: 285 loss: 0.0003418325795792043 Mean Grad Norm: 3.418325901031494\n",
      "custom_loss_function steps: 214656 output dim: 107 loss: 0.000341836828738451 Mean Grad Norm: 3.418368339538574\n",
      "custom_loss_function steps: 214784 output dim: 287 loss: 0.0003418411361053586 Mean Grad Norm: 3.4184114933013916\n",
      "custom_loss_function steps: 214912 output dim: 82 loss: 5.9488630294799805 Mean Grad Norm: 3.418454170227051\n",
      "custom_loss_function steps: 215040 output dim: 197 loss: 0.00034185044933110476 Mean Grad Norm: 3.4185047149658203\n",
      "custom_loss_function steps: 215168 output dim: 298 loss: 0.00034185496042482555 Mean Grad Norm: 3.4185497760772705\n",
      "custom_loss_function steps: 215296 output dim: 254 loss: 0.0003418598498683423 Mean Grad Norm: 3.4185986518859863\n",
      "custom_loss_function steps: 215424 output dim: 89 loss: 5.795678615570068 Mean Grad Norm: 3.418644428253174\n",
      "custom_loss_function steps: 215552 output dim: 138 loss: 0.000341869774274528 Mean Grad Norm: 3.4186978340148926\n",
      "custom_loss_function steps: 215680 output dim: 280 loss: 0.00034187472192570567 Mean Grad Norm: 3.4187471866607666\n",
      "custom_loss_function steps: 215808 output dim: 97 loss: 5.34827995300293 Mean Grad Norm: 3.418794870376587\n",
      "custom_loss_function steps: 215936 output dim: 262 loss: 0.0003418837732169777 Mean Grad Norm: 3.418837785720825\n",
      "custom_loss_function steps: 216064 output dim: 117 loss: 0.0003418878186494112 Mean Grad Norm: 3.4188783168792725\n",
      "custom_loss_function steps: 216192 output dim: 179 loss: 0.00034189168945886195 Mean Grad Norm: 3.418916940689087\n",
      "custom_loss_function steps: 216320 output dim: 272 loss: 0.00034189646248705685 Mean Grad Norm: 3.4189646244049072\n",
      "custom_loss_function steps: 216448 output dim: 192 loss: 0.0003419008571654558 Mean Grad Norm: 3.419008731842041\n",
      "custom_loss_function steps: 216576 output dim: 337 loss: 0.00034190519363619387 Mean Grad Norm: 3.4190518856048584\n",
      "custom_loss_function steps: 216704 output dim: 143 loss: 0.00034190990845672786 Mean Grad Norm: 3.4190990924835205\n",
      "custom_loss_function steps: 216832 output dim: 323 loss: 0.000341914186719805 Mean Grad Norm: 3.419142007827759\n",
      "custom_loss_function steps: 216960 output dim: 72 loss: 0.0003419190470594913 Mean Grad Norm: 3.4191906452178955\n",
      "custom_loss_function steps: 217088 output dim: 368 loss: 0.000341923936503008 Mean Grad Norm: 3.4192395210266113\n",
      "custom_loss_function steps: 217216 output dim: 147 loss: 0.0003419287095312029 Mean Grad Norm: 3.4192872047424316\n",
      "custom_loss_function steps: 217344 output dim: 149 loss: 0.0003419338900130242 Mean Grad Norm: 3.4193389415740967\n",
      "custom_loss_function steps: 217472 output dim: 168 loss: 0.0003419391287025064 Mean Grad Norm: 3.419391393661499\n",
      "custom_loss_function steps: 217600 output dim: 261 loss: 0.0003419439890421927 Mean Grad Norm: 3.4194400310516357\n",
      "custom_loss_function steps: 217728 output dim: 130 loss: 5.891347885131836 Mean Grad Norm: 3.419485569000244\n",
      "custom_loss_function steps: 217856 output dim: 134 loss: 0.0003419538261368871 Mean Grad Norm: 3.4195382595062256\n",
      "custom_loss_function steps: 217984 output dim: 249 loss: 0.0003419588028918952 Mean Grad Norm: 3.419588088989258\n",
      "custom_loss_function steps: 218112 output dim: 141 loss: 0.0003419633430894464 Mean Grad Norm: 3.419633626937866\n",
      "custom_loss_function steps: 218240 output dim: 153 loss: 5.713305473327637 Mean Grad Norm: 3.419682025909424\n",
      "custom_loss_function steps: 218368 output dim: 247 loss: 0.0003419737331569195 Mean Grad Norm: 3.4197373390197754\n",
      "custom_loss_function steps: 218496 output dim: 114 loss: 0.00034197900095023215 Mean Grad Norm: 3.419790029525757\n",
      "custom_loss_function steps: 218624 output dim: 344 loss: 0.00034198371577076614 Mean Grad Norm: 3.419837236404419\n",
      "custom_loss_function steps: 218752 output dim: 248 loss: 0.0003419893328100443 Mean Grad Norm: 3.419893503189087\n",
      "custom_loss_function steps: 218880 output dim: 108 loss: 6.696407794952393 Mean Grad Norm: 3.419948101043701\n",
      "custom_loss_function steps: 219008 output dim: 204 loss: 0.00034200091613456607 Mean Grad Norm: 3.420009136199951\n",
      "custom_loss_function steps: 219136 output dim: 148 loss: 0.0003420068824198097 Mean Grad Norm: 3.4200689792633057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 219264 output dim: 184 loss: 0.0003420123248361051 Mean Grad Norm: 3.420123338699341\n",
      "custom_loss_function steps: 219392 output dim: 66 loss: 6.351163387298584 Mean Grad Norm: 3.420177698135376\n",
      "custom_loss_function steps: 219520 output dim: 208 loss: 0.0003420227731112391 Mean Grad Norm: 3.4202277660369873\n",
      "custom_loss_function steps: 219648 output dim: 150 loss: 0.000342027546139434 Mean Grad Norm: 3.4202754497528076\n",
      "custom_loss_function steps: 219776 output dim: 124 loss: 0.0003420324355829507 Mean Grad Norm: 3.4203245639801025\n",
      "custom_loss_function steps: 219904 output dim: 128 loss: 0.00034203793620690703 Mean Grad Norm: 3.420379400253296\n",
      "custom_loss_function steps: 220032 output dim: 111 loss: 0.00034204291296191514 Mean Grad Norm: 3.420429229736328\n",
      "custom_loss_function steps: 220160 output dim: 702 loss: 0.0003420485882088542 Mean Grad Norm: 3.4204859733581543\n",
      "custom_loss_function steps: 220288 output dim: 168 loss: 0.0003420535649638623 Mean Grad Norm: 3.4205358028411865\n",
      "custom_loss_function steps: 220416 output dim: 76 loss: 0.00034205804695375264 Mean Grad Norm: 3.4205806255340576\n",
      "custom_loss_function steps: 220544 output dim: 172 loss: 0.00034206322743557394 Mean Grad Norm: 3.4206323623657227\n",
      "custom_loss_function steps: 220672 output dim: 330 loss: 0.00034206785494461656 Mean Grad Norm: 3.4206786155700684\n",
      "custom_loss_function steps: 220800 output dim: 94 loss: 0.0003420718712732196 Mean Grad Norm: 3.4207189083099365\n",
      "custom_loss_function steps: 220928 output dim: 348 loss: 0.0003420755674596876 Mean Grad Norm: 3.420755624771118\n",
      "custom_loss_function steps: 221056 output dim: 229 loss: 0.0003420787397772074 Mean Grad Norm: 3.4207875728607178\n",
      "custom_loss_function steps: 221184 output dim: 99 loss: 0.0003420814755372703 Mean Grad Norm: 3.4208147525787354\n",
      "custom_loss_function steps: 221312 output dim: 156 loss: 0.0003420840366743505 Mean Grad Norm: 3.4208405017852783\n",
      "custom_loss_function steps: 221440 output dim: 210 loss: 0.0003420863067731261 Mean Grad Norm: 3.420863151550293\n",
      "custom_loss_function steps: 221568 output dim: 151 loss: 0.00034208831493742764 Mean Grad Norm: 3.4208831787109375\n",
      "custom_loss_function steps: 221696 output dim: 150 loss: 0.00034209073055535555 Mean Grad Norm: 3.4209072589874268\n",
      "custom_loss_function steps: 221824 output dim: 89 loss: 0.000342092796927318 Mean Grad Norm: 3.4209280014038086\n",
      "custom_loss_function steps: 221952 output dim: 185 loss: 0.00034209468867629766 Mean Grad Norm: 3.4209468364715576\n",
      "custom_loss_function steps: 222080 output dim: 119 loss: 0.000342097831889987 Mean Grad Norm: 3.420978307723999\n",
      "custom_loss_function steps: 222208 output dim: 98 loss: 5.460948944091797 Mean Grad Norm: 3.4210164546966553\n",
      "custom_loss_function steps: 222336 output dim: 84 loss: 0.00034210531157441437 Mean Grad Norm: 3.421053171157837\n",
      "custom_loss_function steps: 222464 output dim: 173 loss: 0.0003421091823838651 Mean Grad Norm: 3.4210920333862305\n",
      "custom_loss_function steps: 222592 output dim: 412 loss: 0.00034211273305118084 Mean Grad Norm: 3.4211275577545166\n",
      "custom_loss_function steps: 222720 output dim: 305 loss: 0.0003421170695219189 Mean Grad Norm: 3.421170711517334\n",
      "custom_loss_function steps: 222848 output dim: 117 loss: 0.00034212105674669147 Mean Grad Norm: 3.421210765838623\n",
      "custom_loss_function steps: 222976 output dim: 309 loss: 0.00034212478203698993 Mean Grad Norm: 3.421247959136963\n",
      "custom_loss_function steps: 223104 output dim: 160 loss: 0.000342128420015797 Mean Grad Norm: 3.4212841987609863\n",
      "custom_loss_function steps: 223232 output dim: 130 loss: 0.0003421319124754518 Mean Grad Norm: 3.4213192462921143\n",
      "custom_loss_function steps: 223360 output dim: 99 loss: 0.00034213525941595435 Mean Grad Norm: 3.4213526248931885\n",
      "custom_loss_function steps: 223488 output dim: 356 loss: 0.0003421382571104914 Mean Grad Norm: 3.4213826656341553\n",
      "custom_loss_function steps: 223616 output dim: 210 loss: 7.752305507659912 Mean Grad Norm: 3.4214155673980713\n",
      "custom_loss_function steps: 223744 output dim: 355 loss: 0.0003421461151447147 Mean Grad Norm: 3.421461343765259\n",
      "custom_loss_function steps: 223872 output dim: 125 loss: 0.0003421506262384355 Mean Grad Norm: 3.421506404876709\n",
      "custom_loss_function steps: 224000 output dim: 353 loss: 0.00034215531195513904 Mean Grad Norm: 3.421553134918213\n",
      "custom_loss_function steps: 224128 output dim: 65 loss: 0.00034215953201055527 Mean Grad Norm: 3.421595335006714\n",
      "custom_loss_function steps: 224256 output dim: 127 loss: 0.0003421647707000375 Mean Grad Norm: 3.421647787094116\n",
      "custom_loss_function steps: 224384 output dim: 124 loss: 0.00034216989297419786 Mean Grad Norm: 3.421699047088623\n",
      "custom_loss_function steps: 224512 output dim: 447 loss: 0.0003421756555326283 Mean Grad Norm: 3.4217565059661865\n",
      "custom_loss_function steps: 224640 output dim: 165 loss: 0.0003421814471948892 Mean Grad Norm: 3.421814441680908\n",
      "custom_loss_function steps: 224768 output dim: 122 loss: 0.00034218773362226784 Mean Grad Norm: 3.421877384185791\n",
      "custom_loss_function steps: 224896 output dim: 138 loss: 0.0003421936125960201 Mean Grad Norm: 3.421936273574829\n",
      "custom_loss_function steps: 225024 output dim: 321 loss: 8.08010196685791 Mean Grad Norm: 3.4219977855682373\n",
      "custom_loss_function steps: 225152 output dim: 98 loss: 0.0003422064473852515 Mean Grad Norm: 3.4220645427703857\n",
      "custom_loss_function steps: 225280 output dim: 212 loss: 0.00034221267560496926 Mean Grad Norm: 3.4221267700195312\n",
      "custom_loss_function steps: 225408 output dim: 154 loss: 0.0003422186418902129 Mean Grad Norm: 3.4221866130828857\n",
      "custom_loss_function steps: 225536 output dim: 74 loss: 0.00034222417161799967 Mean Grad Norm: 3.422241687774658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 225664 output dim: 215 loss: 0.00034222923568449914 Mean Grad Norm: 3.422292470932007\n",
      "custom_loss_function steps: 225792 output dim: 220 loss: 0.000342234707204625 Mean Grad Norm: 3.422347068786621\n",
      "custom_loss_function steps: 225920 output dim: 178 loss: 0.000342239742167294 Mean Grad Norm: 3.4223976135253906\n",
      "custom_loss_function steps: 226048 output dim: 111 loss: 0.000342245155479759 Mean Grad Norm: 3.4224517345428467\n",
      "custom_loss_function steps: 226176 output dim: 97 loss: 0.0003422501031309366 Mean Grad Norm: 3.4225010871887207\n",
      "custom_loss_function steps: 226304 output dim: 67 loss: 0.0003422552836127579 Mean Grad Norm: 3.4225528240203857\n",
      "custom_loss_function steps: 226432 output dim: 106 loss: 4.977505207061768 Mean Grad Norm: 3.4225988388061523\n",
      "custom_loss_function steps: 226560 output dim: 196 loss: 0.00034226395655423403 Mean Grad Norm: 3.4226396083831787\n",
      "custom_loss_function steps: 226688 output dim: 472 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 226816 output dim: 454 loss: 8.342968940734863 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 226944 output dim: 233 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227072 output dim: 260 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227200 output dim: 332 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227328 output dim: 352 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227456 output dim: 88 loss: 6.400859355926514 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227584 output dim: 130 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227712 output dim: 146 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227840 output dim: 179 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 227968 output dim: 202 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 228096 output dim: 269 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 228224 output dim: 151 loss: 0.0003422678855713457 Mean Grad Norm: 3.4226789474487305\n",
      "custom_loss_function steps: 228352 output dim: 80 loss: 0.0003422714362386614 Mean Grad Norm: 3.4227144718170166\n",
      "custom_loss_function steps: 228480 output dim: 59 loss: 0.0003422752197366208 Mean Grad Norm: 3.4227523803710938\n",
      "custom_loss_function steps: 228608 output dim: 85 loss: 0.0003422787704039365 Mean Grad Norm: 3.422787666320801\n",
      "custom_loss_function steps: 228736 output dim: 164 loss: 0.00034228278673253953 Mean Grad Norm: 3.422827959060669\n",
      "custom_loss_function steps: 228864 output dim: 167 loss: 0.00034228680306114256 Mean Grad Norm: 3.422868013381958\n",
      "custom_loss_function steps: 228992 output dim: 127 loss: 0.0003422909358050674 Mean Grad Norm: 3.4229094982147217\n",
      "custom_loss_function steps: 229120 output dim: 92 loss: 0.00034229492302984 Mean Grad Norm: 3.4229493141174316\n",
      "custom_loss_function steps: 229248 output dim: 241 loss: 0.0003422988229431212 Mean Grad Norm: 3.4229884147644043\n",
      "custom_loss_function steps: 229376 output dim: 74 loss: 0.000342302315402776 Mean Grad Norm: 3.423023223876953\n",
      "custom_loss_function steps: 229504 output dim: 278 loss: 0.0003423055459279567 Mean Grad Norm: 3.423055648803711\n",
      "custom_loss_function steps: 229632 output dim: 119 loss: 0.00034230854362249374 Mean Grad Norm: 3.4230854511260986\n",
      "custom_loss_function steps: 229760 output dim: 198 loss: 0.0003423113375902176 Mean Grad Norm: 3.4231133460998535\n",
      "custom_loss_function steps: 229888 output dim: 194 loss: 0.0003423138987272978 Mean Grad Norm: 3.4231390953063965\n",
      "custom_loss_function steps: 230016 output dim: 219 loss: 0.0003423163725528866 Mean Grad Norm: 3.423163890838623\n",
      "custom_loss_function steps: 230144 output dim: 230 loss: 0.0003423199523240328 Mean Grad Norm: 3.4231996536254883\n",
      "custom_loss_function steps: 230272 output dim: 230 loss: 0.00034232341567985713 Mean Grad Norm: 3.423234224319458\n",
      "custom_loss_function steps: 230400 output dim: 79 loss: 0.00034232664620503783 Mean Grad Norm: 3.4232664108276367\n",
      "custom_loss_function steps: 230528 output dim: 105 loss: 0.00034232958569191396 Mean Grad Norm: 3.4232959747314453\n",
      "custom_loss_function steps: 230656 output dim: 91 loss: 0.00034233348560519516 Mean Grad Norm: 3.423334836959839\n",
      "custom_loss_function steps: 230784 output dim: 133 loss: 0.00034233799669891596 Mean Grad Norm: 3.423380136489868\n",
      "custom_loss_function steps: 230912 output dim: 75 loss: 0.00034234297345392406 Mean Grad Norm: 3.4234299659729004\n",
      "custom_loss_function steps: 231040 output dim: 154 loss: 0.0003423484740778804 Mean Grad Norm: 3.4234848022460938\n",
      "custom_loss_function steps: 231168 output dim: 103 loss: 0.00034235353814437985 Mean Grad Norm: 3.4235353469848633\n",
      "custom_loss_function steps: 231296 output dim: 155 loss: 0.00034235918428748846 Mean Grad Norm: 3.4235918521881104\n",
      "custom_loss_function steps: 231424 output dim: 121 loss: 0.0003423650923650712 Mean Grad Norm: 3.4236509799957275\n",
      "custom_loss_function steps: 231552 output dim: 231 loss: 0.0003423705347813666 Mean Grad Norm: 3.423705577850342\n",
      "custom_loss_function steps: 231680 output dim: 222 loss: 0.0003423757152631879 Mean Grad Norm: 3.423757314682007\n",
      "custom_loss_function steps: 231808 output dim: 245 loss: 0.0003423814196139574 Mean Grad Norm: 3.423814296722412\n",
      "custom_loss_function steps: 231936 output dim: 238 loss: 0.0003423878806643188 Mean Grad Norm: 3.4238789081573486\n",
      "custom_loss_function steps: 232064 output dim: 119 loss: 0.0003423942835070193 Mean Grad Norm: 3.423942804336548\n",
      "custom_loss_function steps: 232192 output dim: 212 loss: 0.00034240022068843246 Mean Grad Norm: 3.424002170562744\n",
      "custom_loss_function steps: 232320 output dim: 91 loss: 0.00034240566310472786 Mean Grad Norm: 3.4240567684173584\n",
      "custom_loss_function steps: 232448 output dim: 92 loss: 0.0003424107562750578 Mean Grad Norm: 3.424107789993286\n",
      "custom_loss_function steps: 232576 output dim: 160 loss: 0.00034241582034155726 Mean Grad Norm: 3.4241583347320557\n",
      "custom_loss_function steps: 232704 output dim: 89 loss: 4.440653324127197 Mean Grad Norm: 3.4242067337036133\n",
      "custom_loss_function steps: 232832 output dim: 365 loss: 0.0003424250171519816 Mean Grad Norm: 3.424250364303589\n",
      "custom_loss_function steps: 232960 output dim: 175 loss: 0.00034242955734953284 Mean Grad Norm: 3.424295663833618\n",
      "custom_loss_function steps: 233088 output dim: 248 loss: 0.00034243360278196633 Mean Grad Norm: 3.4243361949920654\n",
      "custom_loss_function steps: 233216 output dim: 213 loss: 0.00034243741538375616 Mean Grad Norm: 3.4243741035461426\n",
      "custom_loss_function steps: 233344 output dim: 232 loss: 0.00034244070411659777 Mean Grad Norm: 3.4244072437286377\n",
      "custom_loss_function steps: 233472 output dim: 282 loss: 0.00034244483686052263 Mean Grad Norm: 3.4244484901428223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 233600 output dim: 322 loss: 0.0003424485621508211 Mean Grad Norm: 3.424485683441162\n",
      "custom_loss_function steps: 233728 output dim: 227 loss: 0.00034245316055603325 Mean Grad Norm: 3.4245316982269287\n",
      "custom_loss_function steps: 233856 output dim: 364 loss: 0.00034245740971527994 Mean Grad Norm: 3.424574136734009\n",
      "custom_loss_function steps: 233984 output dim: 151 loss: 0.0003424611350055784 Mean Grad Norm: 3.4246115684509277\n",
      "custom_loss_function steps: 234112 output dim: 158 loss: 0.0003424651804380119 Mean Grad Norm: 3.424651861190796\n",
      "custom_loss_function steps: 234240 output dim: 111 loss: 0.00034246884752064943 Mean Grad Norm: 3.4246885776519775\n",
      "custom_loss_function steps: 234368 output dim: 106 loss: 0.0003424721653573215 Mean Grad Norm: 3.4247217178344727\n",
      "custom_loss_function steps: 234496 output dim: 98 loss: 0.0003424751339480281 Mean Grad Norm: 3.4247512817382812\n",
      "custom_loss_function steps: 234624 output dim: 150 loss: 0.0003424777532927692 Mean Grad Norm: 3.4247775077819824\n",
      "custom_loss_function steps: 234752 output dim: 95 loss: 0.00034248133306391537 Mean Grad Norm: 3.4248135089874268\n",
      "custom_loss_function steps: 234880 output dim: 225 loss: 0.0003424844762776047 Mean Grad Norm: 3.424844980239868\n",
      "custom_loss_function steps: 235008 output dim: 271 loss: 0.0003424877650104463 Mean Grad Norm: 3.424877882003784\n",
      "custom_loss_function steps: 235136 output dim: 119 loss: 0.00034249082091264427 Mean Grad Norm: 3.424908399581909\n",
      "custom_loss_function steps: 235264 output dim: 876 loss: 8.134918212890625 Mean Grad Norm: 3.4249460697174072\n",
      "custom_loss_function steps: 235392 output dim: 171 loss: 0.00034249856253154576 Mean Grad Norm: 3.424985647201538\n",
      "custom_loss_function steps: 235520 output dim: 151 loss: 0.00034250240423716605 Mean Grad Norm: 3.4250242710113525\n",
      "custom_loss_function steps: 235648 output dim: 212 loss: 0.0003425070899538696 Mean Grad Norm: 3.4250710010528564\n",
      "custom_loss_function steps: 235776 output dim: 198 loss: 0.000342511513736099 Mean Grad Norm: 3.4251151084899902\n",
      "custom_loss_function steps: 235904 output dim: 149 loss: 0.00034251553006470203 Mean Grad Norm: 3.4251554012298584\n",
      "custom_loss_function steps: 236032 output dim: 363 loss: 0.00034251922625117004 Mean Grad Norm: 3.425192356109619\n",
      "custom_loss_function steps: 236160 output dim: 512 loss: 0.0003425230097491294 Mean Grad Norm: 3.4252302646636963\n",
      "custom_loss_function steps: 236288 output dim: 77 loss: 0.0003425264440011233 Mean Grad Norm: 3.425264596939087\n",
      "custom_loss_function steps: 236416 output dim: 140 loss: 0.0003425302274990827 Mean Grad Norm: 3.425302505493164\n",
      "custom_loss_function steps: 236544 output dim: 171 loss: 0.0003425341856200248 Mean Grad Norm: 3.425341844558716\n",
      "custom_loss_function steps: 236672 output dim: 170 loss: 0.0003425378818064928 Mean Grad Norm: 3.4253787994384766\n",
      "custom_loss_function steps: 236800 output dim: 213 loss: 0.0003425422473810613 Mean Grad Norm: 3.425422430038452\n",
      "custom_loss_function steps: 236928 output dim: 99 loss: 0.0003425468457862735 Mean Grad Norm: 3.4254684448242188\n",
      "custom_loss_function steps: 237056 output dim: 125 loss: 0.00034255144419148564 Mean Grad Norm: 3.4255144596099854\n",
      "custom_loss_function steps: 237184 output dim: 106 loss: 0.0003425556351430714 Mean Grad Norm: 3.4255564212799072\n",
      "custom_loss_function steps: 237312 output dim: 210 loss: 0.00034255944774486125 Mean Grad Norm: 3.4255945682525635\n",
      "custom_loss_function steps: 237440 output dim: 167 loss: 0.00034256349317729473 Mean Grad Norm: 3.4256350994110107\n",
      "custom_loss_function steps: 237568 output dim: 83 loss: 5.829414367675781 Mean Grad Norm: 3.4256720542907715\n",
      "custom_loss_function steps: 237696 output dim: 335 loss: 0.00034257047809660435 Mean Grad Norm: 3.4257049560546875\n",
      "custom_loss_function steps: 237824 output dim: 345 loss: 0.00034257350489497185 Mean Grad Norm: 3.4257349967956543\n",
      "custom_loss_function steps: 237952 output dim: 218 loss: 0.00034257658990100026 Mean Grad Norm: 3.4257659912109375\n",
      "custom_loss_function steps: 238080 output dim: 318 loss: 0.00034257941297255456 Mean Grad Norm: 3.4257941246032715\n",
      "custom_loss_function steps: 238208 output dim: 180 loss: 0.0003425828763283789 Mean Grad Norm: 3.4258289337158203\n",
      "custom_loss_function steps: 238336 output dim: 152 loss: 0.0003425863105803728 Mean Grad Norm: 3.425863265991211\n",
      "custom_loss_function steps: 238464 output dim: 185 loss: 0.0003425893373787403 Mean Grad Norm: 3.425893545150757\n",
      "custom_loss_function steps: 238592 output dim: 120 loss: 0.0003425923641771078 Mean Grad Norm: 3.4259238243103027\n",
      "custom_loss_function steps: 238720 output dim: 207 loss: 0.0003425961476750672 Mean Grad Norm: 3.425961494445801\n",
      "custom_loss_function steps: 238848 output dim: 86 loss: 6.2644476890563965 Mean Grad Norm: 3.425999879837036\n",
      "custom_loss_function steps: 238976 output dim: 102 loss: 0.0003426048206165433 Mean Grad Norm: 3.4260482788085938\n",
      "custom_loss_function steps: 239104 output dim: 213 loss: 0.00034261029213666916 Mean Grad Norm: 3.426102876663208\n",
      "custom_loss_function steps: 239232 output dim: 118 loss: 0.0003426152979955077 Mean Grad Norm: 3.4261531829833984\n",
      "custom_loss_function steps: 239360 output dim: 188 loss: 5.850771427154541 Mean Grad Norm: 3.4262020587921143\n",
      "custom_loss_function steps: 239488 output dim: 259 loss: 0.0003426256007514894 Mean Grad Norm: 3.4262561798095703\n",
      "custom_loss_function steps: 239616 output dim: 428 loss: 0.00034263127599842846 Mean Grad Norm: 3.4263129234313965\n",
      "custom_loss_function steps: 239744 output dim: 138 loss: 0.00034263654379174113 Mean Grad Norm: 3.426365613937378\n",
      "custom_loss_function steps: 239872 output dim: 99 loss: 0.00034264122950844467 Mean Grad Norm: 3.426412343978882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 240000 output dim: 82 loss: 0.0003426455659791827 Mean Grad Norm: 3.4264557361602783\n",
      "custom_loss_function steps: 240128 output dim: 383 loss: 0.00034265060094185174 Mean Grad Norm: 3.4265060424804688\n",
      "custom_loss_function steps: 240256 output dim: 131 loss: 0.00034265537397004664 Mean Grad Norm: 3.426553726196289\n",
      "custom_loss_function steps: 240384 output dim: 87 loss: 0.0003426596231292933 Mean Grad Norm: 3.4265964031219482\n",
      "custom_loss_function steps: 240512 output dim: 302 loss: 6.329485893249512 Mean Grad Norm: 3.426645278930664\n",
      "custom_loss_function steps: 240640 output dim: 127 loss: 5.7719407081604 Mean Grad Norm: 3.426694393157959\n",
      "custom_loss_function steps: 240768 output dim: 167 loss: 0.00034267400042153895 Mean Grad Norm: 3.4267401695251465\n",
      "custom_loss_function steps: 240896 output dim: 82 loss: 5.127901554107666 Mean Grad Norm: 3.426788091659546\n",
      "custom_loss_function steps: 241024 output dim: 397 loss: 0.0003426831681281328 Mean Grad Norm: 3.4268317222595215\n",
      "custom_loss_function steps: 241152 output dim: 205 loss: 0.0003426871553529054 Mean Grad Norm: 3.4268717765808105\n",
      "custom_loss_function steps: 241280 output dim: 202 loss: 0.0003426909970585257 Mean Grad Norm: 3.426910161972046\n",
      "custom_loss_function steps: 241408 output dim: 123 loss: 0.00034269457682967186 Mean Grad Norm: 3.426945924758911\n",
      "custom_loss_function steps: 241536 output dim: 125 loss: 0.000342697836458683 Mean Grad Norm: 3.426978349685669\n",
      "custom_loss_function steps: 241664 output dim: 204 loss: 0.00034270077594555914 Mean Grad Norm: 3.4270079135894775\n",
      "custom_loss_function steps: 241792 output dim: 91 loss: 0.0003427035117056221 Mean Grad Norm: 3.427035331726074\n",
      "custom_loss_function steps: 241920 output dim: 148 loss: 0.00034270627656951547 Mean Grad Norm: 3.427062749862671\n",
      "custom_loss_function steps: 242048 output dim: 103 loss: 0.00034270909964106977 Mean Grad Norm: 3.427091121673584\n",
      "custom_loss_function steps: 242176 output dim: 130 loss: 0.0003427124465815723 Mean Grad Norm: 3.427124500274658\n",
      "custom_loss_function steps: 242304 output dim: 147 loss: 0.00034271596814505756 Mean Grad Norm: 3.4271597862243652\n",
      "custom_loss_function steps: 242432 output dim: 201 loss: 0.00034271925687789917 Mean Grad Norm: 3.4271926879882812\n",
      "custom_loss_function steps: 242560 output dim: 154 loss: 0.00034272216726094484 Mean Grad Norm: 3.4272217750549316\n",
      "custom_loss_function steps: 242688 output dim: 143 loss: 0.00034272484481334686 Mean Grad Norm: 3.427248477935791\n",
      "custom_loss_function steps: 242816 output dim: 236 loss: 0.0003427272313274443 Mean Grad Norm: 3.427272319793701\n",
      "custom_loss_function steps: 242944 output dim: 202 loss: 0.0003427300835028291 Mean Grad Norm: 3.4273009300231934\n",
      "custom_loss_function steps: 243072 output dim: 117 loss: 0.00034273299388587475 Mean Grad Norm: 3.4273300170898438\n",
      "custom_loss_function steps: 243200 output dim: 115 loss: 5.559545993804932 Mean Grad Norm: 3.427361011505127\n",
      "custom_loss_function steps: 243328 output dim: 351 loss: 0.00034273898927494884 Mean Grad Norm: 3.4273898601531982\n",
      "custom_loss_function steps: 243456 output dim: 87 loss: 0.0003427417541388422 Mean Grad Norm: 3.427417755126953\n",
      "custom_loss_function steps: 243584 output dim: 235 loss: 0.00034274495556019247 Mean Grad Norm: 3.4274497032165527\n",
      "custom_loss_function steps: 243712 output dim: 144 loss: 0.0003427478950470686 Mean Grad Norm: 3.4274790287017822\n",
      "custom_loss_function steps: 243840 output dim: 173 loss: 0.000342750659910962 Mean Grad Norm: 3.427506685256958\n",
      "custom_loss_function steps: 243968 output dim: 187 loss: 0.0003427542978897691 Mean Grad Norm: 3.4275429248809814\n",
      "custom_loss_function steps: 244096 output dim: 87 loss: 6.146610260009766 Mean Grad Norm: 3.4275758266448975\n",
      "custom_loss_function steps: 244224 output dim: 205 loss: 0.0003427608753554523 Mean Grad Norm: 3.4276089668273926\n",
      "custom_loss_function steps: 244352 output dim: 234 loss: 0.000342764105880633 Mean Grad Norm: 3.4276411533355713\n",
      "custom_loss_function steps: 244480 output dim: 430 loss: 0.00034276695805601776 Mean Grad Norm: 3.4276697635650635\n",
      "custom_loss_function steps: 244608 output dim: 269 loss: 0.00034276937367394567 Mean Grad Norm: 3.4276938438415527\n",
      "custom_loss_function steps: 244736 output dim: 125 loss: 0.0003427721676416695 Mean Grad Norm: 3.4277217388153076\n",
      "custom_loss_function steps: 244864 output dim: 97 loss: 0.0003427758638281375 Mean Grad Norm: 3.4277586936950684\n",
      "custom_loss_function steps: 244992 output dim: 87 loss: 5.518507480621338 Mean Grad Norm: 3.4277923107147217\n",
      "custom_loss_function steps: 245120 output dim: 98 loss: 5.595736980438232 Mean Grad Norm: 3.427823543548584\n",
      "custom_loss_function steps: 245248 output dim: 165 loss: 0.0003427861083764583 Mean Grad Norm: 3.427861213684082\n",
      "custom_loss_function steps: 245376 output dim: 140 loss: 0.0003427898045629263 Mean Grad Norm: 3.4278981685638428\n",
      "custom_loss_function steps: 245504 output dim: 145 loss: 0.00034279300598427653 Mean Grad Norm: 3.4279301166534424\n",
      "custom_loss_function steps: 245632 output dim: 379 loss: 0.0003427969932090491 Mean Grad Norm: 3.4279699325561523\n",
      "custom_loss_function steps: 245760 output dim: 315 loss: 0.000342800747603178 Mean Grad Norm: 3.4280076026916504\n",
      "custom_loss_function steps: 245888 output dim: 168 loss: 0.0003428044728934765 Mean Grad Norm: 3.4280447959899902\n",
      "custom_loss_function steps: 246016 output dim: 156 loss: 0.000342808838468045 Mean Grad Norm: 3.428088426589966\n",
      "custom_loss_function steps: 246144 output dim: 74 loss: 5.299638271331787 Mean Grad Norm: 3.428133964538574\n",
      "custom_loss_function steps: 246272 output dim: 123 loss: 10.187273025512695 Mean Grad Norm: 3.4281773567199707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 246400 output dim: 94 loss: 0.0003428224299568683 Mean Grad Norm: 3.4282243251800537\n",
      "custom_loss_function steps: 246528 output dim: 379 loss: 0.000342826679116115 Mean Grad Norm: 3.428267002105713\n",
      "custom_loss_function steps: 246656 output dim: 138 loss: 0.00034283087006770074 Mean Grad Norm: 3.4283087253570557\n",
      "custom_loss_function steps: 246784 output dim: 243 loss: 0.00034283564309589565 Mean Grad Norm: 3.428356409072876\n",
      "custom_loss_function steps: 246912 output dim: 144 loss: 0.00034284009598195553 Mean Grad Norm: 3.428400993347168\n",
      "custom_loss_function steps: 247040 output dim: 162 loss: 0.00034284425782971084 Mean Grad Norm: 3.4284427165985107\n",
      "custom_loss_function steps: 247168 output dim: 235 loss: 0.0003428481868468225 Mean Grad Norm: 3.4284818172454834\n",
      "custom_loss_function steps: 247296 output dim: 115 loss: 0.0003428520285524428 Mean Grad Norm: 3.428520441055298\n",
      "custom_loss_function steps: 247424 output dim: 119 loss: 0.00034285581205040216 Mean Grad Norm: 3.428558111190796\n",
      "custom_loss_function steps: 247552 output dim: 103 loss: 5.362143516540527 Mean Grad Norm: 3.4285919666290283\n",
      "custom_loss_function steps: 247680 output dim: 101 loss: 0.00034286314621567726 Mean Grad Norm: 3.428631544113159\n",
      "custom_loss_function steps: 247808 output dim: 125 loss: 0.0003428667550906539 Mean Grad Norm: 3.4286675453186035\n",
      "custom_loss_function steps: 247936 output dim: 148 loss: 0.0003428708005230874 Mean Grad Norm: 3.428708076477051\n",
      "custom_loss_function steps: 248064 output dim: 110 loss: 0.0003428746131248772 Mean Grad Norm: 3.428746223449707\n",
      "custom_loss_function steps: 248192 output dim: 83 loss: 6.542618274688721 Mean Grad Norm: 3.4287822246551514\n",
      "custom_loss_function steps: 248320 output dim: 207 loss: 0.0003428816271480173 Mean Grad Norm: 3.428816318511963\n",
      "custom_loss_function steps: 248448 output dim: 129 loss: 0.00034288482856936753 Mean Grad Norm: 3.4288482666015625\n",
      "custom_loss_function steps: 248576 output dim: 160 loss: 0.00034288770984858274 Mean Grad Norm: 3.428877115249634\n",
      "custom_loss_function steps: 248704 output dim: 114 loss: 0.0003428905038163066 Mean Grad Norm: 3.4289052486419678\n",
      "custom_loss_function steps: 248832 output dim: 130 loss: 0.0003428932395763695 Mean Grad Norm: 3.4289324283599854\n",
      "custom_loss_function steps: 248960 output dim: 204 loss: 0.0003428958007134497 Mean Grad Norm: 3.4289581775665283\n",
      "custom_loss_function steps: 249088 output dim: 166 loss: 0.00034289894392713904 Mean Grad Norm: 3.4289894104003906\n",
      "custom_loss_function steps: 249216 output dim: 140 loss: 0.00034290197072550654 Mean Grad Norm: 3.4290196895599365\n",
      "custom_loss_function steps: 249344 output dim: 102 loss: 0.0003429055504966527 Mean Grad Norm: 3.429055690765381\n",
      "custom_loss_function steps: 249472 output dim: 110 loss: 5.792632579803467 Mean Grad Norm: 3.4290990829467773\n",
      "custom_loss_function steps: 249600 output dim: 166 loss: 0.00034291372867301106 Mean Grad Norm: 3.4291372299194336\n",
      "custom_loss_function steps: 249728 output dim: 90 loss: 0.0003429174539633095 Mean Grad Norm: 3.4291746616363525\n",
      "custom_loss_function steps: 249856 output dim: 81 loss: 8.141511917114258 Mean Grad Norm: 3.4292092323303223\n",
      "custom_loss_function steps: 249984 output dim: 115 loss: 5.49607515335083 Mean Grad Norm: 3.4292492866516113\n",
      "custom_loss_function steps: 250112 output dim: 153 loss: 0.00034292874624952674 Mean Grad Norm: 3.4292876720428467\n",
      "custom_loss_function steps: 250240 output dim: 279 loss: 0.0003429323551245034 Mean Grad Norm: 3.429323673248291\n",
      "custom_loss_function steps: 250368 output dim: 223 loss: 0.00034293573116883636 Mean Grad Norm: 3.4293575286865234\n",
      "custom_loss_function steps: 250496 output dim: 220 loss: 0.0003429390490055084 Mean Grad Norm: 3.4293906688690186\n",
      "custom_loss_function steps: 250624 output dim: 114 loss: 0.00034294213401153684 Mean Grad Norm: 3.4294214248657227\n",
      "custom_loss_function steps: 250752 output dim: 102 loss: 0.00034294629585929215 Mean Grad Norm: 3.4294629096984863\n",
      "custom_loss_function steps: 250880 output dim: 118 loss: 0.00034294999204576015 Mean Grad Norm: 3.429499864578247\n",
      "custom_loss_function steps: 251008 output dim: 189 loss: 0.0003429542121011764 Mean Grad Norm: 3.429542303085327\n",
      "custom_loss_function steps: 251136 output dim: 143 loss: 0.0003429581120144576 Mean Grad Norm: 3.4295811653137207\n",
      "custom_loss_function steps: 251264 output dim: 73 loss: 0.00034296177909709513 Mean Grad Norm: 3.4296178817749023\n",
      "custom_loss_function steps: 251392 output dim: 134 loss: 0.0003429650969337672 Mean Grad Norm: 3.4296510219573975\n",
      "custom_loss_function steps: 251520 output dim: 86 loss: 5.971475124359131 Mean Grad Norm: 3.429689884185791\n",
      "custom_loss_function steps: 251648 output dim: 84 loss: 6.546672344207764 Mean Grad Norm: 3.4297242164611816\n",
      "custom_loss_function steps: 251776 output dim: 212 loss: 0.0003429767384659499 Mean Grad Norm: 3.429767370223999\n",
      "custom_loss_function steps: 251904 output dim: 150 loss: 0.00034298081300221384 Mean Grad Norm: 3.4298081398010254\n",
      "custom_loss_function steps: 252032 output dim: 192 loss: 0.00034298462560400367 Mean Grad Norm: 3.4298462867736816\n",
      "custom_loss_function steps: 252160 output dim: 161 loss: 0.00034298840910196304 Mean Grad Norm: 3.429884195327759\n",
      "custom_loss_function steps: 252288 output dim: 176 loss: 0.0003429927455727011 Mean Grad Norm: 3.4299275875091553\n",
      "custom_loss_function steps: 252416 output dim: 166 loss: 0.0003429969947319478 Mean Grad Norm: 3.4299700260162354\n",
      "custom_loss_function steps: 252544 output dim: 68 loss: 5.082015037536621 Mean Grad Norm: 3.430014133453369\n",
      "custom_loss_function steps: 252672 output dim: 225 loss: 0.00034300636616535485 Mean Grad Norm: 3.4300637245178223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 252800 output dim: 160 loss: 0.0003430109063629061 Mean Grad Norm: 3.4301092624664307\n",
      "custom_loss_function steps: 252928 output dim: 72 loss: 0.0003430154756642878 Mean Grad Norm: 3.430154800415039\n",
      "custom_loss_function steps: 253056 output dim: 511 loss: 0.00034301987034268677 Mean Grad Norm: 3.430198907852173\n",
      "custom_loss_function steps: 253184 output dim: 84 loss: 5.550096035003662 Mean Grad Norm: 3.430238723754883\n",
      "custom_loss_function steps: 253312 output dim: 103 loss: 0.0003430275828577578 Mean Grad Norm: 3.4302759170532227\n",
      "custom_loss_function steps: 253440 output dim: 148 loss: 0.0003430308133829385 Mean Grad Norm: 3.4303083419799805\n",
      "custom_loss_function steps: 253568 output dim: 363 loss: 0.0003430345095694065 Mean Grad Norm: 3.430345296859741\n",
      "custom_loss_function steps: 253696 output dim: 399 loss: 0.00034303785650990903 Mean Grad Norm: 3.4303786754608154\n",
      "custom_loss_function steps: 253824 output dim: 110 loss: 0.0003430410288274288 Mean Grad Norm: 3.430410385131836\n",
      "custom_loss_function steps: 253952 output dim: 126 loss: 0.00034304402652196586 Mean Grad Norm: 3.4304404258728027\n",
      "custom_loss_function steps: 254080 output dim: 70 loss: 0.00034304679138585925 Mean Grad Norm: 3.4304680824279785\n",
      "custom_loss_function steps: 254208 output dim: 144 loss: 0.0003430495271459222 Mean Grad Norm: 3.430495262145996\n",
      "custom_loss_function steps: 254336 output dim: 77 loss: 0.00034305269946344197 Mean Grad Norm: 3.4305272102355957\n",
      "custom_loss_function steps: 254464 output dim: 119 loss: 0.00034305639564991 Mean Grad Norm: 3.4305641651153564\n",
      "custom_loss_function steps: 254592 output dim: 172 loss: 0.00034306032466702163 Mean Grad Norm: 3.430603265762329\n",
      "custom_loss_function steps: 254720 output dim: 143 loss: 0.0003430640499573201 Mean Grad Norm: 3.430640459060669\n",
      "custom_loss_function steps: 254848 output dim: 130 loss: 0.000343067804351449 Mean Grad Norm: 3.430678129196167\n",
      "custom_loss_function steps: 254976 output dim: 166 loss: 0.0003430714423302561 Mean Grad Norm: 3.4307143688201904\n",
      "custom_loss_function steps: 255104 output dim: 314 loss: 0.00034307566238567233 Mean Grad Norm: 3.4307565689086914\n",
      "custom_loss_function steps: 255232 output dim: 89 loss: 0.00034307988244108856 Mean Grad Norm: 3.4307990074157715\n",
      "custom_loss_function steps: 255360 output dim: 201 loss: 0.00034308398608118296 Mean Grad Norm: 3.430840015411377\n",
      "custom_loss_function steps: 255488 output dim: 195 loss: 0.00034308797330595553 Mean Grad Norm: 3.430879831314087\n",
      "custom_loss_function steps: 255616 output dim: 195 loss: 0.0003430916112847626 Mean Grad Norm: 3.4309160709381104\n",
      "custom_loss_function steps: 255744 output dim: 98 loss: 0.00034309501643292606 Mean Grad Norm: 3.430950164794922\n",
      "custom_loss_function steps: 255872 output dim: 192 loss: 0.00034309932379983366 Mean Grad Norm: 3.4309933185577393\n",
      "custom_loss_function steps: 256000 output dim: 652 loss: 0.0003431031946092844 Mean Grad Norm: 3.4310319423675537\n",
      "custom_loss_function steps: 256128 output dim: 102 loss: 0.0003431068907957524 Mean Grad Norm: 3.4310691356658936\n",
      "custom_loss_function steps: 256256 output dim: 147 loss: 0.00034311041235923767 Mean Grad Norm: 3.4311041831970215\n",
      "custom_loss_function steps: 256384 output dim: 75 loss: 0.000343113875715062 Mean Grad Norm: 3.431138753890991\n",
      "custom_loss_function steps: 256512 output dim: 139 loss: 0.00034311763010919094 Mean Grad Norm: 3.4311764240264893\n",
      "custom_loss_function steps: 256640 output dim: 100 loss: 0.00034312138450331986 Mean Grad Norm: 3.431213855743408\n",
      "custom_loss_function steps: 256768 output dim: 149 loss: 0.00034312508068978786 Mean Grad Norm: 3.431250810623169\n",
      "custom_loss_function steps: 256896 output dim: 301 loss: 0.00034312932984903455 Mean Grad Norm: 3.431293249130249\n",
      "custom_loss_function steps: 257024 output dim: 98 loss: 0.0003431341319810599 Mean Grad Norm: 3.4313414096832275\n",
      "custom_loss_function steps: 257152 output dim: 76 loss: 5.387548446655273 Mean Grad Norm: 3.4313931465148926\n",
      "custom_loss_function steps: 257280 output dim: 87 loss: 0.00034314440563321114 Mean Grad Norm: 3.4314441680908203\n",
      "custom_loss_function steps: 257408 output dim: 274 loss: 0.000343149557011202 Mean Grad Norm: 3.4314956665039062\n",
      "custom_loss_function steps: 257536 output dim: 227 loss: 0.00034315523225814104 Mean Grad Norm: 3.4315524101257324\n",
      "custom_loss_function steps: 257664 output dim: 170 loss: 0.0003431616351008415 Mean Grad Norm: 3.4316165447235107\n",
      "custom_loss_function steps: 257792 output dim: 83 loss: 5.722665309906006 Mean Grad Norm: 3.4316773414611816\n",
      "custom_loss_function steps: 257920 output dim: 91 loss: 0.00034317330573685467 Mean Grad Norm: 3.4317331314086914\n",
      "custom_loss_function steps: 258048 output dim: 153 loss: 0.000343178806360811 Mean Grad Norm: 3.431788206100464\n",
      "custom_loss_function steps: 258176 output dim: 281 loss: 0.0003431841905694455 Mean Grad Norm: 3.4318418502807617\n",
      "custom_loss_function steps: 258304 output dim: 212 loss: 0.00034318972029723227 Mean Grad Norm: 3.4318974018096924\n",
      "custom_loss_function steps: 258432 output dim: 137 loss: 0.0003431950171943754 Mean Grad Norm: 3.431950330734253\n",
      "custom_loss_function steps: 258560 output dim: 82 loss: 0.00034320083796046674 Mean Grad Norm: 3.4320085048675537\n",
      "custom_loss_function steps: 258688 output dim: 247 loss: 0.0003432063676882535 Mean Grad Norm: 3.4320638179779053\n",
      "custom_loss_function steps: 258816 output dim: 178 loss: 6.071577072143555 Mean Grad Norm: 3.432115077972412\n",
      "custom_loss_function steps: 258944 output dim: 117 loss: 4.965559959411621 Mean Grad Norm: 3.432166337966919\n",
      "custom_loss_function steps: 259072 output dim: 117 loss: 0.00034322121064178646 Mean Grad Norm: 3.4322121143341064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 259200 output dim: 172 loss: 0.0003432258381508291 Mean Grad Norm: 3.4322586059570312\n",
      "custom_loss_function steps: 259328 output dim: 262 loss: 0.00034322997089475393 Mean Grad Norm: 3.432299852371216\n",
      "custom_loss_function steps: 259456 output dim: 106 loss: 0.0003432343655731529 Mean Grad Norm: 3.4323437213897705\n",
      "custom_loss_function steps: 259584 output dim: 120 loss: 0.00034323870204389095 Mean Grad Norm: 3.432387113571167\n",
      "custom_loss_function steps: 259712 output dim: 350 loss: 0.00034324266016483307 Mean Grad Norm: 3.432426691055298\n",
      "custom_loss_function steps: 259840 output dim: 75 loss: 0.0003432461526244879 Mean Grad Norm: 3.4324615001678467\n",
      "custom_loss_function steps: 259968 output dim: 52 loss: 5.000761032104492 Mean Grad Norm: 3.4325013160705566\n",
      "custom_loss_function steps: 260096 output dim: 127 loss: 0.00034325409797020257 Mean Grad Norm: 3.4325411319732666\n",
      "custom_loss_function steps: 260224 output dim: 201 loss: 0.00034325869637541473 Mean Grad Norm: 3.432586908340454\n",
      "custom_loss_function steps: 260352 output dim: 80 loss: 0.00034326285822317004 Mean Grad Norm: 3.432628631591797\n",
      "custom_loss_function steps: 260480 output dim: 462 loss: 0.0003432676603551954 Mean Grad Norm: 3.4326765537261963\n",
      "custom_loss_function steps: 260608 output dim: 93 loss: 0.0003432720841374248 Mean Grad Norm: 3.432720899581909\n",
      "custom_loss_function steps: 260736 output dim: 208 loss: 0.000343277002684772 Mean Grad Norm: 3.432770252227783\n",
      "custom_loss_function steps: 260864 output dim: 145 loss: 0.0003432817757129669 Mean Grad Norm: 3.4328179359436035\n",
      "custom_loss_function steps: 260992 output dim: 329 loss: 0.0003432861703913659 Mean Grad Norm: 3.432861804962158\n",
      "custom_loss_function steps: 261120 output dim: 135 loss: 0.0003432903322391212 Mean Grad Norm: 3.432903289794922\n",
      "custom_loss_function steps: 261248 output dim: 134 loss: 0.0003432946978136897 Mean Grad Norm: 3.4329469203948975\n",
      "custom_loss_function steps: 261376 output dim: 211 loss: 0.00034329938353039324 Mean Grad Norm: 3.4329938888549805\n",
      "custom_loss_function steps: 261504 output dim: 131 loss: 0.00034330360358580947 Mean Grad Norm: 3.4330360889434814\n",
      "custom_loss_function steps: 261632 output dim: 118 loss: 0.00034330753260292113 Mean Grad Norm: 3.433075428009033\n",
      "custom_loss_function steps: 261760 output dim: 302 loss: 0.00034331210190430284 Mean Grad Norm: 3.4331212043762207\n",
      "custom_loss_function steps: 261888 output dim: 64 loss: 0.00034331774804741144 Mean Grad Norm: 3.4331777095794678\n",
      "custom_loss_function steps: 262016 output dim: 67 loss: 0.0003433226956985891 Mean Grad Norm: 3.433227062225342\n",
      "custom_loss_function steps: 262144 output dim: 110 loss: 0.000343327468726784 Mean Grad Norm: 3.433274745941162\n",
      "custom_loss_function steps: 262272 output dim: 175 loss: 0.00034333288203924894 Mean Grad Norm: 3.433328866958618\n",
      "custom_loss_function steps: 262400 output dim: 141 loss: 0.00034333858639001846 Mean Grad Norm: 3.4333858489990234\n",
      "custom_loss_function steps: 262528 output dim: 145 loss: 0.0003433437959756702 Mean Grad Norm: 3.4334380626678467\n",
      "custom_loss_function steps: 262656 output dim: 91 loss: 0.0003433489182498306 Mean Grad Norm: 3.4334893226623535\n",
      "custom_loss_function steps: 262784 output dim: 124 loss: 0.0003433546226006001 Mean Grad Norm: 3.433546304702759\n",
      "custom_loss_function steps: 262912 output dim: 197 loss: 0.0003433598903939128 Mean Grad Norm: 3.4335989952087402\n",
      "custom_loss_function steps: 263040 output dim: 85 loss: 0.0003433647798374295 Mean Grad Norm: 3.433647871017456\n",
      "custom_loss_function steps: 263168 output dim: 86 loss: 0.0003433692327234894 Mean Grad Norm: 3.433692455291748\n",
      "custom_loss_function steps: 263296 output dim: 195 loss: 0.00034337304532527924 Mean Grad Norm: 3.4337306022644043\n",
      "custom_loss_function steps: 263424 output dim: 126 loss: 0.00034337691613473 Mean Grad Norm: 3.4337692260742188\n",
      "custom_loss_function steps: 263552 output dim: 72 loss: 5.333869457244873 Mean Grad Norm: 3.4338014125823975\n",
      "custom_loss_function steps: 263680 output dim: 74 loss: 0.0003433834353927523 Mean Grad Norm: 3.4338343143463135\n",
      "custom_loss_function steps: 263808 output dim: 293 loss: 0.0003433871315792203 Mean Grad Norm: 3.433871269226074\n",
      "custom_loss_function steps: 263936 output dim: 101 loss: 0.00034339085686951876 Mean Grad Norm: 3.433908700942993\n",
      "custom_loss_function steps: 264064 output dim: 777 loss: 0.00034339423291385174 Mean Grad Norm: 3.4339423179626465\n",
      "custom_loss_function steps: 264192 output dim: 92 loss: 0.00034339804551564157 Mean Grad Norm: 3.4339804649353027\n",
      "custom_loss_function steps: 264320 output dim: 281 loss: 0.00034340147976763546 Mean Grad Norm: 3.4340147972106934\n",
      "custom_loss_function steps: 264448 output dim: 108 loss: 0.0003434045647736639 Mean Grad Norm: 3.4340457916259766\n",
      "custom_loss_function steps: 264576 output dim: 167 loss: 0.00034340840647928417 Mean Grad Norm: 3.434084177017212\n",
      "custom_loss_function steps: 264704 output dim: 119 loss: 0.0003434129757806659 Mean Grad Norm: 3.4341297149658203\n",
      "custom_loss_function steps: 264832 output dim: 129 loss: 0.00034341710852459073 Mean Grad Norm: 3.434171199798584\n",
      "custom_loss_function steps: 264960 output dim: 199 loss: 0.0003434215614106506 Mean Grad Norm: 3.434215784072876\n",
      "custom_loss_function steps: 265088 output dim: 155 loss: 0.0003434255195315927 Mean Grad Norm: 3.434255361557007\n",
      "custom_loss_function steps: 265216 output dim: 119 loss: 0.00034342912840656936 Mean Grad Norm: 3.434291362762451\n",
      "custom_loss_function steps: 265344 output dim: 111 loss: 0.0003434323880355805 Mean Grad Norm: 3.434324026107788\n",
      "custom_loss_function steps: 265472 output dim: 314 loss: 0.0003434352402109653 Mean Grad Norm: 3.434352397918701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:192: UserWarning: Could not find a config file in /mnt/data/deepseek-math-7b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_loss_function steps: 265600 output dim: 85 loss: 5.342731475830078 Mean Grad Norm: 3.434378147125244\n",
      "custom_loss_function steps: 265728 output dim: 156 loss: 0.00034344065352343023 Mean Grad Norm: 3.4344067573547363\n",
      "custom_loss_function steps: 265856 output dim: 357 loss: 0.00034344420419074595 Mean Grad Norm: 3.4344420433044434\n",
      "custom_loss_function steps: 266112 output dim: 136 loss: 0.0003434519749134779 Mean Grad Norm: 3.4345197677612305\n",
      "custom_loss_function steps: 266240 output dim: 124 loss: 0.00034345564199611545 Mean Grad Norm: 3.434556484222412\n",
      "custom_loss_function steps: 266368 output dim: 233 loss: 0.0003434587852098048 Mean Grad Norm: 3.4345879554748535\n",
      "custom_loss_function steps: 266496 output dim: 95 loss: 0.00034346242318861187 Mean Grad Norm: 3.434624433517456\n",
      "custom_loss_function steps: 266624 output dim: 173 loss: 0.0003434657119214535 Mean Grad Norm: 3.434657335281372\n",
      "custom_loss_function steps: 266752 output dim: 58 loss: 5.861666202545166 Mean Grad Norm: 3.434694766998291\n",
      "custom_loss_function steps: 266880 output dim: 83 loss: 5.791387557983398 Mean Grad Norm: 3.4347293376922607\n",
      "custom_loss_function steps: 267008 output dim: 106 loss: 0.0003434769460000098 Mean Grad Norm: 3.434769630432129\n",
      "custom_loss_function steps: 267136 output dim: 219 loss: 0.0003434807003941387 Mean Grad Norm: 3.434807062149048\n",
      "custom_loss_function steps: 267264 output dim: 366 loss: 0.0003434840473346412 Mean Grad Norm: 3.434840679168701\n",
      "custom_loss_function steps: 267392 output dim: 114 loss: 0.0003434874815866351 Mean Grad Norm: 3.434875011444092\n",
      "custom_loss_function steps: 267520 output dim: 371 loss: 6.787457466125488 Mean Grad Norm: 3.434908866882324\n",
      "custom_loss_function steps: 267648 output dim: 96 loss: 5.804851055145264 Mean Grad Norm: 3.4349400997161865\n",
      "custom_loss_function steps: 267776 output dim: 70 loss: 5.621005535125732 Mean Grad Norm: 3.434979200363159\n",
      "custom_loss_function steps: 267904 output dim: 94 loss: 0.00034350150963291526 Mean Grad Norm: 3.4350152015686035\n",
      "custom_loss_function steps: 268032 output dim: 104 loss: 0.00034350500209257007 Mean Grad Norm: 3.4350502490997314\n",
      "custom_loss_function steps: 268160 output dim: 280 loss: 0.0003435084072407335 Mean Grad Norm: 3.435084104537964\n",
      "custom_loss_function steps: 268288 output dim: 169 loss: 0.00034351125941611826 Mean Grad Norm: 3.435112714767456\n",
      "custom_loss_function steps: 268416 output dim: 334 loss: 0.0003435139951761812 Mean Grad Norm: 3.4351401329040527\n",
      "custom_loss_function steps: 268544 output dim: 145 loss: 0.00034351632348261774 Mean Grad Norm: 3.4351632595062256\n",
      "custom_loss_function steps: 268672 output dim: 346 loss: 0.0003435184189584106 Mean Grad Norm: 3.4351842403411865\n",
      "custom_loss_function steps: 268800 output dim: 85 loss: 0.00034352033981122077 Mean Grad Norm: 3.4352035522460938\n",
      "custom_loss_function steps: 268928 output dim: 87 loss: 0.00034352208604104817 Mean Grad Norm: 3.435220956802368\n",
      "custom_loss_function steps: 269056 output dim: 215 loss: 0.0003435235994402319 Mean Grad Norm: 3.4352359771728516\n",
      "custom_loss_function steps: 269184 output dim: 160 loss: 0.00034352499642409384 Mean Grad Norm: 3.4352500438690186\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=\"/mnt/data/deepseekTrain0/checkpoint-1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model() # 用它保存,用 AutoPeftModelForCausalLM 读取"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save_pretrained(\"I:/kaggle/wizardAd1\", max_shard_size = '2GB',) # 它没用,保存之后读不出来"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-10T16:32:18.804826Z",
     "iopub.status.busy": "2024-05-10T16:32:18.804678Z",
     "iopub.status.idle": "2024-05-11T02:11:17.659135Z",
     "shell.execute_reply": "2024-05-11T02:11:17.657563Z",
     "shell.execute_reply.started": "2024-05-10T16:32:18.804806Z"
    },
    "tags": []
   },
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=\"/mnt/data/deepseekTrain0/checkpoint-1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTl608RhmJKK"
   },
   "source": [
    "Start training our model by calling the `train()` method on our `Trainer` instance. This will start the training loop and train our model for 3 epochs. Since we are using a PEFT method, we will only save the adapted model weights and not the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzr7YhWHmJKL"
   },
   "source": [
    "It took ~3.5 hrs on the free T4 GPU in Google Colab to finish training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQ5O_AEWmJKL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# free the memory again\n",
    "# del model\n",
    "# del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "hWftnY0emJKL"
   },
   "source": [
    "### Merge LoRA adapter in to the original model_\n",
    "\n",
    "When using QLoRA, we only train adapters and not the full model. This means when saving the model during training we only save the adapter weights and not the full model. If you want to save the full model, which makes it easier to use with Text Generation Inference you can merge the adapter weights into the model weights using the `merge_and_unload` method and then save the model with the `save_pretrained` method. This will save a default model, which can be used for inference.\n",
    "\n",
    "Note: You might require > 30GB CPU Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "e70a0e15ce754d3797232a4e38df2ab5",
      "f245372f35264612a6d32b915fc48991",
      "62193c34c72b40de859bc669faa4ba5c",
      "77f8f78435cd4d938f6e9a8454e64e2c",
      "cfec54bb2f2d4ce8966a1a1a86948059",
      "76ef685779b44f50847f38f4060a3d03",
      "02d6241a9eae4251a8f728f0c0a6df06",
      "02575f561563479dabb25807d5c84a3c",
      "be9604e0390445eeac84f4f6f104be08",
      "e73c1b21bd1a428987d34c9499edfe99",
      "37788f87e3fc48e59bf99a60d6084ef4"
     ]
    },
    "id": "ihxnz9kdmJKL",
    "outputId": "3c830e62-7248-4a0c-d8ac-c2f4e25587c0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MERGE PEFT AND BASE MODEL 官方参数不要变 , 不要用量化加载合并, 合并的模型精度不行 报废\n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "checkPoint = \"/checkpoint-1000\"\n",
    "checkPoint = \"\"\n",
    "try:\n",
    "    # Load PEFT model on CPU\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        train_args.output_dir + checkPoint,\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        train_args.output_dir + checkPoint,\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "e70a0e15ce754d3797232a4e38df2ab5",
      "f245372f35264612a6d32b915fc48991",
      "62193c34c72b40de859bc669faa4ba5c",
      "77f8f78435cd4d938f6e9a8454e64e2c",
      "cfec54bb2f2d4ce8966a1a1a86948059",
      "76ef685779b44f50847f38f4060a3d03",
      "02d6241a9eae4251a8f728f0c0a6df06",
      "02575f561563479dabb25807d5c84a3c",
      "be9604e0390445eeac84f4f6f104be08",
      "e73c1b21bd1a428987d34c9499edfe99",
      "37788f87e3fc48e59bf99a60d6084ef4"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-05-11T18:43:16.573533Z",
     "iopub.status.busy": "2024-05-11T18:43:16.573162Z",
     "iopub.status.idle": "2024-05-11T18:43:32.168310Z",
     "shell.execute_reply": "2024-05-11T18:43:32.167776Z",
     "shell.execute_reply.started": "2024-05-11T18:43:16.573512Z"
    },
    "id": "ihxnz9kdmJKL",
    "outputId": "3c830e62-7248-4a0c-d8ac-c2f4e25587c0",
    "tags": []
   },
   "source": [
    "# MERGE PEFT AND BASE MODEL 官方参数不要变 , 不要用量化加载合并, 合并的模型精度不行 报废\n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "try:\n",
    "    # Load PEFT model on CPU\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        train_args.output_dir + \"/checkpoint-50\",\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        train_args.output_dir + \"/checkpoint-50\",\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "e70a0e15ce754d3797232a4e38df2ab5",
      "f245372f35264612a6d32b915fc48991",
      "62193c34c72b40de859bc669faa4ba5c",
      "77f8f78435cd4d938f6e9a8454e64e2c",
      "cfec54bb2f2d4ce8966a1a1a86948059",
      "76ef685779b44f50847f38f4060a3d03",
      "02d6241a9eae4251a8f728f0c0a6df06",
      "02575f561563479dabb25807d5c84a3c",
      "be9604e0390445eeac84f4f6f104be08",
      "e73c1b21bd1a428987d34c9499edfe99",
      "37788f87e3fc48e59bf99a60d6084ef4"
     ]
    },
    "id": "ihxnz9kdmJKL",
    "outputId": "3c830e62-7248-4a0c-d8ac-c2f4e25587c0",
    "tags": []
   },
   "source": [
    "# MERGE PEFT AND BASE MODEL 官方参数不要变 , 不要用量化加载合并, 合并的模型精度不行 报废\n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "# Load PEFT model on CPU\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    train_args.output_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "e70a0e15ce754d3797232a4e38df2ab5",
      "f245372f35264612a6d32b915fc48991",
      "62193c34c72b40de859bc669faa4ba5c",
      "77f8f78435cd4d938f6e9a8454e64e2c",
      "cfec54bb2f2d4ce8966a1a1a86948059",
      "76ef685779b44f50847f38f4060a3d03",
      "02d6241a9eae4251a8f728f0c0a6df06",
      "02575f561563479dabb25807d5c84a3c",
      "be9604e0390445eeac84f4f6f104be08",
      "e73c1b21bd1a428987d34c9499edfe99",
      "37788f87e3fc48e59bf99a60d6084ef4"
     ]
    },
    "id": "ihxnz9kdmJKL",
    "outputId": "3c830e62-7248-4a0c-d8ac-c2f4e25587c0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge LoRA and base model and save\n",
    "merged_model = model.merge_and_unload()\n",
    "print(\"merge_and_unload finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_model.save_pretrained(train_args.output_dir + \"Merged\", safe_serialization=True, max_shard_size=\"2GB\")\n",
    "print(train_args.output_dir + \"Merged\", \"save_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_tokenize_function(examples, tokenizer):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    question = examples[\"question\"]\n",
    "    context = \"\"\n",
    "    system = \"You're an expert Python programmer and mathematician. Help the user to solve this problem using code when necessary. \\\n",
    "Make sure to put the answer (and only answer) inside \\\\boxed{}.\"\n",
    "    user = f\"{question}\\n\\n{context}\"\n",
    "    generated_solution = \"\"\n",
    "    Q = f\"System:\\n{system}\\n\\nUser:\\n{user}Assistant:\\n{generated_solution}\"\n",
    "    \n",
    "    input_ids = tokenizer(Q, return_tensors=\"pt\", padding=\"longest\", max_length=4096,\n",
    "                          truncation=True, add_special_tokens=True)\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(dataset[\"test\"][0][\"input_ids\"]).unsqueeze(0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "del model, merged_model\n",
    "for i in range(5):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if isWin:\n",
    "    model_name = \"I:/kaggle/deepseek-math-7b-it\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"I:/kaggle/deepseek-math-7b-it\")\n",
    "    attn_implementation=None\n",
    "else:\n",
    "    model_name = \"/mnt/data/deepseek-math-7b-it\"\n",
    "    model_name = \"/mnt/data/deepseek-math-7b-it-Train\" + str(shard) + \"Merged\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"/mnt/data/deepseek-math-7b-it\")\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             attn_implementation = attn_implementation,\n",
    "                                             quantization_config=bnb_config)\n",
    "\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxloutword=2000\n",
    "max_new_tokens=None\n",
    "outputs = model.generate(input_ids=input_ids, max_length=maxloutword, max_new_tokens=max_new_tokens, num_beams=1, pad_token_id=tokenizer.pad_token_id)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resultTxt = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(resultTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = tokenizer.decode(dataset[\"test\"][0][\"labels\"], skip_special_tokens=True)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "src_file = 'largeLossRecords.deepseekmath.' + str(shard) + '.json'\n",
    "dst_file = '/mnt/data/' + 'largeLossRecords.deepseekmath.' + str(shard) + '.json'\n",
    "shutil.copy2(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.copy2(train_args.output_dir + \"/trainer_state.json\", train_args.output_dir + \"Merged/trainer_state.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd = \"cp \" + train_args.output_dir + \"/trainer_state.json \" + train_args.output_dir + \"Merged/trainer_state.json\"\n",
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bash -c \"$cmd\"\n",
    "!sleep 5s\n",
    "!kill -SIGTERM 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "XOjv6NTMmJKL"
   },
   "source": [
    "## 4. Test Model and run Inference\n",
    "Note: Evaluating Generative AI models is not a trivial task since 1 input can have multiple correct outputs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "b7323429c5b8490693b3da75dca6ffcd",
      "f2f5ecc068284ce2a8bdf7c22a2fbd24",
      "2751626066e84ce7b9c37babc2a89e2c",
      "13bdd1b732bf4df9bc8cb76ccff3b24c",
      "fefde476a4904defb603dfd4e83011a7",
      "992690906540442ca0fa3e08651221fe",
      "5d9c46c38136490d8507aa2954a930d8",
      "5eb0dd76b7c14211adb7ca9f6d04ee41",
      "d6c1dcbefd804d7c8d25866d69fa3b29",
      "ebc1b53d5d2d44ceb2588fa6fd84dcad",
      "c5925ecc3a03493b805f4821d8a810ee"
     ]
    },
    "id": "_uMuQ-DsmJKL",
    "outputId": "8aef4296-2e45-44ce-f726-d3c26b62db57"
   },
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "peft_model_id = \"/mnt/data/outputMergedModel\"\n",
    "\n",
    "# Load Model with PEFT adapter\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  peft_model_id,\n",
    "  device_map=\"auto\",\n",
    "  torch_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "# load into pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uPKvRxfmJKL"
   },
   "source": [
    "Let’s load our test dataset try to generate an instruction."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "hH-Z99-sV4O2"
   },
   "source": [
    "## 5. Next step\n",
    "1. Scale it up (more data, more compute, bigger model Gemma 7B to build a more powerful model *or*\n",
    "2. Add domain data so that the model can do well in your specific area of interest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainer.train(resume_from_checkpoint = 'checkpoint目录')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from transformers import Trainer\n",
    "import os\n",
    "from peft import PeftModel\n",
    "from transformers.utils import (\n",
    "    ADAPTER_SAFE_WEIGHTS_NAME,\n",
    "    ADAPTER_WEIGHTS_NAME,\n",
    "    is_sagemaker_mp_enabled,\n",
    "    is_peft_available,\n",
    "    logging,\n",
    ")\n",
    " \n",
    "logger = logging.get_logger(__name__)\n",
    " \n",
    "class PeftTrainer(Trainer):\n",
    " \n",
    "    def _load_from_peft_checkpoint(self, resume_from_checkpoint, model):\n",
    "        adapter_weights_file = os.path.join(resume_from_checkpoint, ADAPTER_WEIGHTS_NAME)\n",
    "        adapter_safe_weights_file = os.path.join(resume_from_checkpoint, ADAPTER_SAFE_WEIGHTS_NAME)\n",
    " \n",
    "        if not any(\n",
    "            os.path.isfile(f) for f in [adapter_weights_file, adapter_safe_weights_file]\n",
    "        ):\n",
    "            raise ValueError(f\"Can't find a valid checkpoint at {resume_from_checkpoint}\")\n",
    " \n",
    "        logger.info(f\"Loading model from {resume_from_checkpoint}.\")\n",
    "        # Load adapters following PR # 24096 \n",
    "        if is_peft_available() and isinstance(model, PeftModel):\n",
    "            # If train a model using PEFT & LoRA, assume that adapter have been saved properly.\n",
    "            if hasattr(model, \"active_adapter\") and hasattr(model, \"load_adapter\"):\n",
    "                if os.path.exists(resume_from_checkpoint) or os.path.exists(resume_from_checkpoint):\n",
    "                    model.load_adapter(resume_from_checkpoint, model.active_adapter)\n",
    "                    # Load_adapter has no return value present, modify it when appropriate.\n",
    "                    from torch.nn.modules.module import _IncompatibleKeys\n",
    " \n",
    "                    load_result = _IncompatibleKeys([], [])\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        \"The intermediate checkpoints of PEFT may not be saved correctly, \"\n",
    "                        f\"using `TrainerCallback` to save {ADAPTER_WEIGHTS_NAME} in corresponding folders, \"\n",
    "                        \"here are some examples https://github.com/huggingface/peft/issues/96\"\n",
    "                    )\n",
    "            else:\n",
    "                logger.warning(\"Could not load adapter model, make sure to have `peft>=0.3.0` installed\")\n",
    " \n",
    "    def _load_from_checkpoint(self, resume_from_checkpoint, model=None):\n",
    " \n",
    "        if model is None:\n",
    "            model = self.model_wrapped if is_sagemaker_mp_enabled() else self.model\n",
    "        if is_peft_available() and isinstance(model, PeftModel):\n",
    "            # Try to load adapters before trying to load a torch model\n",
    "            try:\n",
    "                return self._load_from_peft_checkpoint(resume_from_checkpoint, model=model)\n",
    "            except:\n",
    "                return super()._load_from_checkpoint(resume_from_checkpoint, model=model)\n",
    "            # If it is not a PeftModel, use the original _load_from_checkpoint\n",
    "        else:\n",
    "            return super()._load_from_checkpoint(resume_from_checkpoint, model=model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "share": {
   "datetime": "2024-04-22T18:57:23.242Z",
   "image": {
    "name": "modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-cpu-py310-ubuntu22.04",
    "url": "dsw-registry-vpc.cn-beijing.cr.aliyuncs.com/pai/modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-cpu-py310-ubuntu22.04"
   },
   "instance": "dsw-26927642f1cd1802",
   "spec": {
    "id": "ecs.c6.large",
    "type": "CPU"
   },
   "uid": "1997963905750917"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007cfd8a537142229c2d235b15400c8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "00a76cb5cc95473bbb6ddb508fcbd699": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59332a992769404598deda3e9ca58e67",
      "placeholder": "​",
      "style": "IPY_MODEL_4cfec8c44e024ab3894b2d2fae85ed5c",
      "value": "tokenizer.model: 100%"
     }
    },
    "01b42d47976f40a1906cbe42f6c60c3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02575f561563479dabb25807d5c84a3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02d6241a9eae4251a8f728f0c0a6df06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "032f0226c35449a2896e7ed91fcd386e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b9f33eba5924aeda288228e798bca13",
      "placeholder": "​",
      "style": "IPY_MODEL_69d50e01293b4bdca4660ab260e3c6a2",
      "value": "Creating json from Arrow format: 100%"
     }
    },
    "045a50a6c75b411b80a7b5027e51c181": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "06479897f6274233af05cdf0668ca1db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_42404638dd694d3d8a3cfdd138d6fc66",
       "IPY_MODEL_091ace5b54a74902850ed61a6f655946",
       "IPY_MODEL_922dc79bc31444709d6f7eb530eaf64f"
      ],
      "layout": "IPY_MODEL_58e2d80780084dc4b07007793da1e8ea"
     }
    },
    "068f7c7cb6eb4e3fbc1ba47069eae016": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "091ace5b54a74902850ed61a6f655946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c78f2b49dc0e471d9b45e02468847172",
      "max": 1108,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24992123bc334c288a1a019a6fa198bb",
      "value": 1108
     }
    },
    "096c3d2c072c450487e42f64732fee60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71bda48290eb4d7dbe5a933fba3dda11",
       "IPY_MODEL_47521b61c9d7430d8dfd8255e29b60a2",
       "IPY_MODEL_09ded4e6f5374ed6a3904252ee0736a3"
      ],
      "layout": "IPY_MODEL_b07fad7d5a47401ca71d2a92f0091b8a"
     }
    },
    "09ded4e6f5374ed6a3904252ee0736a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_938b866becb44e1587a08f6208dbae70",
      "placeholder": "​",
      "style": "IPY_MODEL_afe89bfcf37441b8ba52027c648af168",
      "value": " 2/2 [00:23&lt;00:00,  9.82s/it]"
     }
    },
    "0b3ef4c5e1fe4bd98af4aeb06cc6b2d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c172a14961d4f438de225049d9044df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_340e738ce18949c48d4e1d1a31bbd88a",
      "placeholder": "​",
      "style": "IPY_MODEL_17a0ffcaf2044ee6bcc92908ff45a159",
      "value": " 750/0 [00:02&lt;00:00, 535.46 examples/s]"
     }
    },
    "0d5ecd11429040e68195365208ef0119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0fbf798e6e1b41d0b312dbba47775151": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10733a8728304535b92fdae1793bb5b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1112d215714b4840ad87b7ef68fd3398": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d78129063f944f3b958fdc822ad9c099",
      "max": 67121608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9ae47e1b51c4d1ab283b107405e7047",
      "value": 67121608
     }
    },
    "11e94b1e39294c18a999406eabeb05e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12bff94024954bc8821ea4a44a840e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "12d445af02ea423c9aad5787fa77c458": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d5bef3679d4ab2912925ec2ea989d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "138f18f322b24b44b57903bd3217c829": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7054268f0c6a413dbbfcd9bf02934d11",
      "placeholder": "​",
      "style": "IPY_MODEL_8e917a14602149b9a65af221a78b1d2a",
      "value": " 137/137 [00:00&lt;00:00, 8.97kB/s]"
     }
    },
    "13bdd1b732bf4df9bc8cb76ccff3b24c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebc1b53d5d2d44ceb2588fa6fd84dcad",
      "placeholder": "​",
      "style": "IPY_MODEL_c5925ecc3a03493b805f4821d8a810ee",
      "value": " 2/2 [00:29&lt;00:00, 12.41s/it]"
     }
    },
    "13e3e63b9b15449ab4ef12d616d8cf8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c53421f3e144a5c8f177776cdb27f4d",
      "placeholder": "​",
      "style": "IPY_MODEL_ada74a8c85d048f0a21d2aa87805ea57",
      "value": "Generating train split: 100%"
     }
    },
    "1474b943860a4eec9dd0857aa9d06ccc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1498fe42ab654942a06fc77e6126ed55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "156fdb05e0174c01b8b8654b53678f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16cc37a8ccfb495aa1dd00b840c80979": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_707bf67138fc408bbc5fca19ba3da979",
      "placeholder": "​",
      "style": "IPY_MODEL_1d37d6633632461f810b1c58ea8b5808",
      "value": "config.json: 100%"
     }
    },
    "175960d3168c412cabb59bfe78b03ecc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17a0ffcaf2044ee6bcc92908ff45a159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "197ae61c4bf848db8be190fee88e19cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8efb03187fee4246b82a6bdfc547e89b",
      "placeholder": "​",
      "style": "IPY_MODEL_29c8129f38304342a613f57ca29a8294",
      "value": " 627/627 [00:00&lt;00:00, 21.6kB/s]"
     }
    },
    "1bd32cea190448f69aed171933d17da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c8330917ed84143b4ce70e9c00ae321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_435bcb23f0704c7fa272555813500683",
      "max": 4241003,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_045a50a6c75b411b80a7b5027e51c181",
      "value": 4241003
     }
    },
    "1d37d6633632461f810b1c58ea8b5808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1daf70f309724a929872d41dbf3d376f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de902ded9fef41f4ae3d1ccbda5e1258",
      "placeholder": "​",
      "style": "IPY_MODEL_aa457525adf340dea4c6202c01362726",
      "value": "Downloading shards: 100%"
     }
    },
    "21615c5b5d8c4e84879d2aaf81d1bb43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb67dec7271c44fd889ebbaa85d56802",
      "placeholder": "​",
      "style": "IPY_MODEL_c986036531e448bb8116b435837691ef",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "24992123bc334c288a1a019a6fa198bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24d2deefe80f443094703c1ebe7f1380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2751626066e84ce7b9c37babc2a89e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5eb0dd76b7c14211adb7ca9f6d04ee41",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6c1dcbefd804d7c8d25866d69fa3b29",
      "value": 2
     }
    },
    "29c8129f38304342a613f57ca29a8294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a697b9a7d254aa28224d575b0c115b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c45f7a00fdd4e8b97de882870a106e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c75a816067041619e25612e46720b1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0c8764dcdae4187b4a4131ea1e8c88d",
      "placeholder": "​",
      "style": "IPY_MODEL_156fdb05e0174c01b8b8654b53678f67",
      "value": " 2.81M/2.81M [00:00&lt;00:00, 3.38MB/s]"
     }
    },
    "2cc8532abd1f43dcbd1f995c0e723bfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e5c783c78a74c5993c9209cec54e719": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ee86ba7d8bd488e8d008a30cd22e3e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f67e4575954a2caf8bed2265a583d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31686c96e7af40d092dd93b5ee483978": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_032f0226c35449a2896e7ed91fcd386e",
       "IPY_MODEL_862b7ba3b11f44439c307ead7344d2cb",
       "IPY_MODEL_3f1434935da240c386618b8022a5fbf9"
      ],
      "layout": "IPY_MODEL_a85d45deaa2d4257a5603d6ccd9a7bb9"
     }
    },
    "31c5d5388a2b4c668ad12587e188cfb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "323c0c03593f4bf38c5731d04cd72998": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_987cb2c7d6b1438b86a6d95fd351840d",
      "placeholder": "​",
      "style": "IPY_MODEL_ccaaa00b2acf4fa1b6aa0fb66f7d3ea6",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "328ed3cebac940d3ad0b46f4d86ebd3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32b892b3a25c4fee8b8d7cd76de556f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "340e738ce18949c48d4e1d1a31bbd88a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34aece58f82c4bffbbb1d214197e9da6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37788f87e3fc48e59bf99a60d6084ef4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39dad16cb7cf402fa11643da3dfea7c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3abc9d04fe214a96bb6431e5ac18e1ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7ea7fe5345b42428903d157f149ce10",
       "IPY_MODEL_c9824521bd394d2cb69f8d432bb16de4",
       "IPY_MODEL_69184744f9ed4a549f04d613a44ca7d9"
      ],
      "layout": "IPY_MODEL_328ed3cebac940d3ad0b46f4d86ebd3c"
     }
    },
    "3cc87f748baa492d94ded7a30a861b5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ffea054e09744301ac4300e8c53406c3",
       "IPY_MODEL_1112d215714b4840ad87b7ef68fd3398",
       "IPY_MODEL_462f07486b424f84897ac26c063c71a0"
      ],
      "layout": "IPY_MODEL_e4143b8db5f9409ab655a2dd85f19520"
     }
    },
    "3d153896aee2452aa68724031468f81d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d96fb1090fb04da19dd8b10cb76d7393",
      "placeholder": "​",
      "style": "IPY_MODEL_aa31001338eb49b9800ec773d2b7415c",
      "value": " 4.24M/4.24M [00:00&lt;00:00, 16.9MB/s]"
     }
    },
    "3f1434935da240c386618b8022a5fbf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4384ae8aed14fb2b6bfd95d3a948d30",
      "placeholder": "​",
      "style": "IPY_MODEL_55b0f3cf946e4bba8576ff9c35d3c4dd",
      "value": " 1/1 [00:00&lt;00:00,  9.68ba/s]"
     }
    },
    "40655705a3c94b18aa2dda12570dfd2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42180aa2bef94f899376dc993f549810": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42404638dd694d3d8a3cfdd138d6fc66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8768fa4dccbb409391ac0a7d4a1d2611",
      "placeholder": "​",
      "style": "IPY_MODEL_aefe6b26137a4051a4a6eee34202222f",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "426a6f2b9dc44149a4b2fa3208109590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1136e7f5c9d4d41bb4606e0d17429b5",
      "placeholder": "​",
      "style": "IPY_MODEL_b06dc128b7374396abe5c41de11eb0a7",
      "value": "Generating train split: "
     }
    },
    "42927861ab844eec9b279a221f574ecf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "435bcb23f0704c7fa272555813500683": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43c08dffca244f849456ede07572064a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5651bb0eaff04486831b58b2b57b89ce",
       "IPY_MODEL_cb4441030c074583b5484f47e8098914",
       "IPY_MODEL_859510d2bfb24b72855c7efbb7c19803"
      ],
      "layout": "IPY_MODEL_a8b4cada8cf8458da963b8491f379fcf"
     }
    },
    "462f07486b424f84897ac26c063c71a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_759aebed80f2496cbefeae2c4279f59d",
      "placeholder": "​",
      "style": "IPY_MODEL_d21f79fd666e49b2906dae1390932099",
      "value": " 67.1M/67.1M [00:00&lt;00:00, 267MB/s]"
     }
    },
    "4701f15db2f547e89fae6b90b13ff846": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4a1a352853f4b2c9c77240b1ca49b9b",
      "placeholder": "​",
      "style": "IPY_MODEL_5e7fad834ce64f04bce884f79696003a",
      "value": " 4617/4617 [00:00&lt;00:00, 24280.28 examples/s]"
     }
    },
    "47521b61c9d7430d8dfd8255e29b60a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa49e0b5fd2b4f0192649cb3da665a28",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1b13313b731401a89bc2d4dd9018818",
      "value": 2
     }
    },
    "4c85b82fd1e64f088e8db094c0257f6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_00a76cb5cc95473bbb6ddb508fcbd699",
       "IPY_MODEL_1c8330917ed84143b4ce70e9c00ae321",
       "IPY_MODEL_3d153896aee2452aa68724031468f81d"
      ],
      "layout": "IPY_MODEL_40655705a3c94b18aa2dda12570dfd2f"
     }
    },
    "4cfec8c44e024ab3894b2d2fae85ed5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d9c16ab8af44e799be88f59a1edea94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d31839d6366a45caa66bbff9706f1c33",
      "max": 555,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75c17d67086c44f6a6849b543364bde2",
      "value": 555
     }
    },
    "4fe593d166024384a2dc0ec21d00b176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13e3e63b9b15449ab4ef12d616d8cf8b",
       "IPY_MODEL_c542d12ff49e4906a929c20dcae6211c",
       "IPY_MODEL_4701f15db2f547e89fae6b90b13ff846"
      ],
      "layout": "IPY_MODEL_50e4e01a0d544b11b0dcf230719b7f16"
     }
    },
    "50e4e01a0d544b11b0dcf230719b7f16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55009b25754143baba31ceb76ac875ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55b0f3cf946e4bba8576ff9c35d3c4dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "562cb530ea4b4ad7a7e5eef39222222b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5651bb0eaff04486831b58b2b57b89ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12d445af02ea423c9aad5787fa77c458",
      "placeholder": "​",
      "style": "IPY_MODEL_d82646bbbd064b44802c0eee8b3a3655",
      "value": "Creating json from Arrow format: 100%"
     }
    },
    "5772b7b0e2b746c681633f47149100d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0a321a6dd7c4798afa3ab38a0ccf2cb",
      "max": 13489,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b02bc6faca25412ea8283c64ffd016ac",
      "value": 13489
     }
    },
    "58e2d80780084dc4b07007793da1e8ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "591e62b79c8149619c0cb603bb7072e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59332a992769404598deda3e9ca58e67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "599936f48cd64ec88686ccf23ba27bd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "5bc0366463e441ed8dcd3366478f921f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16cc37a8ccfb495aa1dd00b840c80979",
       "IPY_MODEL_6891a65f8bb949868ed446ccfd308d1c",
       "IPY_MODEL_197ae61c4bf848db8be190fee88e19cb"
      ],
      "layout": "IPY_MODEL_2e5c783c78a74c5993c9209cec54e719"
     }
    },
    "5cf9d8de00cd46c3a1c2c7ffe55ed393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d9c46c38136490d8507aa2954a930d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e7fad834ce64f04bce884f79696003a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e90dcd28cac4ee9ad8265c91548cff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5eb0dd76b7c14211adb7ca9f6d04ee41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fbd29d5a4324815be82272fac4d95fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7df45e2c21f416bb41b84a3ada5beb2",
      "placeholder": "​",
      "style": "IPY_MODEL_12d5bef3679d4ab2912925ec2ea989d1",
      "value": " 13.5k/13.5k [00:00&lt;00:00, 286kB/s]"
     }
    },
    "609ef420aad44702b590afbe2fa81756": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6123674bc4d547888f1f1bf8d44aeee7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62193c34c72b40de859bc669faa4ba5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02575f561563479dabb25807d5c84a3c",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be9604e0390445eeac84f4f6f104be08",
      "value": 2
     }
    },
    "63ea853c844f487bb09f65f2feeff984": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6593cce05bd843a89c2c4eb359dd2b85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67edbbe26a124b0dabdd35a85654aa28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6891a65f8bb949868ed446ccfd308d1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_853ad627aa334416b7a4b55106bc0dbf",
      "max": 627,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f28f7c64e6c0446a82113c4ec1af0193",
      "value": 627
     }
    },
    "68bedf2d19504b96b06ee03838784b04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5f8dc0085744927b7c4d914fbecae7a",
      "placeholder": "​",
      "style": "IPY_MODEL_2cc8532abd1f43dcbd1f995c0e723bfd",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "69184744f9ed4a549f04d613a44ca7d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c64f5056de0d402a9e237bbb450b9adc",
      "placeholder": "​",
      "style": "IPY_MODEL_d66681d9ea324015a5929511b95440f5",
      "value": " 4155/0 [00:00&lt;00:00, 24158.00 examples/s]"
     }
    },
    "69d50e01293b4bdca4660ab260e3c6a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6aa72395a2494379a977587414c52c38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_426a6f2b9dc44149a4b2fa3208109590",
       "IPY_MODEL_aa900b37612d46d8b10d2bb21f101a39",
       "IPY_MODEL_0c172a14961d4f438de225049d9044df"
      ],
      "layout": "IPY_MODEL_79784bdf64254f1dad4b291f5dd98e38"
     }
    },
    "6b10456df05041df985b8752ccf5898c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b338dd6322c4abda77e6dc005029080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6bc000b7fcdc4c84b1707af92d1ba12a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63ea853c844f487bb09f65f2feeff984",
      "placeholder": "​",
      "style": "IPY_MODEL_f8210c6f006447058895e3fa818daf2a",
      "value": "Downloading data: 100%"
     }
    },
    "6bd021532b76412cb055c3e39d3c641e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ec24ce536db4942bfb917a706f8ad45",
      "max": 4617,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12bff94024954bc8821ea4a44a840e32",
      "value": 4617
     }
    },
    "6c44e182b59b4325b66837685173fb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_323c0c03593f4bf38c5731d04cd72998",
       "IPY_MODEL_4d9c16ab8af44e799be88f59a1edea94",
       "IPY_MODEL_e4544f009fb94e95a1c318cf3f0e8b49"
      ],
      "layout": "IPY_MODEL_42180aa2bef94f899376dc993f549810"
     }
    },
    "6c7f60d3377b4fb390c41c943a7795d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f4ee8533ff343478671a7c3233e075e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11e94b1e39294c18a999406eabeb05e0",
      "max": 17477553,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b54bf5e8a5c84e8999a70c6d10f5a863",
      "value": 17477553
     }
    },
    "7054268f0c6a413dbbfcd9bf02934d11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "707bf67138fc408bbc5fca19ba3da979": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "708998649ad74c1b951a39542b364e61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1daf70f309724a929872d41dbf3d376f",
       "IPY_MODEL_e149d40659c942e6b62cba384cd99d5c",
       "IPY_MODEL_a6d4002266044d20a8fffa5b61287336"
      ],
      "layout": "IPY_MODEL_0fbf798e6e1b41d0b312dbba47775151"
     }
    },
    "71bda48290eb4d7dbe5a933fba3dda11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c07459afaf82464da23c865e73b7e80b",
      "placeholder": "​",
      "style": "IPY_MODEL_9ed18b2cacc24e09a55fdac9d82deaef",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "72e5300257f04bdd86a9b6c8ce2f6b08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "759aebed80f2496cbefeae2c4279f59d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75b77ea4041146cd8587f7bb90817873": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68bedf2d19504b96b06ee03838784b04",
       "IPY_MODEL_5772b7b0e2b746c681633f47149100d9",
       "IPY_MODEL_5fbd29d5a4324815be82272fac4d95fa"
      ],
      "layout": "IPY_MODEL_34aece58f82c4bffbbb1d214197e9da6"
     }
    },
    "75c17d67086c44f6a6849b543364bde2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "76ef685779b44f50847f38f4060a3d03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "774c70183a0d49dabc89451c7712be97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77f8f78435cd4d938f6e9a8454e64e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e73c1b21bd1a428987d34c9499edfe99",
      "placeholder": "​",
      "style": "IPY_MODEL_37788f87e3fc48e59bf99a60d6084ef4",
      "value": " 2/2 [00:27&lt;00:00, 11.60s/it]"
     }
    },
    "78a2a37845484ba1825007eeccd32224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb61d047875c4af4adc6d0bb5e0115e6",
      "placeholder": "​",
      "style": "IPY_MODEL_6593cce05bd843a89c2c4eb359dd2b85",
      "value": " 2/2 [00:26&lt;00:00, 11.01s/it]"
     }
    },
    "79784bdf64254f1dad4b291f5dd98e38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b5cb432abbf4cfc83440d8024352b00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c53421f3e144a5c8f177776cdb27f4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e7330c0191d42338824d109ef5b35b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ec24ce536db4942bfb917a706f8ad45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f8b0b36f8b846b9be39df85a4baf3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f88e35aa7a0344a999eececbd31a9847",
       "IPY_MODEL_b7c3fae6a0f847de9f03aa6c7fb91d9d",
       "IPY_MODEL_ef408261c9a9424d8859d4e3efffe062"
      ],
      "layout": "IPY_MODEL_aaab9382ff0e4301bd14bd217d2c9f7e"
     }
    },
    "84fa4041864d4c4d9f6ffab71cde8c58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e536b3a947604bbeb35cab551a8aebfa",
       "IPY_MODEL_a7f2c1d2eeb444c1baec80f2a67283ea",
       "IPY_MODEL_138f18f322b24b44b57903bd3217c829"
      ],
      "layout": "IPY_MODEL_6123674bc4d547888f1f1bf8d44aeee7"
     }
    },
    "853ad627aa334416b7a4b55106bc0dbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "859510d2bfb24b72855c7efbb7c19803": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba7ea628ec594bf99931fd0b50bfe7ec",
      "placeholder": "​",
      "style": "IPY_MODEL_31c5d5388a2b4c668ad12587e188cfb7",
      "value": " 5/5 [00:00&lt;00:00,  8.01ba/s]"
     }
    },
    "860930ccbdfb4fa9954ec8e39f1edde9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b10456df05041df985b8752ccf5898c",
      "max": 4945242264,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d5ecd11429040e68195365208ef0119",
      "value": 4945242264
     }
    },
    "862b7ba3b11f44439c307ead7344d2cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39dad16cb7cf402fa11643da3dfea7c5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b338dd6322c4abda77e6dc005029080",
      "value": 1
     }
    },
    "86bd8f7557d24e7eb664fc19d4ca2a93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8768fa4dccbb409391ac0a7d4a1d2611": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b9f33eba5924aeda288228e798bca13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dc630947fbf4852b25d9d1db6972668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e917a14602149b9a65af221a78b1d2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8efb03187fee4246b82a6bdfc547e89b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "907497e32ece4ce8b820190631b331e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "922dc79bc31444709d6f7eb530eaf64f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f82da5381fdb4112a860e6e7dfcfdbb8",
      "placeholder": "​",
      "style": "IPY_MODEL_10733a8728304535b92fdae1793bb5b0",
      "value": " 1.11k/1.11k [00:00&lt;00:00, 47.5kB/s]"
     }
    },
    "938b866becb44e1587a08f6208dbae70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94e6f75c68d34a27b6cc4411d5fdf1d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "987cb2c7d6b1438b86a6d95fd351840d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "992690906540442ca0fa3e08651221fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b94dcef291f42ecbe60f581797e59b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e4f9354cc944c4f99386a48acde165f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cf9d8de00cd46c3a1c2c7ffe55ed393",
      "placeholder": "​",
      "style": "IPY_MODEL_2a697b9a7d254aa28224d575b0c115b5",
      "value": "Map: 100%"
     }
    },
    "9ed18b2cacc24e09a55fdac9d82deaef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f12c904bdc844a696519b3e6986b996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fef7137378f48bfb5383e979fc8e9e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1e9de4b77e54950835323813f126d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3864b1953ff4af591a5df19f80ad5ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a43d897a45c048fb9c3dc2e2abf652f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_609ef420aad44702b590afbe2fa81756",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e90dcd28cac4ee9ad8265c91548cff9",
      "value": 2
     }
    },
    "a6a3de028e14414cb1c80685cc26853c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6d4002266044d20a8fffa5b61287336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c45f7a00fdd4e8b97de882870a106e6",
      "placeholder": "​",
      "style": "IPY_MODEL_1bd32cea190448f69aed171933d17da4",
      "value": " 2/2 [00:48&lt;00:00, 20.16s/it]"
     }
    },
    "a7a7bb91463648918a7ea9f6e99917c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_21615c5b5d8c4e84879d2aaf81d1bb43",
       "IPY_MODEL_a43d897a45c048fb9c3dc2e2abf652f2",
       "IPY_MODEL_78a2a37845484ba1825007eeccd32224"
      ],
      "layout": "IPY_MODEL_bed787ac4f3240c59f38374b5d4b0c7c"
     }
    },
    "a7f2c1d2eeb444c1baec80f2a67283ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_774c70183a0d49dabc89451c7712be97",
      "max": 137,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_068f7c7cb6eb4e3fbc1ba47069eae016",
      "value": 137
     }
    },
    "a85d45deaa2d4257a5603d6ccd9a7bb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8b4cada8cf8458da963b8491f379fcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa31001338eb49b9800ec773d2b7415c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa457525adf340dea4c6202c01362726": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa49e0b5fd2b4f0192649cb3da665a28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa900b37612d46d8b10d2bb21f101a39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_599936f48cd64ec88686ccf23ba27bd6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8dc630947fbf4852b25d9d1db6972668",
      "value": 1
     }
    },
    "aaab9382ff0e4301bd14bd217d2c9f7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abdb16b883c34bce87eb758c32ada189": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_907497e32ece4ce8b820190631b331e8",
      "placeholder": "​",
      "style": "IPY_MODEL_bfd271db1aa34381984561d6d0849908",
      "value": "tokenizer.json: 100%"
     }
    },
    "ada74a8c85d048f0a21d2aa87805ea57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aefe6b26137a4051a4a6eee34202222f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afe89bfcf37441b8ba52027c648af168": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b02bc6faca25412ea8283c64ffd016ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b06dc128b7374396abe5c41de11eb0a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b07fad7d5a47401ca71d2a92f0091b8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0c8764dcdae4187b4a4131ea1e8c88d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1136e7f5c9d4d41bb4606e0d17429b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b54bf5e8a5c84e8999a70c6d10f5a863": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7323429c5b8490693b3da75dca6ffcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2f5ecc068284ce2a8bdf7c22a2fbd24",
       "IPY_MODEL_2751626066e84ce7b9c37babc2a89e2c",
       "IPY_MODEL_13bdd1b732bf4df9bc8cb76ccff3b24c"
      ],
      "layout": "IPY_MODEL_fefde476a4904defb603dfd4e83011a7"
     }
    },
    "b7c3fae6a0f847de9f03aa6c7fb91d9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94e6f75c68d34a27b6cc4411d5fdf1d3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c7f60d3377b4fb390c41c943a7795d6",
      "value": 1
     }
    },
    "ba31fada7e8648e3a22270af2f370a38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba7ea628ec594bf99931fd0b50bfe7ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be9604e0390445eeac84f4f6f104be08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bed787ac4f3240c59f38374b5d4b0c7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfd271db1aa34381984561d6d0849908": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c07459afaf82464da23c865e73b7e80b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0911e2284c3457694f3252ae0787a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abdb16b883c34bce87eb758c32ada189",
       "IPY_MODEL_6f4ee8533ff343478671a7c3233e075e",
       "IPY_MODEL_f15fed4f17b146aba228cda43ec065c6"
      ],
      "layout": "IPY_MODEL_562cb530ea4b4ad7a7e5eef39222222b"
     }
    },
    "c0a321a6dd7c4798afa3ab38a0ccf2cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4a1a352853f4b2c9c77240b1ca49b9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c542d12ff49e4906a929c20dcae6211c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30f67e4575954a2caf8bed2265a583d8",
      "max": 4617,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf0257bf1eba428d8c475ff263f51f47",
      "value": 4617
     }
    },
    "c5925ecc3a03493b805f4821d8a810ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5f8dc0085744927b7c4d914fbecae7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c64f5056de0d402a9e237bbb450b9adc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c68f6d84e22b442d98f3ed5b2f4df115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c78f2b49dc0e471d9b45e02468847172": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9824521bd394d2cb69f8d432bb16de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1498fe42ab654942a06fc77e6126ed55",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe037efafdd2438799b57bf60f3ffad2",
      "value": 1
     }
    },
    "c986036531e448bb8116b435837691ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9fabaa1a89747bda99f556ed8cfa3eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d0eedbbce9464d6e9e21367a3dfe1b3d",
       "IPY_MODEL_860930ccbdfb4fa9954ec8e39f1edde9",
       "IPY_MODEL_e33cc2696c8548fe8000a5882a51100c"
      ],
      "layout": "IPY_MODEL_ba31fada7e8648e3a22270af2f370a38"
     }
    },
    "cb4441030c074583b5484f47e8098914": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67edbbe26a124b0dabdd35a85654aa28",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1cfc4a4074d40e9bf587f8f2cb6a047",
      "value": 5
     }
    },
    "cb61d047875c4af4adc6d0bb5e0115e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb67dec7271c44fd889ebbaa85d56802": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc579f76e7be4092b3942987154e3b44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bc000b7fcdc4c84b1707af92d1ba12a",
       "IPY_MODEL_fd98f0d9d2254d90857765c5455039fa",
       "IPY_MODEL_2c75a816067041619e25612e46720b1e"
      ],
      "layout": "IPY_MODEL_175960d3168c412cabb59bfe78b03ecc"
     }
    },
    "ccaaa00b2acf4fa1b6aa0fb66f7d3ea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf0257bf1eba428d8c475ff263f51f47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cfec54bb2f2d4ce8966a1a1a86948059": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0eedbbce9464d6e9e21367a3dfe1b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee3f7f276176492f9952e30fbfbd385f",
      "placeholder": "​",
      "style": "IPY_MODEL_e37b603e7eef430697af13ffce2c8584",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "d198b894872f40ffaeb3febcbd3e6f14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_591e62b79c8149619c0cb603bb7072e0",
      "placeholder": "​",
      "style": "IPY_MODEL_9b94dcef291f42ecbe60f581797e59b4",
      "value": " 4617/4617 [00:00&lt;00:00, 5492.10 examples/s]"
     }
    },
    "d21f79fd666e49b2906dae1390932099": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d31839d6366a45caa66bbff9706f1c33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d446af78e6ce4d10b204da001c228043": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e4f9354cc944c4f99386a48acde165f",
       "IPY_MODEL_6bd021532b76412cb055c3e39d3c641e",
       "IPY_MODEL_d198b894872f40ffaeb3febcbd3e6f14"
      ],
      "layout": "IPY_MODEL_9f12c904bdc844a696519b3e6986b996"
     }
    },
    "d5a73174b3ee4acf807b828f79269194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d66681d9ea324015a5929511b95440f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6c1dcbefd804d7c8d25866d69fa3b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d78129063f944f3b958fdc822ad9c099": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7df45e2c21f416bb41b84a3ada5beb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d82646bbbd064b44802c0eee8b3a3655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d96fb1090fb04da19dd8b10cb76d7393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de902ded9fef41f4ae3d1ccbda5e1258": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e149d40659c942e6b62cba384cd99d5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ee86ba7d8bd488e8d008a30cd22e3e4",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fef7137378f48bfb5383e979fc8e9e0",
      "value": 2
     }
    },
    "e1b13313b731401a89bc2d4dd9018818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e1cfc4a4074d40e9bf587f8f2cb6a047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e33cc2696c8548fe8000a5882a51100c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86bd8f7557d24e7eb664fc19d4ca2a93",
      "placeholder": "​",
      "style": "IPY_MODEL_a1e9de4b77e54950835323813f126d91",
      "value": " 4.95G/4.95G [00:47&lt;00:00, 76.9MB/s]"
     }
    },
    "e37b603e7eef430697af13ffce2c8584": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4143b8db5f9409ab655a2dd85f19520": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4384ae8aed14fb2b6bfd95d3a948d30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4544f009fb94e95a1c318cf3f0e8b49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55009b25754143baba31ceb76ac875ba",
      "placeholder": "​",
      "style": "IPY_MODEL_c68f6d84e22b442d98f3ed5b2f4df115",
      "value": " 555/555 [00:00&lt;00:00, 9.00kB/s]"
     }
    },
    "e536b3a947604bbeb35cab551a8aebfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b3ef4c5e1fe4bd98af4aeb06cc6b2d6",
      "placeholder": "​",
      "style": "IPY_MODEL_e706b86348fa4850b0d4870efae73bed",
      "value": "generation_config.json: 100%"
     }
    },
    "e706b86348fa4850b0d4870efae73bed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e70a0e15ce754d3797232a4e38df2ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f245372f35264612a6d32b915fc48991",
       "IPY_MODEL_62193c34c72b40de859bc669faa4ba5c",
       "IPY_MODEL_77f8f78435cd4d938f6e9a8454e64e2c"
      ],
      "layout": "IPY_MODEL_cfec54bb2f2d4ce8966a1a1a86948059"
     }
    },
    "e73c1b21bd1a428987d34c9499edfe99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebc1b53d5d2d44ceb2588fa6fd84dcad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee3f7f276176492f9952e30fbfbd385f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef408261c9a9424d8859d4e3efffe062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01b42d47976f40a1906cbe42f6c60c3a",
      "placeholder": "​",
      "style": "IPY_MODEL_d5a73174b3ee4acf807b828f79269194",
      "value": " 462/0 [00:00&lt;00:00, 5937.45 examples/s]"
     }
    },
    "f15fed4f17b146aba228cda43ec065c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32b892b3a25c4fee8b8d7cd76de556f1",
      "placeholder": "​",
      "style": "IPY_MODEL_a6a3de028e14414cb1c80685cc26853c",
      "value": " 17.5M/17.5M [00:00&lt;00:00, 39.8MB/s]"
     }
    },
    "f245372f35264612a6d32b915fc48991": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76ef685779b44f50847f38f4060a3d03",
      "placeholder": "​",
      "style": "IPY_MODEL_02d6241a9eae4251a8f728f0c0a6df06",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "f28f7c64e6c0446a82113c4ec1af0193": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2f5ecc068284ce2a8bdf7c22a2fbd24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_992690906540442ca0fa3e08651221fe",
      "placeholder": "​",
      "style": "IPY_MODEL_5d9c46c38136490d8507aa2954a930d8",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "f7ea7fe5345b42428903d157f149ce10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b5cb432abbf4cfc83440d8024352b00",
      "placeholder": "​",
      "style": "IPY_MODEL_24d2deefe80f443094703c1ebe7f1380",
      "value": "Generating train split: "
     }
    },
    "f8210c6f006447058895e3fa818daf2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f82da5381fdb4112a860e6e7dfcfdbb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f88e35aa7a0344a999eececbd31a9847": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3864b1953ff4af591a5df19f80ad5ff",
      "placeholder": "​",
      "style": "IPY_MODEL_7e7330c0191d42338824d109ef5b35b3",
      "value": "Generating train split: "
     }
    },
    "f9ae47e1b51c4d1ab283b107405e7047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd98f0d9d2254d90857765c5455039fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42927861ab844eec9b279a221f574ecf",
      "max": 2805436,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_007cfd8a537142229c2d235b15400c8e",
      "value": 2805436
     }
    },
    "fe037efafdd2438799b57bf60f3ffad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fefde476a4904defb603dfd4e83011a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffea054e09744301ac4300e8c53406c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72e5300257f04bdd86a9b6c8ce2f6b08",
      "placeholder": "​",
      "style": "IPY_MODEL_1474b943860a4eec9dd0857aa9d06ccc",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
